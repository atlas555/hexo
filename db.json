{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/robots.txt","path":"robots.txt","modified":0,"renderable":0},{"_id":"themes/vexozxl/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/vexozxl/source/js/script.js","path":"js/script.js","modified":0,"renderable":1},{"_id":"themes/vexozxl/source/js/qrious.js","path":"js/qrious.js","modified":0,"renderable":1},{"_id":"themes/vexozxl/source/css/images/escheres.png","path":"css/images/escheres.png","modified":0,"renderable":1},{"_id":"themes/vexozxl/source/css/images/logo.png","path":"css/images/logo.png","modified":0,"renderable":1},{"_id":"themes/vexozxl/source/css/images/alipay.png","path":"css/images/alipay.png","modified":0,"renderable":1},{"_id":"themes/vexozxl/source/css/images/menu.png","path":"css/images/menu.png","modified":0,"renderable":1},{"_id":"themes/vexozxl/source/css/images/top.png","path":"css/images/top.png","modified":0,"renderable":1},{"_id":"themes/vexozxl/source/css/plugins/gitment.css","path":"css/plugins/gitment.css","modified":0,"renderable":1},{"_id":"themes/vexozxl/source/css/images/wechat.png","path":"css/images/wechat.png","modified":0,"renderable":1},{"_id":"themes/vexozxl/source/fonts/SourceSansPro.ttf","path":"fonts/SourceSansPro.ttf","modified":0,"renderable":1},{"_id":"themes/vexozxl/source/js/gitment.js","path":"js/gitment.js","modified":0,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"cf1797faffad13fdf42f28cba18a05d3a992d747","modified":1506426271000},{"_id":"source/robots.txt","hash":"9631979ef280b534d113141d3752eb719b56f824","modified":1506408836000},{"_id":"themes/vexozxl/_config.yml","hash":"5676b6fc8d75b91428f19b19f32891204960b49a","modified":1507789940000},{"_id":"themes/vexozxl/lint.sh","hash":"f580302e4aa9ccfb95a253851da6501d145613fe","modified":1507789940000},{"_id":"themes/vexozxl/package.json","hash":"4a839847a872079d154a4884182a7bc773e76535","modified":1507789940000},{"_id":"source/404/index.md","hash":"32f11379878375b0ececf4514cdd51c52a64d2db","modified":1506583280000},{"_id":"source/_posts/elasticsearch_tec_book_v1.01.md","hash":"b70c580dc7b10269bc92125534e4e7ebb595e4b1","modified":1506764155000},{"_id":"source/_posts/machine_learning-GAN_tec_share.md","hash":"50cbe888758b3a9214b416c32aed48377f04e6fb","modified":1507863790000},{"_id":"source/_posts/自己动手打造推荐系统-一-常用推荐算法优势分析.md","hash":"98749a3a4f98ed3ab2fb6c6ce6b7287c44bb315d","modified":1506761934000},{"_id":"source/about/index.md","hash":"68c8af0453deca5f6b03eb18ee6f89fb0c1f1f75","modified":1506395533000},{"_id":"source/bookshelf/index.md","hash":"a431cd000eb907a570e4d08c1629ff938fd0317b","modified":1506395533000},{"_id":"source/search/index.md","hash":"25f79ca74c25c2fd943e9761aebd1c9b45c92252","modified":1506395532000},{"_id":"source/resys/index.md","hash":"8ed642c8978f071561eb6798cd96cd2913990f7c","modified":1506592209000},{"_id":"source/tags/index.md","hash":"80a15f1b5daff22b04849109e976bc91a410b83e","modified":1506395533000},{"_id":"themes/vexozxl/layout/404.ejs","hash":"080d537f81c877a2a326ab121608edc16cdd79dd","modified":1507789940000},{"_id":"themes/vexozxl/layout/about.ejs","hash":"9d0f12efdc59859aec21fd7c4acab9ac150a4cd5","modified":1507789940000},{"_id":"themes/vexozxl/layout/archive.ejs","hash":"cb12abb19cb70e90d410a6233933eedb3f2c033a","modified":1507789940000},{"_id":"themes/vexozxl/layout/layout.ejs","hash":"a7b8f1debdca12d667ecd1bcc3d4bc6e13a23d7b","modified":1507789940000},{"_id":"themes/vexozxl/layout/index.ejs","hash":"6c7358c1d6a3fb5ae19dea47cea708c9896809a2","modified":1507789940000},{"_id":"themes/vexozxl/layout/page.ejs","hash":"26b2d3725496836867a702a55a91277991fec1a4","modified":1507789940000},{"_id":"themes/vexozxl/layout/tags.ejs","hash":"5b326e2bd3292b3015d0666b796544d7126acfda","modified":1507789940000},{"_id":"themes/vexozxl/layout/toc.ejs","hash":"223cff923b7b177ed7d4db9bef6f326dd290ea4f","modified":1507789940000},{"_id":"themes/vexozxl/node_modules/.DS_Store","hash":"edce1e94103911a82fe55e19abc2330e6eaf59b9","modified":1507789940000},{"_id":"themes/vexozxl/_source/about/index.md","hash":"68c8af0453deca5f6b03eb18ee6f89fb0c1f1f75","modified":1507789940000},{"_id":"themes/vexozxl/_source/project/index.md","hash":"b8f5482c157514bd2df4ce8a4e4d01a957497924","modified":1507789940000},{"_id":"themes/vexozxl/layout/_partial/archive.ejs","hash":"9abbf14034d581569c0b6c992fe22035cb5306b3","modified":1507789940000},{"_id":"themes/vexozxl/_source/tags/index.md","hash":"80a15f1b5daff22b04849109e976bc91a410b83e","modified":1507789940000},{"_id":"themes/vexozxl/layout/_partial/footer.ejs","hash":"d1ba79eaf22b9a7b01dbf31e5dcbbfce8c6a6aa4","modified":1507789940000},{"_id":"themes/vexozxl/layout/_partial/head.ejs","hash":"9c2cb91d07c78657eb6723a1629fee96dc5b2176","modified":1507789940000},{"_id":"themes/vexozxl/layout/_partial/header.ejs","hash":"e544f516b23bc609cc6367190f380c879b935c21","modified":1507789940000},{"_id":"themes/vexozxl/layout/_partial/pager.ejs","hash":"3a1b9680fbfa3baa76933c7c17216996381ad241","modified":1507789940000},{"_id":"themes/vexozxl/layout/_partial/tag.ejs","hash":"5d2a2c3f8ca7000945ab426a0c6939421974b224","modified":1507789940000},{"_id":"themes/vexozxl/layout/_partial/top.ejs","hash":"f09dea486246a580213005b21d4b38810dd16fb3","modified":1507789940000},{"_id":"themes/vexozxl/source/css/_config.styl","hash":"ac69c720d1699d2c93982b81c233c02982fc01be","modified":1507789940000},{"_id":"themes/vexozxl/source/css/style.styl","hash":"f2a32891e67d53d0414daa3255167296204d7f51","modified":1507789940000},{"_id":"themes/vexozxl/source/js/script.js","hash":"a19ed5f3c1d9c64855f162bce7ec66b47aada780","modified":1507789940000},{"_id":"themes/vexozxl/source/js/qrious.js","hash":"a9271e81e2ac6a692b1c133811afa33f0f3d7dc5","modified":1507789940000},{"_id":"themes/vexozxl/node_modules/.staging/uslug-d79edd83/index.js","hash":"adcfa6488fb6ff5ddf31d13b589d22dbc176bf96","modified":1507789940000},{"_id":"themes/vexozxl/node_modules/.staging/uslug-d79edd83/.npmignore","hash":"0a861f1091bff14f09cdcf55bf72d2a7f1b4bd1b","modified":1507789940000},{"_id":"themes/vexozxl/node_modules/.staging/uslug-d79edd83/LICENSE","hash":"2fe6c1073604f5c099a17a5ec183b9015b6e02f3","modified":1507789940000},{"_id":"themes/vexozxl/node_modules/.staging/uslug-d79edd83/README.md","hash":"624f19c7ea6bfbf91d3d60be9bd6d28c004b2d76","modified":1507789940000},{"_id":"themes/vexozxl/node_modules/.staging/uslug-d79edd83/package.json","hash":"1bd898af40f6c47ed08304b5e94c429a5575b518","modified":1507789940000},{"_id":"themes/vexozxl/source/css/_partial/about.styl","hash":"e4a9bffe9c44c3179c021e2d924386ff9f758399","modified":1507789940000},{"_id":"themes/vexozxl/source/css/_partial/archive.styl","hash":"e80ddf26f2af3523632afeabd57f81592537985a","modified":1507789940000},{"_id":"themes/vexozxl/source/css/_partial/footer.styl","hash":"acc26664e5b3bdb40534496234a66fca2994e905","modified":1507789940000},{"_id":"themes/vexozxl/source/css/_partial/header.styl","hash":"def3a6938d925c585a7da6256a6f2e90f3b7d61e","modified":1507789940000},{"_id":"themes/vexozxl/source/css/_partial/pager.styl","hash":"888384c67429c7568aa38b5ebe5acae3cc4de367","modified":1507789940000},{"_id":"themes/vexozxl/source/css/_partial/markdown.styl","hash":"fead738af515436dff5c05bffcae4da929ae75e9","modified":1507789940000},{"_id":"themes/vexozxl/source/css/_partial/project.styl","hash":"e9b6faadf4852bce3a4141cba0a102a7afb81e9f","modified":1507789940000},{"_id":"themes/vexozxl/source/css/_partial/tags.styl","hash":"5198a7f7c221341138ae5c65185e86b6e13e8e26","modified":1507789940000},{"_id":"themes/vexozxl/source/css/images/escheres.png","hash":"55deece3236dcc2fb44c28dec3e8bacbb7b46542","modified":1507789940000},{"_id":"themes/vexozxl/source/css/images/logo.png","hash":"3cc2fc6bda241e89369e1cef5887c31368528663","modified":1507789940000},{"_id":"themes/vexozxl/source/css/images/alipay.png","hash":"9f6b1c1389daf4d4725e1dd0649882463940687b","modified":1507789940000},{"_id":"themes/vexozxl/source/css/images/menu.png","hash":"bdaa35eb1ed119caeb934e15a05b9f4a5396d957","modified":1507789940000},{"_id":"themes/vexozxl/source/css/images/top.png","hash":"611a257907474ca02828319f81b006c1d818bb84","modified":1507789940000},{"_id":"themes/vexozxl/source/css/plugins/gitment.css","hash":"541ff18d7f3542b5663dc6aad06d43e135332b71","modified":1507789940000},{"_id":"themes/vexozxl/source/css/images/wechat.png","hash":"047933e41de09c3931e5c16fb008038bb55aec8e","modified":1507789940000},{"_id":"themes/vexozxl/source/fonts/SourceSansPro.ttf","hash":"1e9f0372c269da205fdbac8cf27cb9cf59f6ad45","modified":1507789940000},{"_id":"themes/vexozxl/source/js/gitment.js","hash":"376446d9c5930576016f97dd63e5e6616c94d8d4","modified":1507789940000},{"_id":"themes/vexozxl/node_modules/.staging/uslug-d79edd83/lib/Z.js","hash":"794d12289bb4ac77e1b97b3965a69c35813ef289","modified":1507789940000},{"_id":"themes/vexozxl/node_modules/.staging/uslug-d79edd83/lib/M.js","hash":"e1cad9515147544f2a3edaf6e999033275ea4f26","modified":1507789940000},{"_id":"themes/vexozxl/node_modules/.staging/uslug-d79edd83/lib/N.js","hash":"35a5ff6b2274af2ade459d0141cf53275ed81b4c","modified":1507789940000},{"_id":"themes/vexozxl/node_modules/.staging/uslug-d79edd83/test/test.js","hash":"845d084bde9afb8d49274c1fbee586544e7f81ad","modified":1507789940000},{"_id":"themes/vexozxl/node_modules/.staging/uslug-d79edd83/lib/uslug.js","hash":"5ebbff4e7c9f8dd8b629dd674ec50c5790d6cfc7","modified":1507789940000},{"_id":"themes/vexozxl/node_modules/.staging/uslug-d79edd83/lib/L.js","hash":"c5f59c21644741cd89efa99b86dc13b9e64a4abe","modified":1507789940000},{"_id":"public/baidusitemap.xml","hash":"9fe473e5729c25ce7032655dfe51779b6ebba509","modified":1507863797871},{"_id":"public/sitemap.xml","hash":"79ba6c4210472ab575a57b202f24bf9b8afc8d98","modified":1507863797939},{"_id":"public/atom.xml","hash":"4caaffaace6c2cb221953a15cf457929c1b4af11","modified":1507863797936},{"_id":"public/404.html","hash":"61bbbab6165c4a77a63e99645d99b16ae685b945","modified":1507863584433},{"_id":"public/about/index.html","hash":"3a54a76dd71f77fdc03b05da2b8876a46b02415a","modified":1507863584438},{"_id":"public/bookshelf/index.html","hash":"f229473b9bff6901ec2083356a06e080f9fa1c9f","modified":1507863584439},{"_id":"public/search/index.html","hash":"b1f975a55fb77f6912ad90a4888c0241d1b3ad8e","modified":1507863584439},{"_id":"public/resys/index.html","hash":"7e8ad3d5e494a90671d38dce6c1139c2256f33dd","modified":1507863584439},{"_id":"public/tags/index.html","hash":"68ffc8270015867aafe25be19ce667b6d3731f21","modified":1507863797941},{"_id":"public/archives/index.html","hash":"4ea549b1b140cee083603ea778a702f3340fa67a","modified":1507863584439},{"_id":"public/archives/2017/index.html","hash":"693903aa382a7f2da1d4d4eb0f4cf4e259c494ba","modified":1507863584440},{"_id":"public/archives/2017/09/index.html","hash":"abcdbb375b0a4dbd83219cafd9cb1110d4a67ca6","modified":1507863584440},{"_id":"public/categories/search/index.html","hash":"c5284f7e6651118bbe145a8f2aece0047ebc4422","modified":1507863584440},{"_id":"public/categories/resys/index.html","hash":"f466a2bed330d440d31cbcf66801c813ca759f38","modified":1507863584440},{"_id":"public/resys/resys_common_algorithm_analyse.html","hash":"e79a4261a5f7b08371171466053ff7beaef966fd","modified":1507863584440},{"_id":"public/search/elasticsearch_tec_book.html","hash":"cca4e7f41544387ac39280e8ea1f5960189a21b6","modified":1507863584440},{"_id":"public/tags/search/index.html","hash":"7ce1d8acfeef8b6370dc623108a7cb986dbb26c0","modified":1507863584448},{"_id":"public/tags/resys/index.html","hash":"57af2d93e8397f4893f944981919f1eb4855461a","modified":1507863584459},{"_id":"public/index.html","hash":"2cc95ab955b975e740a064aca230382341372b9d","modified":1507863797941},{"_id":"public/deep-learning/deep_learning_gan_tec_share.html","hash":"3588003f016ea752c818309d55f8d4e2aa3440f4","modified":1507863797941},{"_id":"public/archives/2017/10/index.html","hash":"df6703b275e6c33ca75d572e43bd1b5d2f3f66ff","modified":1507863584462},{"_id":"public/categories/deep-learning/index.html","hash":"3205645e55a9f1b1af61def7ed83f2c539a8c237","modified":1507863584462},{"_id":"public/tags/deep-learning/index.html","hash":"739c9b67bb0c3ea4feec6544ee61c993c1fcbede","modified":1507863584462},{"_id":"public/tags/GAN/index.html","hash":"58cbf853c6643e373009915d0f8e2417dedc1718","modified":1507863584462},{"_id":"public/robots.txt","hash":"9631979ef280b534d113141d3752eb719b56f824","modified":1507863584462},{"_id":"public/css/images/escheres.png","hash":"55deece3236dcc2fb44c28dec3e8bacbb7b46542","modified":1507863584462},{"_id":"public/css/images/logo.png","hash":"3cc2fc6bda241e89369e1cef5887c31368528663","modified":1507863584462},{"_id":"public/css/images/alipay.png","hash":"9f6b1c1389daf4d4725e1dd0649882463940687b","modified":1507863584462},{"_id":"public/css/images/menu.png","hash":"bdaa35eb1ed119caeb934e15a05b9f4a5396d957","modified":1507863584462},{"_id":"public/css/images/top.png","hash":"611a257907474ca02828319f81b006c1d818bb84","modified":1507863584462},{"_id":"public/css/images/wechat.png","hash":"047933e41de09c3931e5c16fb008038bb55aec8e","modified":1507863584463},{"_id":"public/js/script.js","hash":"a19ed5f3c1d9c64855f162bce7ec66b47aada780","modified":1507863584757},{"_id":"public/css/style.css","hash":"91599cbf54c671afad2ec2c6a23bafc132e54050","modified":1507863584757},{"_id":"public/js/qrious.js","hash":"a9271e81e2ac6a692b1c133811afa33f0f3d7dc5","modified":1507863584757},{"_id":"public/css/plugins/gitment.css","hash":"541ff18d7f3542b5663dc6aad06d43e135332b71","modified":1507863584757},{"_id":"public/js/gitment.js","hash":"376446d9c5930576016f97dd63e5e6616c94d8d4","modified":1507863584757},{"_id":"public/fonts/SourceSansPro.ttf","hash":"1e9f0372c269da205fdbac8cf27cb9cf59f6ad45","modified":1507863584757}],"Category":[{"name":"deep learning","_id":"cj8pb1nnp0004q9s6m8yc6ve8"},{"name":"search","_id":"cj8pb1nnu000aq9s6tjgxq7wg"},{"name":"resys","_id":"cj8pb1nnw000eq9s6wmwcbyb7"}],"Data":[],"Page":[{"title":"404 Not Found：该页无法显示","date":"2017-09-27T10:57:29.000Z","comments":0,"layout":"404","_content":"","source":"404/index.md","raw":"---\npermalink: /404\ntitle: 404 Not Found：该页无法显示\ndate: 2017-09-27 18:57:29\ncomments: false\nlayout: 404\n---\n","updated":"2017-09-28T07:21:20.000Z","path":"/404.html","_id":"cj8pb1nni0000q9s63jm30ih8","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"About","layout":"about","_content":"","source":"about/index.md","raw":"---\ntitle: About\nlayout: about\n---","date":"2017-09-26T03:12:13.000Z","updated":"2017-09-26T03:12:13.000Z","path":"about/index.html","comments":1,"_id":"cj8pb1nnn0002q9s6n76uubtf","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Bookshelf","id":1949,"comment":false,"date":"2017-06-03T06:12:10.000Z","_content":"\n## 那些年度过的时间\n\n## Book\n\n(1) **Tcp/ip 详解（卷1）** – 评分：7.0\n\n读后评：介绍计算机网络的比较基础的一本书，在学校或多或少都学过，这里不展开讲了。如果在互联网公司，还是请看第二卷、三卷吧。\n\n(2)Java编程思想\n\n(3)Python CookBook\n\n(4) 大型网站技术架构 – 核心原理与案例分析\n\n(4) 本色（乐嘉）\n\n读后评：通过各方面的了解，我还是比较喜欢乐嘉这个人的，他写的这本书买来读了一下，很是通透。\n(6) **请给我结果**\n\n读后评：直白的语言，有些地方不适合互联网公司。\n(7)**番茄工作方法图解**\n\n读后评：经典的方法，以番茄钟来高效的利用自己的时间，尝试了一段时间。但是，还是被自己码代码的投入忘了时间。\n(8)**黑客与画家**\n\n读后评：我对这本书印象最深的是关于财富、创业、语言的部分，很深刻，有共鸣。\n\n(9) **三体** – 刘慈欣\n\n读后评：在一开始就深深的吸引了我，花了一个周末看完了，其中各种的问题真的很令人深思！\n\n(10) **趁年轻，折腾吧（袁岳）**\n\n读后评：一句话概括：趁年轻，折腾吧！！ 推荐一读\n\n(11) **看见（柴静）**\n\n读后评：以自己的经历（看见的）讲到的近几年的各种事情，让我看到了当年各个事件的另一个方面（好的或者坏的或者更坏的）。推荐阅读\n\n## Paper\n\n(1) Bigtable:A Distributed Storage System for Structured Data ([download](http://document-save.qiniudn.com/zhangxiaolong.orgbigtable-osdi06.pdf))\n(2) GFS:The Google File System ([download](http://document-save.qiniudn.com/zhangxiaolong.orggfs-sosp2003.pdf))\n(3) MapReduce:MapReduce: Simplied Data Processing on Large Clusters ([download](http://document-save.qiniudn.com/zhangxiaolong.orgmapreduce-osdi04.pdf))\n(4) Spanner:Google’s Globally-Distributed Database ([download](http://document-save.qiniudn.com/zhangxiaolong.orgspanner-osdi2012.pdf))\n(5) Megastore: Providing Scalable, Highly Available Storage for Interactive Services ([download](http://document-save.qiniudn.com/zhangxiaolong.orgmegastore.pdf))\n(6) Pregel:A System for Large-Scale Graph Processing ([download](http://document-save.qiniudn.com/zhangxiaolong.orgPregel.pdf))\n(7) Dremel: Interactive Analysis of Web-Scale Datasets ([download](http://document-save.qiniudn.com/zhangxiaolong.orgDremel.pdf))\n(8) Caffeine: Large-scale Incremental Processing Using Distributed Transactions and Notications ([download](http://document-save.qiniudn.com/zhangxiaolong.orgCaffeine%20-1.pdf))\n(9) Search The Web ([download](http://document-save.qiniudn.com/web%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%A6%82%E8%AE%BA%E2%80%94%E2%80%94searching_the_web.pdf))","source":"bookshelf/index.md","raw":"---\ntitle: Bookshelf\nid: 1949\ncomment: false\ndate: 2017-06-03 14:12:10\n---\n\n## 那些年度过的时间\n\n## Book\n\n(1) **Tcp/ip 详解（卷1）** – 评分：7.0\n\n读后评：介绍计算机网络的比较基础的一本书，在学校或多或少都学过，这里不展开讲了。如果在互联网公司，还是请看第二卷、三卷吧。\n\n(2)Java编程思想\n\n(3)Python CookBook\n\n(4) 大型网站技术架构 – 核心原理与案例分析\n\n(4) 本色（乐嘉）\n\n读后评：通过各方面的了解，我还是比较喜欢乐嘉这个人的，他写的这本书买来读了一下，很是通透。\n(6) **请给我结果**\n\n读后评：直白的语言，有些地方不适合互联网公司。\n(7)**番茄工作方法图解**\n\n读后评：经典的方法，以番茄钟来高效的利用自己的时间，尝试了一段时间。但是，还是被自己码代码的投入忘了时间。\n(8)**黑客与画家**\n\n读后评：我对这本书印象最深的是关于财富、创业、语言的部分，很深刻，有共鸣。\n\n(9) **三体** – 刘慈欣\n\n读后评：在一开始就深深的吸引了我，花了一个周末看完了，其中各种的问题真的很令人深思！\n\n(10) **趁年轻，折腾吧（袁岳）**\n\n读后评：一句话概括：趁年轻，折腾吧！！ 推荐一读\n\n(11) **看见（柴静）**\n\n读后评：以自己的经历（看见的）讲到的近几年的各种事情，让我看到了当年各个事件的另一个方面（好的或者坏的或者更坏的）。推荐阅读\n\n## Paper\n\n(1) Bigtable:A Distributed Storage System for Structured Data ([download](http://document-save.qiniudn.com/zhangxiaolong.orgbigtable-osdi06.pdf))\n(2) GFS:The Google File System ([download](http://document-save.qiniudn.com/zhangxiaolong.orggfs-sosp2003.pdf))\n(3) MapReduce:MapReduce: Simplied Data Processing on Large Clusters ([download](http://document-save.qiniudn.com/zhangxiaolong.orgmapreduce-osdi04.pdf))\n(4) Spanner:Google’s Globally-Distributed Database ([download](http://document-save.qiniudn.com/zhangxiaolong.orgspanner-osdi2012.pdf))\n(5) Megastore: Providing Scalable, Highly Available Storage for Interactive Services ([download](http://document-save.qiniudn.com/zhangxiaolong.orgmegastore.pdf))\n(6) Pregel:A System for Large-Scale Graph Processing ([download](http://document-save.qiniudn.com/zhangxiaolong.orgPregel.pdf))\n(7) Dremel: Interactive Analysis of Web-Scale Datasets ([download](http://document-save.qiniudn.com/zhangxiaolong.orgDremel.pdf))\n(8) Caffeine: Large-scale Incremental Processing Using Distributed Transactions and Notications ([download](http://document-save.qiniudn.com/zhangxiaolong.orgCaffeine%20-1.pdf))\n(9) Search The Web ([download](http://document-save.qiniudn.com/web%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%A6%82%E8%AE%BA%E2%80%94%E2%80%94searching_the_web.pdf))","updated":"2017-09-26T03:12:13.000Z","path":"bookshelf/index.html","comments":1,"layout":"page","_id":"cj8pb1nnr0006q9s6ab6oskbs","content":"<h2 id=\"那些年度过的时间\"><a href=\"#那些年度过的时间\" class=\"headerlink\" title=\"那些年度过的时间\"></a>那些年度过的时间</h2><h2 id=\"Book\"><a href=\"#Book\" class=\"headerlink\" title=\"Book\"></a>Book</h2><p>(1) <strong>Tcp/ip 详解（卷1）</strong> – 评分：7.0</p>\n<p>读后评：介绍计算机网络的比较基础的一本书，在学校或多或少都学过，这里不展开讲了。如果在互联网公司，还是请看第二卷、三卷吧。</p>\n<p>(2)Java编程思想</p>\n<p>(3)Python CookBook</p>\n<p>(4) 大型网站技术架构 – 核心原理与案例分析</p>\n<p>(4) 本色（乐嘉）</p>\n<p>读后评：通过各方面的了解，我还是比较喜欢乐嘉这个人的，他写的这本书买来读了一下，很是通透。<br>(6) <strong>请给我结果</strong></p>\n<p>读后评：直白的语言，有些地方不适合互联网公司。<br>(7)<strong>番茄工作方法图解</strong></p>\n<p>读后评：经典的方法，以番茄钟来高效的利用自己的时间，尝试了一段时间。但是，还是被自己码代码的投入忘了时间。<br>(8)<strong>黑客与画家</strong></p>\n<p>读后评：我对这本书印象最深的是关于财富、创业、语言的部分，很深刻，有共鸣。</p>\n<p>(9) <strong>三体</strong> – 刘慈欣</p>\n<p>读后评：在一开始就深深的吸引了我，花了一个周末看完了，其中各种的问题真的很令人深思！</p>\n<p>(10) <strong>趁年轻，折腾吧（袁岳）</strong></p>\n<p>读后评：一句话概括：趁年轻，折腾吧！！ 推荐一读</p>\n<p>(11) <strong>看见（柴静）</strong></p>\n<p>读后评：以自己的经历（看见的）讲到的近几年的各种事情，让我看到了当年各个事件的另一个方面（好的或者坏的或者更坏的）。推荐阅读</p>\n<h2 id=\"Paper\"><a href=\"#Paper\" class=\"headerlink\" title=\"Paper\"></a>Paper</h2><p>(1) Bigtable:A Distributed Storage System for Structured Data (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgbigtable-osdi06.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(2) GFS:The Google File System (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orggfs-sosp2003.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(3) MapReduce:MapReduce: Simplied Data Processing on Large Clusters (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgmapreduce-osdi04.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(4) Spanner:Google’s Globally-Distributed Database (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgspanner-osdi2012.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(5) Megastore: Providing Scalable, Highly Available Storage for Interactive Services (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgmegastore.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(6) Pregel:A System for Large-Scale Graph Processing (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgPregel.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(7) Dremel: Interactive Analysis of Web-Scale Datasets (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgDremel.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(8) Caffeine: Large-scale Incremental Processing Using Distributed Transactions and Notications (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgCaffeine%20-1.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(9) Search The Web (<a href=\"http://document-save.qiniudn.com/web%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%A6%82%E8%AE%BA%E2%80%94%E2%80%94searching_the_web.pdf\" target=\"_blank\" rel=\"external\">download</a>)</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"那些年度过的时间\"><a href=\"#那些年度过的时间\" class=\"headerlink\" title=\"那些年度过的时间\"></a>那些年度过的时间</h2><h2 id=\"Book\"><a href=\"#Book\" class=\"headerlink\" title=\"Book\"></a>Book</h2><p>(1) <strong>Tcp/ip 详解（卷1）</strong> – 评分：7.0</p>\n<p>读后评：介绍计算机网络的比较基础的一本书，在学校或多或少都学过，这里不展开讲了。如果在互联网公司，还是请看第二卷、三卷吧。</p>\n<p>(2)Java编程思想</p>\n<p>(3)Python CookBook</p>\n<p>(4) 大型网站技术架构 – 核心原理与案例分析</p>\n<p>(4) 本色（乐嘉）</p>\n<p>读后评：通过各方面的了解，我还是比较喜欢乐嘉这个人的，他写的这本书买来读了一下，很是通透。<br>(6) <strong>请给我结果</strong></p>\n<p>读后评：直白的语言，有些地方不适合互联网公司。<br>(7)<strong>番茄工作方法图解</strong></p>\n<p>读后评：经典的方法，以番茄钟来高效的利用自己的时间，尝试了一段时间。但是，还是被自己码代码的投入忘了时间。<br>(8)<strong>黑客与画家</strong></p>\n<p>读后评：我对这本书印象最深的是关于财富、创业、语言的部分，很深刻，有共鸣。</p>\n<p>(9) <strong>三体</strong> – 刘慈欣</p>\n<p>读后评：在一开始就深深的吸引了我，花了一个周末看完了，其中各种的问题真的很令人深思！</p>\n<p>(10) <strong>趁年轻，折腾吧（袁岳）</strong></p>\n<p>读后评：一句话概括：趁年轻，折腾吧！！ 推荐一读</p>\n<p>(11) <strong>看见（柴静）</strong></p>\n<p>读后评：以自己的经历（看见的）讲到的近几年的各种事情，让我看到了当年各个事件的另一个方面（好的或者坏的或者更坏的）。推荐阅读</p>\n<h2 id=\"Paper\"><a href=\"#Paper\" class=\"headerlink\" title=\"Paper\"></a>Paper</h2><p>(1) Bigtable:A Distributed Storage System for Structured Data (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgbigtable-osdi06.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(2) GFS:The Google File System (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orggfs-sosp2003.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(3) MapReduce:MapReduce: Simplied Data Processing on Large Clusters (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgmapreduce-osdi04.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(4) Spanner:Google’s Globally-Distributed Database (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgspanner-osdi2012.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(5) Megastore: Providing Scalable, Highly Available Storage for Interactive Services (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgmegastore.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(6) Pregel:A System for Large-Scale Graph Processing (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgPregel.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(7) Dremel: Interactive Analysis of Web-Scale Datasets (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgDremel.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(8) Caffeine: Large-scale Incremental Processing Using Distributed Transactions and Notications (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgCaffeine%20-1.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(9) Search The Web (<a href=\"http://document-save.qiniudn.com/web%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%A6%82%E8%AE%BA%E2%80%94%E2%80%94searching_the_web.pdf\" target=\"_blank\" rel=\"external\">download</a>)</p>\n"},{"title":"Search","id":1842,"comment":false,"date":"2017-05-22T04:05:33.000Z","_content":"","source":"search/index.md","raw":"---\ntitle: Search\nid: 1842\ncomment: false\ndate: 2017-05-22 12:05:33\n---\n","updated":"2017-09-26T03:12:12.000Z","path":"search/index.html","comments":1,"layout":"page","_id":"cj8pb1nns0008q9s69ln2l3rk","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"resys","date":"2017-09-26T01:52:24.000Z","_content":"### 自己动手实现推荐系统系列\n\n[自己动手实现推荐系统：一.常用推荐算法优势分析](http://www.zhangxiaolong.org/resys/resys_common_algorithm_analyse.html)\n","source":"resys/index.md","raw":"title: resys\ndate: 2017-09-26 09:52:24\n---\n### 自己动手实现推荐系统系列\n\n[自己动手实现推荐系统：一.常用推荐算法优势分析](http://www.zhangxiaolong.org/resys/resys_common_algorithm_analyse.html)\n","updated":"2017-09-28T09:50:09.000Z","path":"resys/index.html","comments":1,"layout":"page","_id":"cj8pb1nnt0009q9s6ni1a180n","content":"<h3 id=\"自己动手实现推荐系统系列\"><a href=\"#自己动手实现推荐系统系列\" class=\"headerlink\" title=\"自己动手实现推荐系统系列\"></a>自己动手实现推荐系统系列</h3><p><a href=\"http://www.zhangxiaolong.org/resys/resys_common_algorithm_analyse.html\">自己动手实现推荐系统：一.常用推荐算法优势分析</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"自己动手实现推荐系统系列\"><a href=\"#自己动手实现推荐系统系列\" class=\"headerlink\" title=\"自己动手实现推荐系统系列\"></a>自己动手实现推荐系统系列</h3><p><a href=\"http://www.zhangxiaolong.org/resys/resys_common_algorithm_analyse.html\">自己动手实现推荐系统：一.常用推荐算法优势分析</a></p>\n"},{"title":"Tags","layout":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: Tags\nlayout: tags\n---\n","date":"2017-09-26T03:12:13.000Z","updated":"2017-09-26T03:12:13.000Z","path":"tags/index.html","comments":1,"_id":"cj8pb1nnu000cq9s6iawsyyeh","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"深度学习之GAN技术分享","date":"2017-10-13T02:15:17.000Z","english_title":"deep_learning_gan_tec_share","toc":false,"_content":"\n本文是团队内部本人的一个技术分享-深度学习最近的热门之一：生成式对抗网络GAN\n\n## PPT分享\n\n{% pdf http://image.zhangxiaolong.org/file/GAN%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB.pdf %}\n\n参考文献：\n（1）[生成对抗网络nips2016课程](https://zhuanlan.zhihu.com/uai-rocks)\n（2）[伯克利深度学习专题课程：对抗生成网络创始人首次剖析训练实例](https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2651988584&idx=3&sn=e42bbbe2c447de44f465e568d467cebe&chksm=f1215699c656df8f46bbb8275ccb86dc55d63c018acba3f0f14ed55d0b9a9916bc1325cca7e9&mpshare=1&scene=1&srcid=1025xB3CzclBqrVMBZMxSgs1#rd)\n（3）[生成式对抗网络GAN研究进展](http://blog.csdn.net/Solomon1558/article/details/52537114)\n（4）[简述生成式对抗网络](https://chenrudan.github.io/blog/2016/11/12/gan.html)\n","source":"_posts/machine_learning-GAN_tec_share.md","raw":"---\ntitle: '深度学习之GAN技术分享'\ndate: 2017-10-13 10:15:17\ntags:\n  - deep learning\n  - GAN\ncategories:\n  - deep learning\nenglish_title: deep_learning_gan_tec_share\ntoc: false\n---\n\n本文是团队内部本人的一个技术分享-深度学习最近的热门之一：生成式对抗网络GAN\n\n## PPT分享\n\n{% pdf http://image.zhangxiaolong.org/file/GAN%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB.pdf %}\n\n参考文献：\n（1）[生成对抗网络nips2016课程](https://zhuanlan.zhihu.com/uai-rocks)\n（2）[伯克利深度学习专题课程：对抗生成网络创始人首次剖析训练实例](https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2651988584&idx=3&sn=e42bbbe2c447de44f465e568d467cebe&chksm=f1215699c656df8f46bbb8275ccb86dc55d63c018acba3f0f14ed55d0b9a9916bc1325cca7e9&mpshare=1&scene=1&srcid=1025xB3CzclBqrVMBZMxSgs1#rd)\n（3）[生成式对抗网络GAN研究进展](http://blog.csdn.net/Solomon1558/article/details/52537114)\n（4）[简述生成式对抗网络](https://chenrudan.github.io/blog/2016/11/12/gan.html)\n","slug":"machine_learning-GAN_tec_share","published":1,"updated":"2017-10-13T03:03:10.000Z","_id":"cj8pb1nnj0001q9s6jpsz3ukm","comments":1,"layout":"post","photos":[],"link":"","content":"<p>本文是团队内部本人的一个技术分享-深度学习最近的热门之一：生成式对抗网络GAN</p>\n<h2 id=\"PPT分享\"><a href=\"#PPT分享\" class=\"headerlink\" title=\"PPT分享\"></a>PPT分享</h2>\n\n\t<div class=\"row\">\n    <embed src=\"http://image.zhangxiaolong.org/file/GAN%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB.pdf\" width=\"100%\" height=\"550\" type=\"application/pdf\">\n\t</div>\n\n\n\n<p>参考文献：<br>（1）<a href=\"https://zhuanlan.zhihu.com/uai-rocks\" target=\"_blank\" rel=\"external\">生成对抗网络nips2016课程</a><br>（2）<a href=\"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2651988584&amp;idx=3&amp;sn=e42bbbe2c447de44f465e568d467cebe&amp;chksm=f1215699c656df8f46bbb8275ccb86dc55d63c018acba3f0f14ed55d0b9a9916bc1325cca7e9&amp;mpshare=1&amp;scene=1&amp;srcid=1025xB3CzclBqrVMBZMxSgs1#rd\" target=\"_blank\" rel=\"external\">伯克利深度学习专题课程：对抗生成网络创始人首次剖析训练实例</a><br>（3）<a href=\"http://blog.csdn.net/Solomon1558/article/details/52537114\" target=\"_blank\" rel=\"external\">生成式对抗网络GAN研究进展</a><br>（4）<a href=\"https://chenrudan.github.io/blog/2016/11/12/gan.html\" target=\"_blank\" rel=\"external\">简述生成式对抗网络</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>本文是团队内部本人的一个技术分享-深度学习最近的热门之一：生成式对抗网络GAN</p>\n<h2 id=\"PPT分享\"><a href=\"#PPT分享\" class=\"headerlink\" title=\"PPT分享\"></a>PPT分享</h2>\n\n\t<div class=\"row\">\n    <embed src=\"http://image.zhangxiaolong.org/file/GAN%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB.pdf\" width=\"100%\" height=\"550\" type=\"application/pdf\">\n\t</div>\n\n\n\n<p>参考文献：<br>（1）<a href=\"https://zhuanlan.zhihu.com/uai-rocks\" target=\"_blank\" rel=\"external\">生成对抗网络nips2016课程</a><br>（2）<a href=\"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2651988584&amp;idx=3&amp;sn=e42bbbe2c447de44f465e568d467cebe&amp;chksm=f1215699c656df8f46bbb8275ccb86dc55d63c018acba3f0f14ed55d0b9a9916bc1325cca7e9&amp;mpshare=1&amp;scene=1&amp;srcid=1025xB3CzclBqrVMBZMxSgs1#rd\" target=\"_blank\" rel=\"external\">伯克利深度学习专题课程：对抗生成网络创始人首次剖析训练实例</a><br>（3）<a href=\"http://blog.csdn.net/Solomon1558/article/details/52537114\" target=\"_blank\" rel=\"external\">生成式对抗网络GAN研究进展</a><br>（4）<a href=\"https://chenrudan.github.io/blog/2016/11/12/gan.html\" target=\"_blank\" rel=\"external\">简述生成式对抗网络</a></p>\n"},{"title":"elasticsearch 技术手册(持续更新版本) v1.01","author":"Atlas","author_id":"Atlas","date":"2017-09-26T02:47:00.000Z","english_title":"elasticsearch_tec_book","toc":true,"_content":"\n# elasticsearch技术手册 v1.01\n\n## 1. 基础\n本手册内容是基于`elasticsearch5+`版本。准确的说是5.0.1版本。\n### 1.概念\n集群（cluster）、节点（node）、索引（index）、分片（shards）、副本（replicas）；\nterm、tf-idf、boost等\n### 2. Elasticsearch features\n\n1. [Based in lucene, write in java]()\n2. [Realtime analytics]()\n3. [Full Text search engine]()\n4. [Distributed, easy to scale]()\n5. [High availability]()\n6. [Document oriented(json)]()\n7. [Schema free]()\n8. [Restful API, json over http]()\n9. [Open source:Apache License 6.0 (ES:5.x)]()\n10. [Plugins & Community support]()\n\n### 3. elasticsearch do what on lucene?\nElasticsearch 构建在lucene之上，提供json方式的rest api进行交互；\n\n1. Elasticsearch在lucene之上提供一个完整的分布式系统；\n2. Elasticsearch提供了一个分布式的抽象的数据结构；\n3. 提供了一些特性，例如线程池、队列、node/cluster监控api、数据监控api、以及集群管理等等；\n\n## 2. 生产环境\n### 1. 监控（Monitoring）\n对于已经初步部署完成的elasticsearch集群来说，接下来的集群监控就变的更重要了。集群的重要参数，比如集群状态，分片状态等是集群健康的体现。elasticsearch提供了很对的现成api供我们管理和监控cluster。\n其中，(1)marvel是一个很容易监控elasticsearch的工具。它可以整合大量的统计数据通过kibana。\n(2) cluster health\n### 2. 生产环境部署（Production Deploying）\n生产环境的部署有很多考究的地方，接下来我从以下三个方面来说。\n#### 运维部署考虑（硬件以及部署策略）\n（1）memory，elasticsearch是比较吃内存的，尤其像排序、聚合操作，所以保证足够的heap内存是重要的。如果对内存不够的话，会交换到系统的缓存，由于lucene的数据结构是disk-based的格式，这势必会影响搜索的性能；一般建议使用16g-64gRAM的机器。如果大于64g，则会出现[另外的一些问题](https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html)\n（2）cpus,和内存相比，搜索对cpu的要求不是特别高，一般使用多核cpu就行，比如2-8核的；\n（3）disk，硬盘的性能对搜索集群非常重要，磁盘的性能直接影响索引的构建和读写操作，很多时候是搜索的一个瓶颈。ssd硬盘是目前最好的方式，但是由于其价钱看看阿里云，是同样的`喜人`，所以看业务需要，力所能及吧，我们目前使用的是高性能磁盘（high-performance server disks, 15k RPM drives），可以满足业务需求。\n（4）network，一个快速稳定的网络环境对分布式系统非常的重要，低延迟、高带宽有利于节点间的交互以及分片的拷贝和恢复\n（5）其他，尽量避免使用小配置机器组合一个超大的集群，这样管理起来就是一个大坑\n#### 优化配置参数\n(1)Java Virtual Machine\n(2)Transport Client Versus Node Client\nvs:\nTransport Client 可以解耦你的应用和搜索服务，应用可以很快的创建和销毁连接；\nNode Client 可以和搜索服务保持一个持久连接，可以查看搜索的结构信息；\n(3)Important Configuration Changes\nelasticsearch配置文件有非常好的默认设置，都是在实际的工作环境中实践过的。当遇到性能问题的时候，更多的是需要考虑数据存储布局和添加更多的node（elasticsearch文档中特意说明了配置文件的重要性，不让随便更改，大多数情况下是正确的）。\n\n- name\n\n```\n1. Assign Names\ncluster.name: elasticsearch_production\nnode.name: elasticsearch_005_data\n\n2. Paths\npath.data: /path/to/data1,/path/to/data2 \n\n# Path to log files:\npath.logs: /path/to/logs\n\n# Path to where plugins are installed:\npath.plugins: /path/to/plugins\n\n```\n\n- minimum_master_nodes，这个参数是在配置文件中比较重要的一个，如果配置不对的话，会发生split brains（俗称“脑裂”），就是说会存在多个master节点，继而可能发生丢失data现象。这个参数的计算公式：(number of master-eligible nodes / 2) + 1，举例说明：\n\n\t- 假如你有10个node（可存储数据，可成为master），则设置为6；\n\t- 假如你有三个可选为master的节点，100+个数据节点，则设置为2；\n\t- 假如你有2个常规节点，这个值设置为2，但是如果丢失一个则会造成集群不可用，如果设置为1，则不能保证脑裂的不存在，最好的方法是保证最小的节点数为3.\n\n```\ndiscovery.zen.minimum_master_nodes: 2\n```\n因为elasticsearch是自适应的，节点随时添加或者下线，不过还好，有api我们可以实时调整这个参数，\n\n```\nPUT /_cluster/settings\n{\n    \"persistent\" : {\n        \"discovery.zen.minimum_master_nodes\" : 2\n    }\n}\n```\n\n- Recovery Settings\n恢复策略对elasticsearch是必不可少的，举例来说，假如现在集群（10 nodes）集体下线进行维修升级，当重新启动的时候，先启动了5 nodes，此时集群发现有5个node启动了，会执行shard的备份和交换，直到达到分片平衡，此时如果另外5 nodes加入到集群中，会发生什么呢？cluster会继续rebalance，新加入的节点发现数据集群中已经有了，首先删除本地数据，通知集群发动rebalance，平衡各个shards，这整个过程中shard会发生copy、sweap、delete等操作，耗费好多资源和时间，对一个大集群来说，耗费的更多，不可忍受。所以，elasticsearch有三个参数可以配置这些。\n\n```\ngateway.recover_after_nodes: 8   // 集群中恢复的节点数，就是说当改集群启动了8个几点，才尽兴rebalance\n\n// 这两项说明，本集群有10的node，当10个nodes都启动或者启动了8个node且超过5分钟后就会发起rebalance\ngateway.expected_nodes: 10\ngateway.recover_after_time: 5m\n```\n这些策略只和`整个cluster重启`时生效。\n\n- Prefer Unicast over Multicast\nelasticsearch建议使用单播的方式，虽然依然提供了多播的方式，但存在找不到master等尴尬的问题，不建议使用。\n\n```\ndiscovery.zen.ping.unicast.hosts: [\"host1\", \"host2:port\"]\n```\n（4）不要轻易修改的参数\n\n1. Garbage Collector\nelasticsearch中默认采用Concurrent-Mark and Sweep (CMS)的gc回收器；\n\n2. Threadpools\nelasticsearch中设置线程池非常合理的，如果没有特别情况下不要修改这个值\n\n```\nSearch gets a larger threadpool, and is configured to int((# of cores * 3) / 2) + 1\n```\n(5)Heap: Sizing and Swapping\n(6)File Descriptors and MMap\nelasticsearch混合使用nioFS和MMapFS。\n\n### 3. 插件\n1. 使用[head](https://github.com/mobz/elasticsearch-head)插件来查看索引数据\n2. 使用[kopf](https://github.com/lmenezes/elasticsearch-kopf)来备份集群节点\n3. 使用[bigdesk](https://github.com/lukas-vlcek/bigdesk)查看集群性能\n4. [elasticsearch-sql](https://github.com/NLPchina/elasticsearch-sql) 通过sql进行聚合检索, 可以将sql语句翻译成ES的JSON检索语句\n5. 中文分词（ik、pinying）\n6. [Curator](https://www.elastic.co/guide/en/elasticsearch/client/curator/current/about.html)\n\n## 3. 参数配置\n暂空（后补）\n\n### java优化配置\n(1)Heap不要超过系统可用内存的一半，并且不要超过32GB。\n\n(2) cluster集群jvm调优\n当时我们配置ES的JVM(Xms=Xmx=8G)的垃圾回收器主要是CMS,具体配置如下:\n\n```\n# reduce the per-thread stack size\nJAVA_OPTS=\"$JAVA_OPTS -Xss256k\"\n\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UseParNewGC\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UseConcMarkSweepGC\"\n\nJAVA_OPTS=\"$JAVA_OPTS -XX:CMSInitiatingOccupancyFraction=75\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UseCMSInitiatingOccupancyOnly\"\n```\n这块在官方说明中，特意强调了不建议替换java垃圾回收器，[官方并不推荐使用G1](https://www.elastic.co/guide/en/elasticsearch/guide/current/_don_8217_t_touch_these_settings.html#_garbage_collector)。\n\n[其他博文](https://www.geekhub.cn/a/1256.html)中有试过使用其他垃圾回收器。他的G1的具体配置如下:\n\n```\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UseG1GC \"\n#init_globals()末尾打印日志\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintFlagsFinal \"\n#打印gc引用\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintReferenceGC \"\n#输出虚拟机中GC的详细情况.\nJAVA_OPTS=\"$JAVA_OPTS -verbose:gc \"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintGCDetails \"\n#Enables printing of time stamps at every GC. By default, this option is disabled.\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintGCTimeStamps \"\n#Enables printing of information about adaptive generation sizing. By default, this option is disabled.\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintAdaptiveSizePolicy \"\n# unlocks diagnostic JVM options\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UnlockDiagnosticVMOptions \"\n#to measure where the time is spent\nJAVA_OPTS=\"$JAVA_OPTS -XX:+G1SummarizeConcMark \"\n#设置触发标记周期的 Java 堆占用率阈值。默认占用率是整个 Java 堆的 45%。\n#JAVA_OPTS=\"$JAVA_OPTS -XX:InitiatingHeapOccupancyPercent=45 \"\n```\n\n(3) elastic 开启jmx 监控\n有时候监控是必不可少的，所以在有条件的时候可以加上jmx监控\n\n```\n/usr/local/elastic/bin/elasticsearch.in.sh\nJMX_PORT=9305\nJAVA_OPTS=\"$JAVA_OPTS -Dcom.sun.management.jmxremote.port=$JMX_PORT\"\nJAVA_OPTS=\"$JAVA_OPTS -Dcom.sun.management.jmxremote.ssl=false\"\nJAVA_OPTS=\"$JAVA_OPTS -Dcom.sun.management.jmxremote.authenticate=false\"\nJAVA_OPTS=\"$JAVA_OPTS -Djava.rmi.server.hostname=xx.xx.xx..xx\"\n```\n\n### elasticsearch.yml\n这个是最重要的配置，只有在你明白之后在修改，之后我在单独写一篇文章介绍目前elasticsearch默认参数是如何影响系统的。\n\n目前配置包括以下几个部分：\n（1）cluster\n（2）节点node\n（3）log／data路径\n（4）内存\n（5）网络\n（5）发现Discovery\n（6）Gateway\n（7）其他变量\n\n```\n# ======================== Elasticsearch Configuration =========================\n#\n# NOTE: Elasticsearch comes with reasonable defaults for most settings.\n#       Before you set out to tweak and tune the configuration, make sure you\n#       understand what are you trying to accomplish and the consequences.\n#\n# The primary way of configuring a node is via this file. This template lists\n# the most important settings you may want to configure for a production cluster.\n#\n# Please see the documentation for further information on configuration options:\n# <https://www.elastic.co/guide/en/elasticsearch/reference/5.0/settings.html>\n#\n# ---------------------------------- Cluster -----------------------------------\n#\n# Use a descriptive name for your cluster:\n#\ncluster.name: elastic-pro\n#\n# ------------------------------------ Node ------------------------------------\n#\n# Use a descriptive name for the node:\n#\nnode.name: node-0\n#\n# Add custom attributes to the node:\n#\nnode.attr.rack: r1\n#\n# ----------------------------------- Paths ------------------------------------\n#\n# Path to directory where to store the data (separate multiple locations by comma):\n#\npath.data: /apps/home/worker/zhangxiaolong/data/index0\n#\n# Path to log files:\n#\npath.logs: /apps/home/worker/zhangxiaolong/data/log0\n#\n# ----------------------------------- Memory -----------------------------------\n#\n# Lock the memory on startup:\n#\nbootstrap.memory_lock: true\n#\n# Make sure that the heap size is set to about half the memory available\n# on the system and that the owner of the process is allowed to use this\n# limit.\n#\n# Elasticsearch performs poorly when the system is swapping the memory.\n#\n# ---------------------------------- Network -----------------------------------\n#\n# Set the bind address to a specific IP (IPv4 or IPv6):\n#\nnetwork.host: 172.16.7.1\n#\n# Set a custom port for HTTP:\n#\nhttp.port: 9201\n#\n# For more information, see the documentation at:\n# <https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-network.html>\n#\n# --------------------------------- Discovery ----------------------------------\n#\n# Pass an initial list of hosts to perform discovery when new node is started:\n#The default list of hosts is [\"127.0.0.1\", \"[::1]\"]\n#\ndiscovery.zen.ping.unicast.hosts: [\"172.16.7.1:9300\"]\n#\n# Prevent the \"split brain\" by configuring the majority of nodes (total number of nodes / 2 + 1):\n#\ndiscovery.zen.minimum_master_nodes: 2\n#\n# For more information, see the documentation at:\n# <https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-discovery-zen.html>\n#\n# ---------------------------------- Gateway -----------------------------------\n#\n# Block initial recovery after a full cluster restart until N nodes are started:\n#\ngateway.recover_after_nodes: 2\n#\n# For more information, see the documentation at:\n# <https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-gateway.html>\n#\n# ---------------------------------- Various -----------------------------------\n#\n# Require explicit names when deleting indices:\n#\n#action.destructive_requires_name: true\n```\n\n### 其他\n（1）线程池设置成内核数，比如八核机器就设置成8，很多阻塞的操作都是Lucene来操作的，比如硬盘读写。搜索的线程设置可以设置成内核数的三倍\n（2）内存交换\n这个对于性能影响是致命的，可以使用命令sudo swapoff -a来暂时关闭，永久关闭需要编辑文件/etc/fstab，也可以在配置文件中添加配置bootstrap.mlockall: true，这样jvm可以锁定这些内存，避免被交换到物理存储介质\n（3）其他\n\n- 如果你不需要近实时功能，则设置index的刷新时间；\n- 如果在进行一个大bulk导入，可以优先考虑设置副本数为0；\n- 如果在index中的doc你没有一个自然增长的id，可以使用Elasticsearch’s 的自动id做标示，如果有自己的id，尽量设计对lucene友好的id；\n\n## 4. Rolling Restarts & 备份数据 & 备份恢复 \n### Rolling Restarts\n一般下线一个node（升级、维修等），elasticsearch会进行rebalance操作，如果你是真正的下线一个node，这个操作是十分正确的，但是你知道这台node会之后重新加入到cluster中，则rebalance操作不恰当了，当shard比较大或者多的时候会严重耗费系统资源。\n\n那我们正确的操作是什么？\n\n``` shell\n1. 查看集群设置\ncurl -XGET http://10.10.160.129:9200/_cluster/settings\n\n2. 如果可能的话，停止正在索引的数据；\n\n3. 停止分片同步，阻止elasticsearch进行rebalance操作\nPUT /_cluster/settings\n{\n    \"transient\" : {\n        \"cluster.routing.allocation.enable\" : \"none\"\n    }\n}\n\n4.关闭单个node\n\n5.维护或者升级节点node\n\n6.重启node，确认加入cluster\n\n7.重新打开分片同步\nPUT /_cluster/settings\n{\n    \"transient\" : {\n        \"cluster.routing.allocation.enable\" : \"all\"\n    }\n}\n\n8.针对需要的node重复执行3-7操作\n\n9.到这里就重新恢复了cluster；\n```\n\n### 备份数据\n\n``` shell\n1. 先导入一些数据进行备份\ncurl -XPOST 'http://192.168.56.11:9200/bank/account/_bulk?pretty' --data-binary @accounts.json\ncurl -XPOST 'http://192.168.56.11:9200/shakespeare/_bulk?pretty' --data-binary @shakespeare.json\ncurl -XPOST 'http://192.168.56.11:9200/_bulk?pretty' --data-binary @logs.jsonl\n\n2. 使用API创建一个镜像仓库\ncurl -XPOST http://192.168.56.11:9200/_snapshot/my_backup -d '\n{\n    \"type\": \"fs\", \n    \"settings\": { \n        \"location\": \"/data/mount\"\n        \"compress\":  true \n    }\n}'\n## 解释：\n镜像仓库的名称：my_backup\n镜像仓库的类型：fs。还支持curl，hdfs等。\n镜像仓库的位置：/data/mount 。这个位置必须在配置文件中定义。\n是否启用压缩：compres：true 表示启用压缩。\n\n3. 备份前检查配置\n必须确定备份使用的目录在配置文件中声明了，否则会爆如下错误\n{\n  \"error\": {\n    \"root_cause\": [\n      {\n        \"type\": \"repository_exception\",\n        \"reason\": \"[test-bakcup] failed to create repository\"\n      }\n    ],\n    \"type\": \"repository_exception\",\n    \"reason\": \"[test-bakcup] failed to create repository\",\n    \"caused_by\": {\n      \"type\": \"creation_exception\",\n      \"reason\": \"Guice creation errors:\\n\\n1) Error injecting constructor, RepositoryException[[test-bakcup] location [/data/mount] doesn't match any of the locations specified by path.repo because this setting is empty]\\n  at org.elasticsearch.repositories.fs.FsRepository.<init>(Unknown Source)\\n  while locating org.elasticsearch.repositories.fs.FsRepository\\n  while locating org.elasticsearch.repositories.Repository\\n\\n1 error\",\n      \"caused_by\": {\n        \"type\": \"repository_exception\",\n        \"reason\": \"[test-bakcup] location [/data/mount] doesn't match any of the locations specified by path.repo because this setting is empty\"\n      }\n    }\n  },\n  \"status\": 500\n}\n\n4. 开始创建一个快照\n##在后头创建一个快照\ncurl -XPUT  http://192.168.56.20:9200/_snapshot/my_backup/snapshot_1 \n##也可以在前台运行。\ncurl -XPUT  http://192.168.56.11:9200/_snapshot/my_backup/snapshot_1?wait_for_completion=true\n##上面的参数会在my_backup仓库里创建一个snapshot_1 的快照。\n\n5. 可以选择相应的索引进行备份\ncurl -XPUT  http://192.168.56.20:9200/_snapshot/my_backup/snapshot_2 -d '\n{\n    \"indices\": \"bank,logstash-2015.05.18\"\n}'\n## 解释：\n创建一个snapshot_2的快照，只备份bank,logstash-2015.05.18这两个索引。\n\n6. 查看备份状态\n整个备份过程中，可以通过如下命令查看备份进度\n\ncurl -XGET http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_status\n主要由如下几种状态：\na. INITIALIZING 集群状态检查，检查当前集群是否可以做快照，通常这个过程会非常快\nb. STARTED 正在转移数据到仓库\nc. FINALIZING 数据转移完成，正在转移元信息\nd. DONE　完成\ne. FAILED 备份失败\n\n7. 取消备份\ncurl -XDELETE http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812\n\n8. 获取所有快照信息。\ncurl -XGET http://192.168.56.20:9200/_snapshot/my_backup/_all |python -mjson.tool\n##解释\n查看my_backup仓库下的所有快照。\n\n9. 手动删除快照\ncurl -XDELETE http://192.168.56.20:9200/_snapshot/my_backup/snapshot_2\n## 解释\n删除my_backup仓库下的snapshot_2的快照。\n\n```\n\n### 备份恢复\n\n``` json\n1. 恢复备份\ncurl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore\n同备份一样，也可以设置wait_for_completion=true等待恢复结果\n\ncurl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore?wait_for_completion=true\n默认情况下，是恢复所有的索引，我们也可以设置一些参数来指定恢复的索引，以及重命令恢复的索引，这样可以避免覆盖原有的数据.\n\ncurl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore\n{\n    \"indices\": \"index_1\",\n    \"rename_pattern\": \"index_(.+)\",\n    \"rename_replacement\": \"restored_index_$1\"\n}\n上面的indices, 表示只恢复索引’index_1’\nrename_pattern: 表示重命名索引以’index_’开头的索引.\nrename_replacement: 表示将所有的索引重命名为’restored_index_xxx’.如index_1会被重命名为restored_index_1.\n\n2. 查看所有索引的恢复进度\ncurl -XGET http://192.168.0.1:9200/_recovery/\n\n3. 查看索引restored_index_1的恢复进度\ncurl -XGET http://192.168.0.1:9200/_recovery/restored_index_1\n\n4. 取消恢复\n只需要删除索引，即可取消恢复\ncurl -XDELETE http://192.168.0.1:9200/restored_index_1\n```\n\n## 5. 性能优化\n在讲性能优化之前，首先要知道：\n\n\t过早的优化是万恶之源 Premature optimization is the root of all evil.\n\t\t\t\t\t\t\t\t\t\t                —— Donald Knuth\n\n`优化总是发生在目前的情况下不能满足当前的需求，其他我想不出什么理由去优化它。`\n\n`优化很多时候和业务是紧密关联的，优化业务可能比优化程序效率更高、成本更低！`\n\n### 索引性能优化\n索引性能（Index Performance），我们这样定义它，索引的速度是否提高，可以无缝的提供近实时的功能。\n什么时候会发生索引慢呢？\n（1）你读的慢（doc from db，file，inputstream等等）\n（2）你处理的慢（中文下的分词等）\n（3）你写的慢（还是老式的机械盘？！ 高性能的盘或者ssd）\n\n还有就是针对不同场景选择的判断，如果你索引的文件非常大，数量多，那应该选择elasticsearch提供的bulk接口，在create doc速度能跟上的时候，bulk 是可以提高速度的。\n\n### 查询性能优化\n查询性能（Query Perofrmance），说起来比索引更麻烦一些，面对的场景也更多一些；\n\n面对海量数据以及不同的集群，针对业务需求去查询往往会很慢，有什么策略可以搞定这种情况？有，那就是`routing`[Routing a Document to a Shard](https://www.elastic.co/guide/en/elasticsearch/guide/current/routing-value.html)、[_routing field](https://www.elastic.co/guide/en/elasticsearch/reference/5.1/mapping-routing-field.html).\n\n查询策略，分别查询vs合并查询？索引越来越大，单个 shard 也很巨大，查询速度也越来越慢。这时候，是选择分索引还是更多的shards？在实践过程中，更多的 shards 会带来额外的索引压力，即 IO 压力。我们选择了分索引。比如按照每个大分类一个索引，或者主要的大城市一个索引。然后将他们进行合并查询。\n\n索引越来越大，资源使用也越来越多。若是要进行更细的集群分配，大索引使用的资源成倍增加。有什么办法能减小索引？\n根据具体业务需求，减少某些大的索引，这是一个很好的办法，这样这个集群各方面占用的资源会有一定程度的下降，当让你要说这些少的索引怎么办，这些索引可以放在单独的集群中。\n\n## 应用性能优化 - [from youzan](http://tech.youzan.com/search-engine1/)\n一、使用应用级队列防止雪崩\nES一个问题是在高峰期时候极容易发生雪崩. ES有健全的线程池系统来保证并发与稳定性问题. 但是在流量突变的情况下(比如双十一秒杀)还是很容易发生瘫痪的现象, 主要的原因如下:\n\nES几乎为每类操作配置一个线程池; 只能保证每个线程池的资源使用时合理的, 当2个以上的线程池竞争资源时容易造成资源响应不过来.\n\nES没有考虑网络负载导致稳定的问题.\n\n在AS里我们实现了面向请求的全局队列来保证稳定性. 它主要做了3件事情.\n![](http://image.zhangxiaolong.org/mweb/14979525149331.png!medium)\n\n1. 根据业务把请求分成一个个slide, 每个slide对应一个队列. 默认一个应用就是一个slide, 一个应用也可以区分不同的slide, 这样可以保护一个应用内重要的查询.\n2. 每个队列配置一个队列长度, 默认为50.\n3. 每个队列计算这个队列的平均响应时间. 当队列平均响应时间超过200ms, 停止工作1s, 如果请求溢出就写入溢出日志留数据恢复使用. 如果连续10次队列平均响应时间超过500ms就报警, 以便工程师第一时间处理.\n\n二、自动降级\n应用级队列解决雪崩问题有点粗暴, 如果一个应用本身查询就非常慢, 很容易让一个应用持续超时很久. 我们根据搜索引擎的特点编写了自动降级功能.\n\n比如商品搜索的例子, 商品搜索最基本的功能是布尔查询, 但是还需要按照相关性分数和质量度排序等功能, 甚至还有个性化需求. 完成简单的布尔查询, ES使用bitsets操作就可以做到, 但是如果如果需要相关性分, 就必须使用倒排索引, 并有大量CPU消耗来计算分数. ES的bitsets比倒排索引快50倍左右.\n\n对于有降级方案的slide, AS在队列响应过慢时候直接使用降级query代替正常query. 这种方法让我们在不扩容的情况下成功度过了双十一的流量陡增.\n\n三、善用filtered query\n理解lucence filter工作原理对于写出高性能查询语句至关重要. 许多搜索性能优化都和filter的使用有关. filter使用bitsets进行布尔运算, quey使用倒排索引进行计算, 这是filter比query快的原因. bitsets的优势主要体现在: \n\n1. bitsetcache在内存里面, 永不消失(除非被LRU). \n2. bitsets利用CPU原生支持的位运算操作, 比倒排索引快个数量级 \n3. 多个bitsets的与运算也是非常的快(一个64位CPU可以同时计算64个DOC的与运算) \n4. bitsets 在内存的存储是独立于query的, 有很强的复用性 \n5. 如果一个bitset片段全是0, 计算会自动跳过这些片段, 让bitsets在数据稀疏情况下同样表现优于倒排索引.\n\n举个例子:\n``` java \nquery:bool:  \n    tag:'mac'\n    region:'beijing'\n    title: \"apple\"\n```\n\nlucence处理这个query的方式是在倒排索引中寻找这三个term的倒排链 ,并使用跳指针技术求交, 在运算过程中需要对每个doc进行算分. 实际上tag和region对于算分并没有作用, 他们充当是过滤器的作用.\n\n这就是过滤器使用场景, 它只存储存在和不存在两种状态. 如果我们把tag和region使用bitsets进行存储, 这样这两个过滤器可以一直都被缓存在内存里面, 这样会快很多. 另外tag和region之间的求交非常迅速, 因为64位机器可以时间一个CPU周期同时处理64个doc的位运算.\n\n一个lucence金科玉律是: 能用filter就用filter, 除非必须使用query(当且仅当你需要算分的时候).\n正确的写法为:\n\n``` java\nquery:  \n    filtered: \n        query:  \n             title: \"apple\" \n         filter:\n            tag:\"mac\"\n             region:\"beijing\"\n```\n四、其他\n\n1. 线上集群关闭分片自动均衡. 分片的自动均衡主要目的防止更新造成各个分片数据分布不均匀. 但是如果线上一个节点挂掉后, 很容易触发自动均衡, 一时间集群内部的数据移动占用所有带宽. 建议采用闲时定时均衡策略来保证数据的均匀.\n\n2. 尽可能延长refresh时间间隔. 为了确保实时索引es索引刷新时间间隔默认为1秒, 索引刷新会导致查询性能受影响, 在确保业务时效性保证的基础上可以适当延长refresh时间间隔保证查询的性能.\n\n3. 除非有必要把all字段去掉. 索引默认除了索引每个字段外, 还有额外创建一个all的字段, 保存所有文本, 去掉这个字段可以把索引大小降低50%.\n\n4. 创建索引时候, 尽可能把查询比较慢的索引和快的索引物理分离.\n\n##6. 参考（Reference）\n1. [elastic调优参考](http://www.cnblogs.com/guguli/p/5218297.html)\n2. [elastic监控](https://github.com/Wprosdocimo/Elasticsearch-zabbix)\n3. [Mastering Elasticsearch(中文版)](http://udn.yyuap.com/doc/mastering-elasticsearch/chapter-4/41_README.html)\n4. [ELK-权威指南](http://kibana.logstash.es/content/logstash/plugins/input/file.html)\n5. [Elasticsearch 权威指南](http://www.learnes.net/index.html)\n6. [elasticsearch 生产环境配置](http://www.biglittleant.cn/2016/12/01/elastic-study1/)\n7. [有赞搜索引擎实践(工程篇)](http://tech.youzan.com/search-engine1/)\n\n\n**[更新于2017-05-22 - v1.0 ]\n[更新于2017-09-26 - v1.01]**\n\n(完)\n\n","source":"_posts/elasticsearch_tec_book_v1.01.md","raw":"---\ntitle: elasticsearch 技术手册(持续更新版本) v1.01\nauthor: Atlas\nauthor_id: Atlas\ntags:\n  - search\ncategories:\n  - search\ndate: 2017-09-26 10:47:00\nenglish_title: elasticsearch_tec_book\ntoc: true\n---\n\n# elasticsearch技术手册 v1.01\n\n## 1. 基础\n本手册内容是基于`elasticsearch5+`版本。准确的说是5.0.1版本。\n### 1.概念\n集群（cluster）、节点（node）、索引（index）、分片（shards）、副本（replicas）；\nterm、tf-idf、boost等\n### 2. Elasticsearch features\n\n1. [Based in lucene, write in java]()\n2. [Realtime analytics]()\n3. [Full Text search engine]()\n4. [Distributed, easy to scale]()\n5. [High availability]()\n6. [Document oriented(json)]()\n7. [Schema free]()\n8. [Restful API, json over http]()\n9. [Open source:Apache License 6.0 (ES:5.x)]()\n10. [Plugins & Community support]()\n\n### 3. elasticsearch do what on lucene?\nElasticsearch 构建在lucene之上，提供json方式的rest api进行交互；\n\n1. Elasticsearch在lucene之上提供一个完整的分布式系统；\n2. Elasticsearch提供了一个分布式的抽象的数据结构；\n3. 提供了一些特性，例如线程池、队列、node/cluster监控api、数据监控api、以及集群管理等等；\n\n## 2. 生产环境\n### 1. 监控（Monitoring）\n对于已经初步部署完成的elasticsearch集群来说，接下来的集群监控就变的更重要了。集群的重要参数，比如集群状态，分片状态等是集群健康的体现。elasticsearch提供了很对的现成api供我们管理和监控cluster。\n其中，(1)marvel是一个很容易监控elasticsearch的工具。它可以整合大量的统计数据通过kibana。\n(2) cluster health\n### 2. 生产环境部署（Production Deploying）\n生产环境的部署有很多考究的地方，接下来我从以下三个方面来说。\n#### 运维部署考虑（硬件以及部署策略）\n（1）memory，elasticsearch是比较吃内存的，尤其像排序、聚合操作，所以保证足够的heap内存是重要的。如果对内存不够的话，会交换到系统的缓存，由于lucene的数据结构是disk-based的格式，这势必会影响搜索的性能；一般建议使用16g-64gRAM的机器。如果大于64g，则会出现[另外的一些问题](https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html)\n（2）cpus,和内存相比，搜索对cpu的要求不是特别高，一般使用多核cpu就行，比如2-8核的；\n（3）disk，硬盘的性能对搜索集群非常重要，磁盘的性能直接影响索引的构建和读写操作，很多时候是搜索的一个瓶颈。ssd硬盘是目前最好的方式，但是由于其价钱看看阿里云，是同样的`喜人`，所以看业务需要，力所能及吧，我们目前使用的是高性能磁盘（high-performance server disks, 15k RPM drives），可以满足业务需求。\n（4）network，一个快速稳定的网络环境对分布式系统非常的重要，低延迟、高带宽有利于节点间的交互以及分片的拷贝和恢复\n（5）其他，尽量避免使用小配置机器组合一个超大的集群，这样管理起来就是一个大坑\n#### 优化配置参数\n(1)Java Virtual Machine\n(2)Transport Client Versus Node Client\nvs:\nTransport Client 可以解耦你的应用和搜索服务，应用可以很快的创建和销毁连接；\nNode Client 可以和搜索服务保持一个持久连接，可以查看搜索的结构信息；\n(3)Important Configuration Changes\nelasticsearch配置文件有非常好的默认设置，都是在实际的工作环境中实践过的。当遇到性能问题的时候，更多的是需要考虑数据存储布局和添加更多的node（elasticsearch文档中特意说明了配置文件的重要性，不让随便更改，大多数情况下是正确的）。\n\n- name\n\n```\n1. Assign Names\ncluster.name: elasticsearch_production\nnode.name: elasticsearch_005_data\n\n2. Paths\npath.data: /path/to/data1,/path/to/data2 \n\n# Path to log files:\npath.logs: /path/to/logs\n\n# Path to where plugins are installed:\npath.plugins: /path/to/plugins\n\n```\n\n- minimum_master_nodes，这个参数是在配置文件中比较重要的一个，如果配置不对的话，会发生split brains（俗称“脑裂”），就是说会存在多个master节点，继而可能发生丢失data现象。这个参数的计算公式：(number of master-eligible nodes / 2) + 1，举例说明：\n\n\t- 假如你有10个node（可存储数据，可成为master），则设置为6；\n\t- 假如你有三个可选为master的节点，100+个数据节点，则设置为2；\n\t- 假如你有2个常规节点，这个值设置为2，但是如果丢失一个则会造成集群不可用，如果设置为1，则不能保证脑裂的不存在，最好的方法是保证最小的节点数为3.\n\n```\ndiscovery.zen.minimum_master_nodes: 2\n```\n因为elasticsearch是自适应的，节点随时添加或者下线，不过还好，有api我们可以实时调整这个参数，\n\n```\nPUT /_cluster/settings\n{\n    \"persistent\" : {\n        \"discovery.zen.minimum_master_nodes\" : 2\n    }\n}\n```\n\n- Recovery Settings\n恢复策略对elasticsearch是必不可少的，举例来说，假如现在集群（10 nodes）集体下线进行维修升级，当重新启动的时候，先启动了5 nodes，此时集群发现有5个node启动了，会执行shard的备份和交换，直到达到分片平衡，此时如果另外5 nodes加入到集群中，会发生什么呢？cluster会继续rebalance，新加入的节点发现数据集群中已经有了，首先删除本地数据，通知集群发动rebalance，平衡各个shards，这整个过程中shard会发生copy、sweap、delete等操作，耗费好多资源和时间，对一个大集群来说，耗费的更多，不可忍受。所以，elasticsearch有三个参数可以配置这些。\n\n```\ngateway.recover_after_nodes: 8   // 集群中恢复的节点数，就是说当改集群启动了8个几点，才尽兴rebalance\n\n// 这两项说明，本集群有10的node，当10个nodes都启动或者启动了8个node且超过5分钟后就会发起rebalance\ngateway.expected_nodes: 10\ngateway.recover_after_time: 5m\n```\n这些策略只和`整个cluster重启`时生效。\n\n- Prefer Unicast over Multicast\nelasticsearch建议使用单播的方式，虽然依然提供了多播的方式，但存在找不到master等尴尬的问题，不建议使用。\n\n```\ndiscovery.zen.ping.unicast.hosts: [\"host1\", \"host2:port\"]\n```\n（4）不要轻易修改的参数\n\n1. Garbage Collector\nelasticsearch中默认采用Concurrent-Mark and Sweep (CMS)的gc回收器；\n\n2. Threadpools\nelasticsearch中设置线程池非常合理的，如果没有特别情况下不要修改这个值\n\n```\nSearch gets a larger threadpool, and is configured to int((# of cores * 3) / 2) + 1\n```\n(5)Heap: Sizing and Swapping\n(6)File Descriptors and MMap\nelasticsearch混合使用nioFS和MMapFS。\n\n### 3. 插件\n1. 使用[head](https://github.com/mobz/elasticsearch-head)插件来查看索引数据\n2. 使用[kopf](https://github.com/lmenezes/elasticsearch-kopf)来备份集群节点\n3. 使用[bigdesk](https://github.com/lukas-vlcek/bigdesk)查看集群性能\n4. [elasticsearch-sql](https://github.com/NLPchina/elasticsearch-sql) 通过sql进行聚合检索, 可以将sql语句翻译成ES的JSON检索语句\n5. 中文分词（ik、pinying）\n6. [Curator](https://www.elastic.co/guide/en/elasticsearch/client/curator/current/about.html)\n\n## 3. 参数配置\n暂空（后补）\n\n### java优化配置\n(1)Heap不要超过系统可用内存的一半，并且不要超过32GB。\n\n(2) cluster集群jvm调优\n当时我们配置ES的JVM(Xms=Xmx=8G)的垃圾回收器主要是CMS,具体配置如下:\n\n```\n# reduce the per-thread stack size\nJAVA_OPTS=\"$JAVA_OPTS -Xss256k\"\n\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UseParNewGC\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UseConcMarkSweepGC\"\n\nJAVA_OPTS=\"$JAVA_OPTS -XX:CMSInitiatingOccupancyFraction=75\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UseCMSInitiatingOccupancyOnly\"\n```\n这块在官方说明中，特意强调了不建议替换java垃圾回收器，[官方并不推荐使用G1](https://www.elastic.co/guide/en/elasticsearch/guide/current/_don_8217_t_touch_these_settings.html#_garbage_collector)。\n\n[其他博文](https://www.geekhub.cn/a/1256.html)中有试过使用其他垃圾回收器。他的G1的具体配置如下:\n\n```\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UseG1GC \"\n#init_globals()末尾打印日志\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintFlagsFinal \"\n#打印gc引用\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintReferenceGC \"\n#输出虚拟机中GC的详细情况.\nJAVA_OPTS=\"$JAVA_OPTS -verbose:gc \"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintGCDetails \"\n#Enables printing of time stamps at every GC. By default, this option is disabled.\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintGCTimeStamps \"\n#Enables printing of information about adaptive generation sizing. By default, this option is disabled.\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintAdaptiveSizePolicy \"\n# unlocks diagnostic JVM options\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UnlockDiagnosticVMOptions \"\n#to measure where the time is spent\nJAVA_OPTS=\"$JAVA_OPTS -XX:+G1SummarizeConcMark \"\n#设置触发标记周期的 Java 堆占用率阈值。默认占用率是整个 Java 堆的 45%。\n#JAVA_OPTS=\"$JAVA_OPTS -XX:InitiatingHeapOccupancyPercent=45 \"\n```\n\n(3) elastic 开启jmx 监控\n有时候监控是必不可少的，所以在有条件的时候可以加上jmx监控\n\n```\n/usr/local/elastic/bin/elasticsearch.in.sh\nJMX_PORT=9305\nJAVA_OPTS=\"$JAVA_OPTS -Dcom.sun.management.jmxremote.port=$JMX_PORT\"\nJAVA_OPTS=\"$JAVA_OPTS -Dcom.sun.management.jmxremote.ssl=false\"\nJAVA_OPTS=\"$JAVA_OPTS -Dcom.sun.management.jmxremote.authenticate=false\"\nJAVA_OPTS=\"$JAVA_OPTS -Djava.rmi.server.hostname=xx.xx.xx..xx\"\n```\n\n### elasticsearch.yml\n这个是最重要的配置，只有在你明白之后在修改，之后我在单独写一篇文章介绍目前elasticsearch默认参数是如何影响系统的。\n\n目前配置包括以下几个部分：\n（1）cluster\n（2）节点node\n（3）log／data路径\n（4）内存\n（5）网络\n（5）发现Discovery\n（6）Gateway\n（7）其他变量\n\n```\n# ======================== Elasticsearch Configuration =========================\n#\n# NOTE: Elasticsearch comes with reasonable defaults for most settings.\n#       Before you set out to tweak and tune the configuration, make sure you\n#       understand what are you trying to accomplish and the consequences.\n#\n# The primary way of configuring a node is via this file. This template lists\n# the most important settings you may want to configure for a production cluster.\n#\n# Please see the documentation for further information on configuration options:\n# <https://www.elastic.co/guide/en/elasticsearch/reference/5.0/settings.html>\n#\n# ---------------------------------- Cluster -----------------------------------\n#\n# Use a descriptive name for your cluster:\n#\ncluster.name: elastic-pro\n#\n# ------------------------------------ Node ------------------------------------\n#\n# Use a descriptive name for the node:\n#\nnode.name: node-0\n#\n# Add custom attributes to the node:\n#\nnode.attr.rack: r1\n#\n# ----------------------------------- Paths ------------------------------------\n#\n# Path to directory where to store the data (separate multiple locations by comma):\n#\npath.data: /apps/home/worker/zhangxiaolong/data/index0\n#\n# Path to log files:\n#\npath.logs: /apps/home/worker/zhangxiaolong/data/log0\n#\n# ----------------------------------- Memory -----------------------------------\n#\n# Lock the memory on startup:\n#\nbootstrap.memory_lock: true\n#\n# Make sure that the heap size is set to about half the memory available\n# on the system and that the owner of the process is allowed to use this\n# limit.\n#\n# Elasticsearch performs poorly when the system is swapping the memory.\n#\n# ---------------------------------- Network -----------------------------------\n#\n# Set the bind address to a specific IP (IPv4 or IPv6):\n#\nnetwork.host: 172.16.7.1\n#\n# Set a custom port for HTTP:\n#\nhttp.port: 9201\n#\n# For more information, see the documentation at:\n# <https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-network.html>\n#\n# --------------------------------- Discovery ----------------------------------\n#\n# Pass an initial list of hosts to perform discovery when new node is started:\n#The default list of hosts is [\"127.0.0.1\", \"[::1]\"]\n#\ndiscovery.zen.ping.unicast.hosts: [\"172.16.7.1:9300\"]\n#\n# Prevent the \"split brain\" by configuring the majority of nodes (total number of nodes / 2 + 1):\n#\ndiscovery.zen.minimum_master_nodes: 2\n#\n# For more information, see the documentation at:\n# <https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-discovery-zen.html>\n#\n# ---------------------------------- Gateway -----------------------------------\n#\n# Block initial recovery after a full cluster restart until N nodes are started:\n#\ngateway.recover_after_nodes: 2\n#\n# For more information, see the documentation at:\n# <https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-gateway.html>\n#\n# ---------------------------------- Various -----------------------------------\n#\n# Require explicit names when deleting indices:\n#\n#action.destructive_requires_name: true\n```\n\n### 其他\n（1）线程池设置成内核数，比如八核机器就设置成8，很多阻塞的操作都是Lucene来操作的，比如硬盘读写。搜索的线程设置可以设置成内核数的三倍\n（2）内存交换\n这个对于性能影响是致命的，可以使用命令sudo swapoff -a来暂时关闭，永久关闭需要编辑文件/etc/fstab，也可以在配置文件中添加配置bootstrap.mlockall: true，这样jvm可以锁定这些内存，避免被交换到物理存储介质\n（3）其他\n\n- 如果你不需要近实时功能，则设置index的刷新时间；\n- 如果在进行一个大bulk导入，可以优先考虑设置副本数为0；\n- 如果在index中的doc你没有一个自然增长的id，可以使用Elasticsearch’s 的自动id做标示，如果有自己的id，尽量设计对lucene友好的id；\n\n## 4. Rolling Restarts & 备份数据 & 备份恢复 \n### Rolling Restarts\n一般下线一个node（升级、维修等），elasticsearch会进行rebalance操作，如果你是真正的下线一个node，这个操作是十分正确的，但是你知道这台node会之后重新加入到cluster中，则rebalance操作不恰当了，当shard比较大或者多的时候会严重耗费系统资源。\n\n那我们正确的操作是什么？\n\n``` shell\n1. 查看集群设置\ncurl -XGET http://10.10.160.129:9200/_cluster/settings\n\n2. 如果可能的话，停止正在索引的数据；\n\n3. 停止分片同步，阻止elasticsearch进行rebalance操作\nPUT /_cluster/settings\n{\n    \"transient\" : {\n        \"cluster.routing.allocation.enable\" : \"none\"\n    }\n}\n\n4.关闭单个node\n\n5.维护或者升级节点node\n\n6.重启node，确认加入cluster\n\n7.重新打开分片同步\nPUT /_cluster/settings\n{\n    \"transient\" : {\n        \"cluster.routing.allocation.enable\" : \"all\"\n    }\n}\n\n8.针对需要的node重复执行3-7操作\n\n9.到这里就重新恢复了cluster；\n```\n\n### 备份数据\n\n``` shell\n1. 先导入一些数据进行备份\ncurl -XPOST 'http://192.168.56.11:9200/bank/account/_bulk?pretty' --data-binary @accounts.json\ncurl -XPOST 'http://192.168.56.11:9200/shakespeare/_bulk?pretty' --data-binary @shakespeare.json\ncurl -XPOST 'http://192.168.56.11:9200/_bulk?pretty' --data-binary @logs.jsonl\n\n2. 使用API创建一个镜像仓库\ncurl -XPOST http://192.168.56.11:9200/_snapshot/my_backup -d '\n{\n    \"type\": \"fs\", \n    \"settings\": { \n        \"location\": \"/data/mount\"\n        \"compress\":  true \n    }\n}'\n## 解释：\n镜像仓库的名称：my_backup\n镜像仓库的类型：fs。还支持curl，hdfs等。\n镜像仓库的位置：/data/mount 。这个位置必须在配置文件中定义。\n是否启用压缩：compres：true 表示启用压缩。\n\n3. 备份前检查配置\n必须确定备份使用的目录在配置文件中声明了，否则会爆如下错误\n{\n  \"error\": {\n    \"root_cause\": [\n      {\n        \"type\": \"repository_exception\",\n        \"reason\": \"[test-bakcup] failed to create repository\"\n      }\n    ],\n    \"type\": \"repository_exception\",\n    \"reason\": \"[test-bakcup] failed to create repository\",\n    \"caused_by\": {\n      \"type\": \"creation_exception\",\n      \"reason\": \"Guice creation errors:\\n\\n1) Error injecting constructor, RepositoryException[[test-bakcup] location [/data/mount] doesn't match any of the locations specified by path.repo because this setting is empty]\\n  at org.elasticsearch.repositories.fs.FsRepository.<init>(Unknown Source)\\n  while locating org.elasticsearch.repositories.fs.FsRepository\\n  while locating org.elasticsearch.repositories.Repository\\n\\n1 error\",\n      \"caused_by\": {\n        \"type\": \"repository_exception\",\n        \"reason\": \"[test-bakcup] location [/data/mount] doesn't match any of the locations specified by path.repo because this setting is empty\"\n      }\n    }\n  },\n  \"status\": 500\n}\n\n4. 开始创建一个快照\n##在后头创建一个快照\ncurl -XPUT  http://192.168.56.20:9200/_snapshot/my_backup/snapshot_1 \n##也可以在前台运行。\ncurl -XPUT  http://192.168.56.11:9200/_snapshot/my_backup/snapshot_1?wait_for_completion=true\n##上面的参数会在my_backup仓库里创建一个snapshot_1 的快照。\n\n5. 可以选择相应的索引进行备份\ncurl -XPUT  http://192.168.56.20:9200/_snapshot/my_backup/snapshot_2 -d '\n{\n    \"indices\": \"bank,logstash-2015.05.18\"\n}'\n## 解释：\n创建一个snapshot_2的快照，只备份bank,logstash-2015.05.18这两个索引。\n\n6. 查看备份状态\n整个备份过程中，可以通过如下命令查看备份进度\n\ncurl -XGET http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_status\n主要由如下几种状态：\na. INITIALIZING 集群状态检查，检查当前集群是否可以做快照，通常这个过程会非常快\nb. STARTED 正在转移数据到仓库\nc. FINALIZING 数据转移完成，正在转移元信息\nd. DONE　完成\ne. FAILED 备份失败\n\n7. 取消备份\ncurl -XDELETE http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812\n\n8. 获取所有快照信息。\ncurl -XGET http://192.168.56.20:9200/_snapshot/my_backup/_all |python -mjson.tool\n##解释\n查看my_backup仓库下的所有快照。\n\n9. 手动删除快照\ncurl -XDELETE http://192.168.56.20:9200/_snapshot/my_backup/snapshot_2\n## 解释\n删除my_backup仓库下的snapshot_2的快照。\n\n```\n\n### 备份恢复\n\n``` json\n1. 恢复备份\ncurl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore\n同备份一样，也可以设置wait_for_completion=true等待恢复结果\n\ncurl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore?wait_for_completion=true\n默认情况下，是恢复所有的索引，我们也可以设置一些参数来指定恢复的索引，以及重命令恢复的索引，这样可以避免覆盖原有的数据.\n\ncurl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore\n{\n    \"indices\": \"index_1\",\n    \"rename_pattern\": \"index_(.+)\",\n    \"rename_replacement\": \"restored_index_$1\"\n}\n上面的indices, 表示只恢复索引’index_1’\nrename_pattern: 表示重命名索引以’index_’开头的索引.\nrename_replacement: 表示将所有的索引重命名为’restored_index_xxx’.如index_1会被重命名为restored_index_1.\n\n2. 查看所有索引的恢复进度\ncurl -XGET http://192.168.0.1:9200/_recovery/\n\n3. 查看索引restored_index_1的恢复进度\ncurl -XGET http://192.168.0.1:9200/_recovery/restored_index_1\n\n4. 取消恢复\n只需要删除索引，即可取消恢复\ncurl -XDELETE http://192.168.0.1:9200/restored_index_1\n```\n\n## 5. 性能优化\n在讲性能优化之前，首先要知道：\n\n\t过早的优化是万恶之源 Premature optimization is the root of all evil.\n\t\t\t\t\t\t\t\t\t\t                —— Donald Knuth\n\n`优化总是发生在目前的情况下不能满足当前的需求，其他我想不出什么理由去优化它。`\n\n`优化很多时候和业务是紧密关联的，优化业务可能比优化程序效率更高、成本更低！`\n\n### 索引性能优化\n索引性能（Index Performance），我们这样定义它，索引的速度是否提高，可以无缝的提供近实时的功能。\n什么时候会发生索引慢呢？\n（1）你读的慢（doc from db，file，inputstream等等）\n（2）你处理的慢（中文下的分词等）\n（3）你写的慢（还是老式的机械盘？！ 高性能的盘或者ssd）\n\n还有就是针对不同场景选择的判断，如果你索引的文件非常大，数量多，那应该选择elasticsearch提供的bulk接口，在create doc速度能跟上的时候，bulk 是可以提高速度的。\n\n### 查询性能优化\n查询性能（Query Perofrmance），说起来比索引更麻烦一些，面对的场景也更多一些；\n\n面对海量数据以及不同的集群，针对业务需求去查询往往会很慢，有什么策略可以搞定这种情况？有，那就是`routing`[Routing a Document to a Shard](https://www.elastic.co/guide/en/elasticsearch/guide/current/routing-value.html)、[_routing field](https://www.elastic.co/guide/en/elasticsearch/reference/5.1/mapping-routing-field.html).\n\n查询策略，分别查询vs合并查询？索引越来越大，单个 shard 也很巨大，查询速度也越来越慢。这时候，是选择分索引还是更多的shards？在实践过程中，更多的 shards 会带来额外的索引压力，即 IO 压力。我们选择了分索引。比如按照每个大分类一个索引，或者主要的大城市一个索引。然后将他们进行合并查询。\n\n索引越来越大，资源使用也越来越多。若是要进行更细的集群分配，大索引使用的资源成倍增加。有什么办法能减小索引？\n根据具体业务需求，减少某些大的索引，这是一个很好的办法，这样这个集群各方面占用的资源会有一定程度的下降，当让你要说这些少的索引怎么办，这些索引可以放在单独的集群中。\n\n## 应用性能优化 - [from youzan](http://tech.youzan.com/search-engine1/)\n一、使用应用级队列防止雪崩\nES一个问题是在高峰期时候极容易发生雪崩. ES有健全的线程池系统来保证并发与稳定性问题. 但是在流量突变的情况下(比如双十一秒杀)还是很容易发生瘫痪的现象, 主要的原因如下:\n\nES几乎为每类操作配置一个线程池; 只能保证每个线程池的资源使用时合理的, 当2个以上的线程池竞争资源时容易造成资源响应不过来.\n\nES没有考虑网络负载导致稳定的问题.\n\n在AS里我们实现了面向请求的全局队列来保证稳定性. 它主要做了3件事情.\n![](http://image.zhangxiaolong.org/mweb/14979525149331.png!medium)\n\n1. 根据业务把请求分成一个个slide, 每个slide对应一个队列. 默认一个应用就是一个slide, 一个应用也可以区分不同的slide, 这样可以保护一个应用内重要的查询.\n2. 每个队列配置一个队列长度, 默认为50.\n3. 每个队列计算这个队列的平均响应时间. 当队列平均响应时间超过200ms, 停止工作1s, 如果请求溢出就写入溢出日志留数据恢复使用. 如果连续10次队列平均响应时间超过500ms就报警, 以便工程师第一时间处理.\n\n二、自动降级\n应用级队列解决雪崩问题有点粗暴, 如果一个应用本身查询就非常慢, 很容易让一个应用持续超时很久. 我们根据搜索引擎的特点编写了自动降级功能.\n\n比如商品搜索的例子, 商品搜索最基本的功能是布尔查询, 但是还需要按照相关性分数和质量度排序等功能, 甚至还有个性化需求. 完成简单的布尔查询, ES使用bitsets操作就可以做到, 但是如果如果需要相关性分, 就必须使用倒排索引, 并有大量CPU消耗来计算分数. ES的bitsets比倒排索引快50倍左右.\n\n对于有降级方案的slide, AS在队列响应过慢时候直接使用降级query代替正常query. 这种方法让我们在不扩容的情况下成功度过了双十一的流量陡增.\n\n三、善用filtered query\n理解lucence filter工作原理对于写出高性能查询语句至关重要. 许多搜索性能优化都和filter的使用有关. filter使用bitsets进行布尔运算, quey使用倒排索引进行计算, 这是filter比query快的原因. bitsets的优势主要体现在: \n\n1. bitsetcache在内存里面, 永不消失(除非被LRU). \n2. bitsets利用CPU原生支持的位运算操作, 比倒排索引快个数量级 \n3. 多个bitsets的与运算也是非常的快(一个64位CPU可以同时计算64个DOC的与运算) \n4. bitsets 在内存的存储是独立于query的, 有很强的复用性 \n5. 如果一个bitset片段全是0, 计算会自动跳过这些片段, 让bitsets在数据稀疏情况下同样表现优于倒排索引.\n\n举个例子:\n``` java \nquery:bool:  \n    tag:'mac'\n    region:'beijing'\n    title: \"apple\"\n```\n\nlucence处理这个query的方式是在倒排索引中寻找这三个term的倒排链 ,并使用跳指针技术求交, 在运算过程中需要对每个doc进行算分. 实际上tag和region对于算分并没有作用, 他们充当是过滤器的作用.\n\n这就是过滤器使用场景, 它只存储存在和不存在两种状态. 如果我们把tag和region使用bitsets进行存储, 这样这两个过滤器可以一直都被缓存在内存里面, 这样会快很多. 另外tag和region之间的求交非常迅速, 因为64位机器可以时间一个CPU周期同时处理64个doc的位运算.\n\n一个lucence金科玉律是: 能用filter就用filter, 除非必须使用query(当且仅当你需要算分的时候).\n正确的写法为:\n\n``` java\nquery:  \n    filtered: \n        query:  \n             title: \"apple\" \n         filter:\n            tag:\"mac\"\n             region:\"beijing\"\n```\n四、其他\n\n1. 线上集群关闭分片自动均衡. 分片的自动均衡主要目的防止更新造成各个分片数据分布不均匀. 但是如果线上一个节点挂掉后, 很容易触发自动均衡, 一时间集群内部的数据移动占用所有带宽. 建议采用闲时定时均衡策略来保证数据的均匀.\n\n2. 尽可能延长refresh时间间隔. 为了确保实时索引es索引刷新时间间隔默认为1秒, 索引刷新会导致查询性能受影响, 在确保业务时效性保证的基础上可以适当延长refresh时间间隔保证查询的性能.\n\n3. 除非有必要把all字段去掉. 索引默认除了索引每个字段外, 还有额外创建一个all的字段, 保存所有文本, 去掉这个字段可以把索引大小降低50%.\n\n4. 创建索引时候, 尽可能把查询比较慢的索引和快的索引物理分离.\n\n##6. 参考（Reference）\n1. [elastic调优参考](http://www.cnblogs.com/guguli/p/5218297.html)\n2. [elastic监控](https://github.com/Wprosdocimo/Elasticsearch-zabbix)\n3. [Mastering Elasticsearch(中文版)](http://udn.yyuap.com/doc/mastering-elasticsearch/chapter-4/41_README.html)\n4. [ELK-权威指南](http://kibana.logstash.es/content/logstash/plugins/input/file.html)\n5. [Elasticsearch 权威指南](http://www.learnes.net/index.html)\n6. [elasticsearch 生产环境配置](http://www.biglittleant.cn/2016/12/01/elastic-study1/)\n7. [有赞搜索引擎实践(工程篇)](http://tech.youzan.com/search-engine1/)\n\n\n**[更新于2017-05-22 - v1.0 ]\n[更新于2017-09-26 - v1.01]**\n\n(完)\n\n","slug":"elasticsearch_tec_book_v1.01","published":1,"updated":"2017-09-30T09:35:55.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj8pb1nnn0003q9s6yppsqwkc","content":"<h1 id=\"elasticsearch技术手册-v1-01\"><a href=\"#elasticsearch技术手册-v1-01\" class=\"headerlink\" title=\"elasticsearch技术手册 v1.01\"></a>elasticsearch技术手册 v1.01</h1><h2 id=\"1-基础\"><a href=\"#1-基础\" class=\"headerlink\" title=\"1. 基础\"></a>1. 基础</h2><p>本手册内容是基于<code>elasticsearch5+</code>版本。准确的说是5.0.1版本。</p>\n<h3 id=\"1-概念\"><a href=\"#1-概念\" class=\"headerlink\" title=\"1.概念\"></a>1.概念</h3><p>集群（cluster）、节点（node）、索引（index）、分片（shards）、副本（replicas）；<br>term、tf-idf、boost等</p>\n<h3 id=\"2-Elasticsearch-features\"><a href=\"#2-Elasticsearch-features\" class=\"headerlink\" title=\"2. Elasticsearch features\"></a>2. Elasticsearch features</h3><ol>\n<li><a href=\"\">Based in lucene, write in java</a></li>\n<li><a href=\"\">Realtime analytics</a></li>\n<li><a href=\"\">Full Text search engine</a></li>\n<li><a href=\"\">Distributed, easy to scale</a></li>\n<li><a href=\"\">High availability</a></li>\n<li><a href=\"\">Document oriented(json)</a></li>\n<li><a href=\"\">Schema free</a></li>\n<li><a href=\"\">Restful API, json over http</a></li>\n<li><a href=\"\">Open source:Apache License 6.0 (ES:5.x)</a></li>\n<li><a href=\"\">Plugins &amp; Community support</a></li>\n</ol>\n<h3 id=\"3-elasticsearch-do-what-on-lucene\"><a href=\"#3-elasticsearch-do-what-on-lucene\" class=\"headerlink\" title=\"3. elasticsearch do what on lucene?\"></a>3. elasticsearch do what on lucene?</h3><p>Elasticsearch 构建在lucene之上，提供json方式的rest api进行交互；</p>\n<ol>\n<li>Elasticsearch在lucene之上提供一个完整的分布式系统；</li>\n<li>Elasticsearch提供了一个分布式的抽象的数据结构；</li>\n<li>提供了一些特性，例如线程池、队列、node/cluster监控api、数据监控api、以及集群管理等等；</li>\n</ol>\n<h2 id=\"2-生产环境\"><a href=\"#2-生产环境\" class=\"headerlink\" title=\"2. 生产环境\"></a>2. 生产环境</h2><h3 id=\"1-监控（Monitoring）\"><a href=\"#1-监控（Monitoring）\" class=\"headerlink\" title=\"1. 监控（Monitoring）\"></a>1. 监控（Monitoring）</h3><p>对于已经初步部署完成的elasticsearch集群来说，接下来的集群监控就变的更重要了。集群的重要参数，比如集群状态，分片状态等是集群健康的体现。elasticsearch提供了很对的现成api供我们管理和监控cluster。<br>其中，(1)marvel是一个很容易监控elasticsearch的工具。它可以整合大量的统计数据通过kibana。<br>(2) cluster health</p>\n<h3 id=\"2-生产环境部署（Production-Deploying）\"><a href=\"#2-生产环境部署（Production-Deploying）\" class=\"headerlink\" title=\"2. 生产环境部署（Production Deploying）\"></a>2. 生产环境部署（Production Deploying）</h3><p>生产环境的部署有很多考究的地方，接下来我从以下三个方面来说。</p>\n<h4 id=\"运维部署考虑（硬件以及部署策略）\"><a href=\"#运维部署考虑（硬件以及部署策略）\" class=\"headerlink\" title=\"运维部署考虑（硬件以及部署策略）\"></a>运维部署考虑（硬件以及部署策略）</h4><p>（1）memory，elasticsearch是比较吃内存的，尤其像排序、聚合操作，所以保证足够的heap内存是重要的。如果对内存不够的话，会交换到系统的缓存，由于lucene的数据结构是disk-based的格式，这势必会影响搜索的性能；一般建议使用16g-64gRAM的机器。如果大于64g，则会出现<a href=\"https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html\" target=\"_blank\" rel=\"external\">另外的一些问题</a><br>（2）cpus,和内存相比，搜索对cpu的要求不是特别高，一般使用多核cpu就行，比如2-8核的；<br>（3）disk，硬盘的性能对搜索集群非常重要，磁盘的性能直接影响索引的构建和读写操作，很多时候是搜索的一个瓶颈。ssd硬盘是目前最好的方式，但是由于其价钱看看阿里云，是同样的<code>喜人</code>，所以看业务需要，力所能及吧，我们目前使用的是高性能磁盘（high-performance server disks, 15k RPM drives），可以满足业务需求。<br>（4）network，一个快速稳定的网络环境对分布式系统非常的重要，低延迟、高带宽有利于节点间的交互以及分片的拷贝和恢复<br>（5）其他，尽量避免使用小配置机器组合一个超大的集群，这样管理起来就是一个大坑</p>\n<h4 id=\"优化配置参数\"><a href=\"#优化配置参数\" class=\"headerlink\" title=\"优化配置参数\"></a>优化配置参数</h4><p>(1)Java Virtual Machine<br>(2)Transport Client Versus Node Client<br>vs:<br>Transport Client 可以解耦你的应用和搜索服务，应用可以很快的创建和销毁连接；<br>Node Client 可以和搜索服务保持一个持久连接，可以查看搜索的结构信息；<br>(3)Important Configuration Changes<br>elasticsearch配置文件有非常好的默认设置，都是在实际的工作环境中实践过的。当遇到性能问题的时候，更多的是需要考虑数据存储布局和添加更多的node（elasticsearch文档中特意说明了配置文件的重要性，不让随便更改，大多数情况下是正确的）。</p>\n<ul>\n<li>name</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">1. Assign Names</div><div class=\"line\">cluster.name: elasticsearch_production</div><div class=\"line\">node.name: elasticsearch_005_data</div><div class=\"line\"></div><div class=\"line\">2. Paths</div><div class=\"line\">path.data: /path/to/data1,/path/to/data2 </div><div class=\"line\"></div><div class=\"line\"># Path to log files:</div><div class=\"line\">path.logs: /path/to/logs</div><div class=\"line\"></div><div class=\"line\"># Path to where plugins are installed:</div><div class=\"line\">path.plugins: /path/to/plugins</div></pre></td></tr></table></figure>\n<ul>\n<li><p>minimum_master_nodes，这个参数是在配置文件中比较重要的一个，如果配置不对的话，会发生split brains（俗称“脑裂”），就是说会存在多个master节点，继而可能发生丢失data现象。这个参数的计算公式：(number of master-eligible nodes / 2) + 1，举例说明：</p>\n<ul>\n<li>假如你有10个node（可存储数据，可成为master），则设置为6；</li>\n<li>假如你有三个可选为master的节点，100+个数据节点，则设置为2；</li>\n<li>假如你有2个常规节点，这个值设置为2，但是如果丢失一个则会造成集群不可用，如果设置为1，则不能保证脑裂的不存在，最好的方法是保证最小的节点数为3.</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">discovery.zen.minimum_master_nodes: 2</div></pre></td></tr></table></figure>\n<p>因为elasticsearch是自适应的，节点随时添加或者下线，不过还好，有api我们可以实时调整这个参数，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">PUT /_cluster/settings</div><div class=\"line\">&#123;</div><div class=\"line\">    &quot;persistent&quot; : &#123;</div><div class=\"line\">        &quot;discovery.zen.minimum_master_nodes&quot; : 2</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<ul>\n<li>Recovery Settings<br>恢复策略对elasticsearch是必不可少的，举例来说，假如现在集群（10 nodes）集体下线进行维修升级，当重新启动的时候，先启动了5 nodes，此时集群发现有5个node启动了，会执行shard的备份和交换，直到达到分片平衡，此时如果另外5 nodes加入到集群中，会发生什么呢？cluster会继续rebalance，新加入的节点发现数据集群中已经有了，首先删除本地数据，通知集群发动rebalance，平衡各个shards，这整个过程中shard会发生copy、sweap、delete等操作，耗费好多资源和时间，对一个大集群来说，耗费的更多，不可忍受。所以，elasticsearch有三个参数可以配置这些。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">gateway.recover_after_nodes: 8   // 集群中恢复的节点数，就是说当改集群启动了8个几点，才尽兴rebalance</div><div class=\"line\"></div><div class=\"line\">// 这两项说明，本集群有10的node，当10个nodes都启动或者启动了8个node且超过5分钟后就会发起rebalance</div><div class=\"line\">gateway.expected_nodes: 10</div><div class=\"line\">gateway.recover_after_time: 5m</div></pre></td></tr></table></figure>\n<p>这些策略只和<code>整个cluster重启</code>时生效。</p>\n<ul>\n<li>Prefer Unicast over Multicast<br>elasticsearch建议使用单播的方式，虽然依然提供了多播的方式，但存在找不到master等尴尬的问题，不建议使用。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">discovery.zen.ping.unicast.hosts: [&quot;host1&quot;, &quot;host2:port&quot;]</div></pre></td></tr></table></figure>\n<p>（4）不要轻易修改的参数</p>\n<ol>\n<li><p>Garbage Collector<br>elasticsearch中默认采用Concurrent-Mark and Sweep (CMS)的gc回收器；</p>\n</li>\n<li><p>Threadpools<br>elasticsearch中设置线程池非常合理的，如果没有特别情况下不要修改这个值</p>\n</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">Search gets a larger threadpool, and is configured to int((# of cores * 3) / 2) + 1</div></pre></td></tr></table></figure>\n<p>(5)Heap: Sizing and Swapping<br>(6)File Descriptors and MMap<br>elasticsearch混合使用nioFS和MMapFS。</p>\n<h3 id=\"3-插件\"><a href=\"#3-插件\" class=\"headerlink\" title=\"3. 插件\"></a>3. 插件</h3><ol>\n<li>使用<a href=\"https://github.com/mobz/elasticsearch-head\" target=\"_blank\" rel=\"external\">head</a>插件来查看索引数据</li>\n<li>使用<a href=\"https://github.com/lmenezes/elasticsearch-kopf\" target=\"_blank\" rel=\"external\">kopf</a>来备份集群节点</li>\n<li>使用<a href=\"https://github.com/lukas-vlcek/bigdesk\" target=\"_blank\" rel=\"external\">bigdesk</a>查看集群性能</li>\n<li><a href=\"https://github.com/NLPchina/elasticsearch-sql\" target=\"_blank\" rel=\"external\">elasticsearch-sql</a> 通过sql进行聚合检索, 可以将sql语句翻译成ES的JSON检索语句</li>\n<li>中文分词（ik、pinying）</li>\n<li><a href=\"https://www.elastic.co/guide/en/elasticsearch/client/curator/current/about.html\" target=\"_blank\" rel=\"external\">Curator</a></li>\n</ol>\n<h2 id=\"3-参数配置\"><a href=\"#3-参数配置\" class=\"headerlink\" title=\"3. 参数配置\"></a>3. 参数配置</h2><p>暂空（后补）</p>\n<h3 id=\"java优化配置\"><a href=\"#java优化配置\" class=\"headerlink\" title=\"java优化配置\"></a>java优化配置</h3><p>(1)Heap不要超过系统可用内存的一半，并且不要超过32GB。</p>\n<p>(2) cluster集群jvm调优<br>当时我们配置ES的JVM(Xms=Xmx=8G)的垃圾回收器主要是CMS,具体配置如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"># reduce the per-thread stack size</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -Xss256k&quot;</div><div class=\"line\"></div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UseParNewGC&quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UseConcMarkSweepGC&quot;</div><div class=\"line\"></div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:CMSInitiatingOccupancyFraction=75&quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UseCMSInitiatingOccupancyOnly&quot;</div></pre></td></tr></table></figure>\n<p>这块在官方说明中，特意强调了不建议替换java垃圾回收器，<a href=\"https://www.elastic.co/guide/en/elasticsearch/guide/current/_don_8217_t_touch_these_settings.html#_garbage_collector\" target=\"_blank\" rel=\"external\">官方并不推荐使用G1</a>。</p>\n<p><a href=\"https://www.geekhub.cn/a/1256.html\" target=\"_blank\" rel=\"external\">其他博文</a>中有试过使用其他垃圾回收器。他的G1的具体配置如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UseG1GC &quot;</div><div class=\"line\">#init_globals()末尾打印日志</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintFlagsFinal &quot;</div><div class=\"line\">#打印gc引用</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintReferenceGC &quot;</div><div class=\"line\">#输出虚拟机中GC的详细情况.</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -verbose:gc &quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintGCDetails &quot;</div><div class=\"line\">#Enables printing of time stamps at every GC. By default, this option is disabled.</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintGCTimeStamps &quot;</div><div class=\"line\">#Enables printing of information about adaptive generation sizing. By default, this option is disabled.</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintAdaptiveSizePolicy &quot;</div><div class=\"line\"># unlocks diagnostic JVM options</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UnlockDiagnosticVMOptions &quot;</div><div class=\"line\">#to measure where the time is spent</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+G1SummarizeConcMark &quot;</div><div class=\"line\">#设置触发标记周期的 Java 堆占用率阈值。默认占用率是整个 Java 堆的 45%。</div><div class=\"line\">#JAVA_OPTS=&quot;$JAVA_OPTS -XX:InitiatingHeapOccupancyPercent=45 &quot;</div></pre></td></tr></table></figure>\n<p>(3) elastic 开启jmx 监控<br>有时候监控是必不可少的，所以在有条件的时候可以加上jmx监控</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">/usr/local/elastic/bin/elasticsearch.in.sh</div><div class=\"line\">JMX_PORT=9305</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -Dcom.sun.management.jmxremote.port=$JMX_PORT&quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -Dcom.sun.management.jmxremote.ssl=false&quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -Dcom.sun.management.jmxremote.authenticate=false&quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -Djava.rmi.server.hostname=xx.xx.xx..xx&quot;</div></pre></td></tr></table></figure>\n<h3 id=\"elasticsearch-yml\"><a href=\"#elasticsearch-yml\" class=\"headerlink\" title=\"elasticsearch.yml\"></a>elasticsearch.yml</h3><p>这个是最重要的配置，只有在你明白之后在修改，之后我在单独写一篇文章介绍目前elasticsearch默认参数是如何影响系统的。</p>\n<p>目前配置包括以下几个部分：<br>（1）cluster<br>（2）节点node<br>（3）log／data路径<br>（4）内存<br>（5）网络<br>（5）发现Discovery<br>（6）Gateway<br>（7）其他变量</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div></pre></td><td class=\"code\"><pre><div class=\"line\"># ======================== Elasticsearch Configuration =========================</div><div class=\"line\">#</div><div class=\"line\"># NOTE: Elasticsearch comes with reasonable defaults for most settings.</div><div class=\"line\">#       Before you set out to tweak and tune the configuration, make sure you</div><div class=\"line\">#       understand what are you trying to accomplish and the consequences.</div><div class=\"line\">#</div><div class=\"line\"># The primary way of configuring a node is via this file. This template lists</div><div class=\"line\"># the most important settings you may want to configure for a production cluster.</div><div class=\"line\">#</div><div class=\"line\"># Please see the documentation for further information on configuration options:</div><div class=\"line\"># &lt;https://www.elastic.co/guide/en/elasticsearch/reference/5.0/settings.html&gt;</div><div class=\"line\">#</div><div class=\"line\"># ---------------------------------- Cluster -----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Use a descriptive name for your cluster:</div><div class=\"line\">#</div><div class=\"line\">cluster.name: elastic-pro</div><div class=\"line\">#</div><div class=\"line\"># ------------------------------------ Node ------------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Use a descriptive name for the node:</div><div class=\"line\">#</div><div class=\"line\">node.name: node-0</div><div class=\"line\">#</div><div class=\"line\"># Add custom attributes to the node:</div><div class=\"line\">#</div><div class=\"line\">node.attr.rack: r1</div><div class=\"line\">#</div><div class=\"line\"># ----------------------------------- Paths ------------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Path to directory where to store the data (separate multiple locations by comma):</div><div class=\"line\">#</div><div class=\"line\">path.data: /apps/home/worker/zhangxiaolong/data/index0</div><div class=\"line\">#</div><div class=\"line\"># Path to log files:</div><div class=\"line\">#</div><div class=\"line\">path.logs: /apps/home/worker/zhangxiaolong/data/log0</div><div class=\"line\">#</div><div class=\"line\"># ----------------------------------- Memory -----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Lock the memory on startup:</div><div class=\"line\">#</div><div class=\"line\">bootstrap.memory_lock: true</div><div class=\"line\">#</div><div class=\"line\"># Make sure that the heap size is set to about half the memory available</div><div class=\"line\"># on the system and that the owner of the process is allowed to use this</div><div class=\"line\"># limit.</div><div class=\"line\">#</div><div class=\"line\"># Elasticsearch performs poorly when the system is swapping the memory.</div><div class=\"line\">#</div><div class=\"line\"># ---------------------------------- Network -----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Set the bind address to a specific IP (IPv4 or IPv6):</div><div class=\"line\">#</div><div class=\"line\">network.host: 172.16.7.1</div><div class=\"line\">#</div><div class=\"line\"># Set a custom port for HTTP:</div><div class=\"line\">#</div><div class=\"line\">http.port: 9201</div><div class=\"line\">#</div><div class=\"line\"># For more information, see the documentation at:</div><div class=\"line\"># &lt;https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-network.html&gt;</div><div class=\"line\">#</div><div class=\"line\"># --------------------------------- Discovery ----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Pass an initial list of hosts to perform discovery when new node is started:</div><div class=\"line\">#The default list of hosts is [&quot;127.0.0.1&quot;, &quot;[::1]&quot;]</div><div class=\"line\">#</div><div class=\"line\">discovery.zen.ping.unicast.hosts: [&quot;172.16.7.1:9300&quot;]</div><div class=\"line\">#</div><div class=\"line\"># Prevent the &quot;split brain&quot; by configuring the majority of nodes (total number of nodes / 2 + 1):</div><div class=\"line\">#</div><div class=\"line\">discovery.zen.minimum_master_nodes: 2</div><div class=\"line\">#</div><div class=\"line\"># For more information, see the documentation at:</div><div class=\"line\"># &lt;https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-discovery-zen.html&gt;</div><div class=\"line\">#</div><div class=\"line\"># ---------------------------------- Gateway -----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Block initial recovery after a full cluster restart until N nodes are started:</div><div class=\"line\">#</div><div class=\"line\">gateway.recover_after_nodes: 2</div><div class=\"line\">#</div><div class=\"line\"># For more information, see the documentation at:</div><div class=\"line\"># &lt;https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-gateway.html&gt;</div><div class=\"line\">#</div><div class=\"line\"># ---------------------------------- Various -----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Require explicit names when deleting indices:</div><div class=\"line\">#</div><div class=\"line\">#action.destructive_requires_name: true</div></pre></td></tr></table></figure>\n<h3 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h3><p>（1）线程池设置成内核数，比如八核机器就设置成8，很多阻塞的操作都是Lucene来操作的，比如硬盘读写。搜索的线程设置可以设置成内核数的三倍<br>（2）内存交换<br>这个对于性能影响是致命的，可以使用命令sudo swapoff -a来暂时关闭，永久关闭需要编辑文件/etc/fstab，也可以在配置文件中添加配置bootstrap.mlockall: true，这样jvm可以锁定这些内存，避免被交换到物理存储介质<br>（3）其他</p>\n<ul>\n<li>如果你不需要近实时功能，则设置index的刷新时间；</li>\n<li>如果在进行一个大bulk导入，可以优先考虑设置副本数为0；</li>\n<li>如果在index中的doc你没有一个自然增长的id，可以使用Elasticsearch’s 的自动id做标示，如果有自己的id，尽量设计对lucene友好的id；</li>\n</ul>\n<h2 id=\"4-Rolling-Restarts-amp-备份数据-amp-备份恢复\"><a href=\"#4-Rolling-Restarts-amp-备份数据-amp-备份恢复\" class=\"headerlink\" title=\"4. Rolling Restarts &amp; 备份数据 &amp; 备份恢复\"></a>4. Rolling Restarts &amp; 备份数据 &amp; 备份恢复</h2><h3 id=\"Rolling-Restarts\"><a href=\"#Rolling-Restarts\" class=\"headerlink\" title=\"Rolling Restarts\"></a>Rolling Restarts</h3><p>一般下线一个node（升级、维修等），elasticsearch会进行rebalance操作，如果你是真正的下线一个node，这个操作是十分正确的，但是你知道这台node会之后重新加入到cluster中，则rebalance操作不恰当了，当shard比较大或者多的时候会严重耗费系统资源。</p>\n<p>那我们正确的操作是什么？</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div></pre></td><td class=\"code\"><pre><div class=\"line\">1. 查看集群设置</div><div class=\"line\">curl -XGET http://10.10.160.129:9200/_cluster/settings</div><div class=\"line\"></div><div class=\"line\">2. 如果可能的话，停止正在索引的数据；</div><div class=\"line\"></div><div class=\"line\">3. 停止分片同步，阻止elasticsearch进行rebalance操作</div><div class=\"line\">PUT /_cluster/settings</div><div class=\"line\">&#123;</div><div class=\"line\">    \"transient\" : &#123;</div><div class=\"line\">        \"cluster.routing.allocation.enable\" : \"none\"</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">4.关闭单个node</div><div class=\"line\"></div><div class=\"line\">5.维护或者升级节点node</div><div class=\"line\"></div><div class=\"line\">6.重启node，确认加入cluster</div><div class=\"line\"></div><div class=\"line\">7.重新打开分片同步</div><div class=\"line\">PUT /_cluster/settings</div><div class=\"line\">&#123;</div><div class=\"line\">    \"transient\" : &#123;</div><div class=\"line\">        \"cluster.routing.allocation.enable\" : \"all\"</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">8.针对需要的node重复执行3-7操作</div><div class=\"line\"></div><div class=\"line\">9.到这里就重新恢复了cluster；</div></pre></td></tr></table></figure>\n<h3 id=\"备份数据\"><a href=\"#备份数据\" class=\"headerlink\" title=\"备份数据\"></a>备份数据</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div></pre></td><td class=\"code\"><pre><div class=\"line\">1. 先导入一些数据进行备份</div><div class=\"line\">curl -XPOST 'http://192.168.56.11:9200/bank/account/_bulk?pretty' --data-binary @accounts.json</div><div class=\"line\">curl -XPOST 'http://192.168.56.11:9200/shakespeare/_bulk?pretty' --data-binary @shakespeare.json</div><div class=\"line\">curl -XPOST 'http://192.168.56.11:9200/_bulk?pretty' --data-binary @logs.jsonl</div><div class=\"line\"></div><div class=\"line\">2. 使用API创建一个镜像仓库</div><div class=\"line\">curl -XPOST http://192.168.56.11:9200/_snapshot/my_backup -d '</div><div class=\"line\">&#123;</div><div class=\"line\">    \"type\": \"fs\", </div><div class=\"line\">    \"settings\": &#123; </div><div class=\"line\">        \"location\": \"/data/mount\"</div><div class=\"line\">        \"compress\":  true </div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;'</div><div class=\"line\"><span class=\"meta\">#</span># 解释：</div><div class=\"line\">镜像仓库的名称：my_backup</div><div class=\"line\">镜像仓库的类型：fs。还支持curl，hdfs等。</div><div class=\"line\">镜像仓库的位置：/data/mount 。这个位置必须在配置文件中定义。</div><div class=\"line\">是否启用压缩：compres：true 表示启用压缩。</div><div class=\"line\"></div><div class=\"line\">3. 备份前检查配置</div><div class=\"line\">必须确定备份使用的目录在配置文件中声明了，否则会爆如下错误</div><div class=\"line\">&#123;</div><div class=\"line\">  \"error\": &#123;</div><div class=\"line\">    \"root_cause\": [</div><div class=\"line\">      &#123;</div><div class=\"line\">        \"type\": \"repository_exception\",</div><div class=\"line\">        \"reason\": \"[test-bakcup] failed to create repository\"</div><div class=\"line\">      &#125;</div><div class=\"line\">    ],</div><div class=\"line\">    \"type\": \"repository_exception\",</div><div class=\"line\">    \"reason\": \"[test-bakcup] failed to create repository\",</div><div class=\"line\">    \"caused_by\": &#123;</div><div class=\"line\">      \"type\": \"creation_exception\",</div><div class=\"line\">      \"reason\": \"Guice creation errors:\\n\\n1) Error injecting constructor, RepositoryException[[test-bakcup] location [/data/mount] doesn't match any of the locations specified by path.repo because this setting is empty]\\n  at org.elasticsearch.repositories.fs.FsRepository.&lt;init&gt;(Unknown Source)\\n  while locating org.elasticsearch.repositories.fs.FsRepository\\n  while locating org.elasticsearch.repositories.Repository\\n\\n1 error\",</div><div class=\"line\">      \"caused_by\": &#123;</div><div class=\"line\">        \"type\": \"repository_exception\",</div><div class=\"line\">        \"reason\": \"[test-bakcup] location [/data/mount] doesn't match any of the locations specified by path.repo because this setting is empty\"</div><div class=\"line\">      &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;,</div><div class=\"line\">  \"status\": 500</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">4. 开始创建一个快照</div><div class=\"line\"><span class=\"meta\">#</span>#在后头创建一个快照</div><div class=\"line\">curl -XPUT  http://192.168.56.20:9200/_snapshot/my_backup/snapshot_1 </div><div class=\"line\"><span class=\"meta\">#</span>#也可以在前台运行。</div><div class=\"line\">curl -XPUT  http://192.168.56.11:9200/_snapshot/my_backup/snapshot_1?wait_for_completion=true</div><div class=\"line\"><span class=\"meta\">#</span>#上面的参数会在my_backup仓库里创建一个snapshot_1 的快照。</div><div class=\"line\"></div><div class=\"line\">5. 可以选择相应的索引进行备份</div><div class=\"line\">curl -XPUT  http://192.168.56.20:9200/_snapshot/my_backup/snapshot_2 -d '</div><div class=\"line\">&#123;</div><div class=\"line\">    \"indices\": \"bank,logstash-2015.05.18\"</div><div class=\"line\">&#125;'</div><div class=\"line\"><span class=\"meta\">#</span># 解释：</div><div class=\"line\">创建一个snapshot_2的快照，只备份bank,logstash-2015.05.18这两个索引。</div><div class=\"line\"></div><div class=\"line\">6. 查看备份状态</div><div class=\"line\">整个备份过程中，可以通过如下命令查看备份进度</div><div class=\"line\"></div><div class=\"line\">curl -XGET http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_status</div><div class=\"line\">主要由如下几种状态：</div><div class=\"line\">a. INITIALIZING 集群状态检查，检查当前集群是否可以做快照，通常这个过程会非常快</div><div class=\"line\">b. STARTED 正在转移数据到仓库</div><div class=\"line\">c. FINALIZING 数据转移完成，正在转移元信息</div><div class=\"line\">d. DONE　完成</div><div class=\"line\">e. FAILED 备份失败</div><div class=\"line\"></div><div class=\"line\">7. 取消备份</div><div class=\"line\">curl -XDELETE http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812</div><div class=\"line\"></div><div class=\"line\">8. 获取所有快照信息。</div><div class=\"line\">curl -XGET http://192.168.56.20:9200/_snapshot/my_backup/_all |python -mjson.tool</div><div class=\"line\"><span class=\"meta\">#</span>#解释</div><div class=\"line\">查看my_backup仓库下的所有快照。</div><div class=\"line\"></div><div class=\"line\">9. 手动删除快照</div><div class=\"line\">curl -XDELETE http://192.168.56.20:9200/_snapshot/my_backup/snapshot_2</div><div class=\"line\"><span class=\"meta\">#</span># 解释</div><div class=\"line\">删除my_backup仓库下的snapshot_2的快照。</div></pre></td></tr></table></figure>\n<h3 id=\"备份恢复\"><a href=\"#备份恢复\" class=\"headerlink\" title=\"备份恢复\"></a>备份恢复</h3><figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div></pre></td><td class=\"code\"><pre><div class=\"line\">1. 恢复备份</div><div class=\"line\">curl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore</div><div class=\"line\">同备份一样，也可以设置wait_for_completion=true等待恢复结果</div><div class=\"line\"></div><div class=\"line\">curl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore?wait_for_completion=true</div><div class=\"line\">默认情况下，是恢复所有的索引，我们也可以设置一些参数来指定恢复的索引，以及重命令恢复的索引，这样可以避免覆盖原有的数据.</div><div class=\"line\"></div><div class=\"line\">curl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore</div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"attr\">\"indices\"</span>: <span class=\"string\">\"index_1\"</span>,</div><div class=\"line\">    <span class=\"attr\">\"rename_pattern\"</span>: <span class=\"string\">\"index_(.+)\"</span>,</div><div class=\"line\">    <span class=\"attr\">\"rename_replacement\"</span>: <span class=\"string\">\"restored_index_$1\"</span></div><div class=\"line\">&#125;</div><div class=\"line\">上面的indices, 表示只恢复索引’index_1’</div><div class=\"line\">rename_pattern: 表示重命名索引以’index_’开头的索引.</div><div class=\"line\">rename_replacement: 表示将所有的索引重命名为’restored_index_xxx’.如index_1会被重命名为restored_index_1.</div><div class=\"line\"></div><div class=\"line\">2. 查看所有索引的恢复进度</div><div class=\"line\">curl -XGET http://192.168.0.1:9200/_recovery/</div><div class=\"line\"></div><div class=\"line\">3. 查看索引restored_index_1的恢复进度</div><div class=\"line\">curl -XGET http://192.168.0.1:9200/_recovery/restored_index_1</div><div class=\"line\"></div><div class=\"line\">4. 取消恢复</div><div class=\"line\">只需要删除索引，即可取消恢复</div><div class=\"line\">curl -XDELETE http://192.168.0.1:9200/restored_index_1</div></pre></td></tr></table></figure>\n<h2 id=\"5-性能优化\"><a href=\"#5-性能优化\" class=\"headerlink\" title=\"5. 性能优化\"></a>5. 性能优化</h2><p>在讲性能优化之前，首先要知道：</p>\n<pre><code>过早的优化是万恶之源 Premature optimization is the root of all evil.\n                                                    —— Donald Knuth\n</code></pre><p><code>优化总是发生在目前的情况下不能满足当前的需求，其他我想不出什么理由去优化它。</code></p>\n<p><code>优化很多时候和业务是紧密关联的，优化业务可能比优化程序效率更高、成本更低！</code></p>\n<h3 id=\"索引性能优化\"><a href=\"#索引性能优化\" class=\"headerlink\" title=\"索引性能优化\"></a>索引性能优化</h3><p>索引性能（Index Performance），我们这样定义它，索引的速度是否提高，可以无缝的提供近实时的功能。<br>什么时候会发生索引慢呢？<br>（1）你读的慢（doc from db，file，inputstream等等）<br>（2）你处理的慢（中文下的分词等）<br>（3）你写的慢（还是老式的机械盘？！ 高性能的盘或者ssd）</p>\n<p>还有就是针对不同场景选择的判断，如果你索引的文件非常大，数量多，那应该选择elasticsearch提供的bulk接口，在create doc速度能跟上的时候，bulk 是可以提高速度的。</p>\n<h3 id=\"查询性能优化\"><a href=\"#查询性能优化\" class=\"headerlink\" title=\"查询性能优化\"></a>查询性能优化</h3><p>查询性能（Query Perofrmance），说起来比索引更麻烦一些，面对的场景也更多一些；</p>\n<p>面对海量数据以及不同的集群，针对业务需求去查询往往会很慢，有什么策略可以搞定这种情况？有，那就是<code>routing</code><a href=\"https://www.elastic.co/guide/en/elasticsearch/guide/current/routing-value.html\" target=\"_blank\" rel=\"external\">Routing a Document to a Shard</a>、<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/5.1/mapping-routing-field.html\" target=\"_blank\" rel=\"external\">_routing field</a>.</p>\n<p>查询策略，分别查询vs合并查询？索引越来越大，单个 shard 也很巨大，查询速度也越来越慢。这时候，是选择分索引还是更多的shards？在实践过程中，更多的 shards 会带来额外的索引压力，即 IO 压力。我们选择了分索引。比如按照每个大分类一个索引，或者主要的大城市一个索引。然后将他们进行合并查询。</p>\n<p>索引越来越大，资源使用也越来越多。若是要进行更细的集群分配，大索引使用的资源成倍增加。有什么办法能减小索引？<br>根据具体业务需求，减少某些大的索引，这是一个很好的办法，这样这个集群各方面占用的资源会有一定程度的下降，当让你要说这些少的索引怎么办，这些索引可以放在单独的集群中。</p>\n<h2 id=\"应用性能优化-from-youzan\"><a href=\"#应用性能优化-from-youzan\" class=\"headerlink\" title=\"应用性能优化 - from youzan\"></a>应用性能优化 - <a href=\"http://tech.youzan.com/search-engine1/\" target=\"_blank\" rel=\"external\">from youzan</a></h2><p>一、使用应用级队列防止雪崩<br>ES一个问题是在高峰期时候极容易发生雪崩. ES有健全的线程池系统来保证并发与稳定性问题. 但是在流量突变的情况下(比如双十一秒杀)还是很容易发生瘫痪的现象, 主要的原因如下:</p>\n<p>ES几乎为每类操作配置一个线程池; 只能保证每个线程池的资源使用时合理的, 当2个以上的线程池竞争资源时容易造成资源响应不过来.</p>\n<p>ES没有考虑网络负载导致稳定的问题.</p>\n<p>在AS里我们实现了面向请求的全局队列来保证稳定性. 它主要做了3件事情.<br><img src=\"http://image.zhangxiaolong.org/mweb/14979525149331.png!medium\" alt=\"\"></p>\n<ol>\n<li>根据业务把请求分成一个个slide, 每个slide对应一个队列. 默认一个应用就是一个slide, 一个应用也可以区分不同的slide, 这样可以保护一个应用内重要的查询.</li>\n<li>每个队列配置一个队列长度, 默认为50.</li>\n<li>每个队列计算这个队列的平均响应时间. 当队列平均响应时间超过200ms, 停止工作1s, 如果请求溢出就写入溢出日志留数据恢复使用. 如果连续10次队列平均响应时间超过500ms就报警, 以便工程师第一时间处理.</li>\n</ol>\n<p>二、自动降级<br>应用级队列解决雪崩问题有点粗暴, 如果一个应用本身查询就非常慢, 很容易让一个应用持续超时很久. 我们根据搜索引擎的特点编写了自动降级功能.</p>\n<p>比如商品搜索的例子, 商品搜索最基本的功能是布尔查询, 但是还需要按照相关性分数和质量度排序等功能, 甚至还有个性化需求. 完成简单的布尔查询, ES使用bitsets操作就可以做到, 但是如果如果需要相关性分, 就必须使用倒排索引, 并有大量CPU消耗来计算分数. ES的bitsets比倒排索引快50倍左右.</p>\n<p>对于有降级方案的slide, AS在队列响应过慢时候直接使用降级query代替正常query. 这种方法让我们在不扩容的情况下成功度过了双十一的流量陡增.</p>\n<p>三、善用filtered query<br>理解lucence filter工作原理对于写出高性能查询语句至关重要. 许多搜索性能优化都和filter的使用有关. filter使用bitsets进行布尔运算, quey使用倒排索引进行计算, 这是filter比query快的原因. bitsets的优势主要体现在: </p>\n<ol>\n<li>bitsetcache在内存里面, 永不消失(除非被LRU). </li>\n<li>bitsets利用CPU原生支持的位运算操作, 比倒排索引快个数量级 </li>\n<li>多个bitsets的与运算也是非常的快(一个64位CPU可以同时计算64个DOC的与运算) </li>\n<li>bitsets 在内存的存储是独立于query的, 有很强的复用性 </li>\n<li>如果一个bitset片段全是0, 计算会自动跳过这些片段, 让bitsets在数据稀疏情况下同样表现优于倒排索引.</li>\n</ol>\n<p>举个例子:<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">query:bool:  </div><div class=\"line\">    tag:<span class=\"string\">'mac'</span></div><div class=\"line\">    region:<span class=\"string\">'beijing'</span></div><div class=\"line\">    title: <span class=\"string\">\"apple\"</span></div></pre></td></tr></table></figure></p>\n<p>lucence处理这个query的方式是在倒排索引中寻找这三个term的倒排链 ,并使用跳指针技术求交, 在运算过程中需要对每个doc进行算分. 实际上tag和region对于算分并没有作用, 他们充当是过滤器的作用.</p>\n<p>这就是过滤器使用场景, 它只存储存在和不存在两种状态. 如果我们把tag和region使用bitsets进行存储, 这样这两个过滤器可以一直都被缓存在内存里面, 这样会快很多. 另外tag和region之间的求交非常迅速, 因为64位机器可以时间一个CPU周期同时处理64个doc的位运算.</p>\n<p>一个lucence金科玉律是: 能用filter就用filter, 除非必须使用query(当且仅当你需要算分的时候).<br>正确的写法为:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">query:  </div><div class=\"line\">    filtered: </div><div class=\"line\">        query:  </div><div class=\"line\">             title: <span class=\"string\">\"apple\"</span> </div><div class=\"line\">         filter:</div><div class=\"line\">            tag:<span class=\"string\">\"mac\"</span></div><div class=\"line\">             region:<span class=\"string\">\"beijing\"</span></div></pre></td></tr></table></figure>\n<p>四、其他</p>\n<ol>\n<li><p>线上集群关闭分片自动均衡. 分片的自动均衡主要目的防止更新造成各个分片数据分布不均匀. 但是如果线上一个节点挂掉后, 很容易触发自动均衡, 一时间集群内部的数据移动占用所有带宽. 建议采用闲时定时均衡策略来保证数据的均匀.</p>\n</li>\n<li><p>尽可能延长refresh时间间隔. 为了确保实时索引es索引刷新时间间隔默认为1秒, 索引刷新会导致查询性能受影响, 在确保业务时效性保证的基础上可以适当延长refresh时间间隔保证查询的性能.</p>\n</li>\n<li><p>除非有必要把all字段去掉. 索引默认除了索引每个字段外, 还有额外创建一个all的字段, 保存所有文本, 去掉这个字段可以把索引大小降低50%.</p>\n</li>\n<li><p>创建索引时候, 尽可能把查询比较慢的索引和快的索引物理分离.</p>\n</li>\n</ol>\n<p>##6. 参考（Reference）</p>\n<ol>\n<li><a href=\"http://www.cnblogs.com/guguli/p/5218297.html\" target=\"_blank\" rel=\"external\">elastic调优参考</a></li>\n<li><a href=\"https://github.com/Wprosdocimo/Elasticsearch-zabbix\" target=\"_blank\" rel=\"external\">elastic监控</a></li>\n<li><a href=\"http://udn.yyuap.com/doc/mastering-elasticsearch/chapter-4/41_README.html\" target=\"_blank\" rel=\"external\">Mastering Elasticsearch(中文版)</a></li>\n<li><a href=\"http://kibana.logstash.es/content/logstash/plugins/input/file.html\" target=\"_blank\" rel=\"external\">ELK-权威指南</a></li>\n<li><a href=\"http://www.learnes.net/index.html\" target=\"_blank\" rel=\"external\">Elasticsearch 权威指南</a></li>\n<li><a href=\"http://www.biglittleant.cn/2016/12/01/elastic-study1/\" target=\"_blank\" rel=\"external\">elasticsearch 生产环境配置</a></li>\n<li><a href=\"http://tech.youzan.com/search-engine1/\" target=\"_blank\" rel=\"external\">有赞搜索引擎实践(工程篇)</a></li>\n</ol>\n<p><strong>[更新于2017-05-22 - v1.0 ]<br>[更新于2017-09-26 - v1.01]</strong></p>\n<p>(完)</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"elasticsearch技术手册-v1-01\"><a href=\"#elasticsearch技术手册-v1-01\" class=\"headerlink\" title=\"elasticsearch技术手册 v1.01\"></a>elasticsearch技术手册 v1.01</h1><h2 id=\"1-基础\"><a href=\"#1-基础\" class=\"headerlink\" title=\"1. 基础\"></a>1. 基础</h2><p>本手册内容是基于<code>elasticsearch5+</code>版本。准确的说是5.0.1版本。</p>\n<h3 id=\"1-概念\"><a href=\"#1-概念\" class=\"headerlink\" title=\"1.概念\"></a>1.概念</h3><p>集群（cluster）、节点（node）、索引（index）、分片（shards）、副本（replicas）；<br>term、tf-idf、boost等</p>\n<h3 id=\"2-Elasticsearch-features\"><a href=\"#2-Elasticsearch-features\" class=\"headerlink\" title=\"2. Elasticsearch features\"></a>2. Elasticsearch features</h3><ol>\n<li><a href=\"\">Based in lucene, write in java</a></li>\n<li><a href=\"\">Realtime analytics</a></li>\n<li><a href=\"\">Full Text search engine</a></li>\n<li><a href=\"\">Distributed, easy to scale</a></li>\n<li><a href=\"\">High availability</a></li>\n<li><a href=\"\">Document oriented(json)</a></li>\n<li><a href=\"\">Schema free</a></li>\n<li><a href=\"\">Restful API, json over http</a></li>\n<li><a href=\"\">Open source:Apache License 6.0 (ES:5.x)</a></li>\n<li><a href=\"\">Plugins &amp; Community support</a></li>\n</ol>\n<h3 id=\"3-elasticsearch-do-what-on-lucene\"><a href=\"#3-elasticsearch-do-what-on-lucene\" class=\"headerlink\" title=\"3. elasticsearch do what on lucene?\"></a>3. elasticsearch do what on lucene?</h3><p>Elasticsearch 构建在lucene之上，提供json方式的rest api进行交互；</p>\n<ol>\n<li>Elasticsearch在lucene之上提供一个完整的分布式系统；</li>\n<li>Elasticsearch提供了一个分布式的抽象的数据结构；</li>\n<li>提供了一些特性，例如线程池、队列、node/cluster监控api、数据监控api、以及集群管理等等；</li>\n</ol>\n<h2 id=\"2-生产环境\"><a href=\"#2-生产环境\" class=\"headerlink\" title=\"2. 生产环境\"></a>2. 生产环境</h2><h3 id=\"1-监控（Monitoring）\"><a href=\"#1-监控（Monitoring）\" class=\"headerlink\" title=\"1. 监控（Monitoring）\"></a>1. 监控（Monitoring）</h3><p>对于已经初步部署完成的elasticsearch集群来说，接下来的集群监控就变的更重要了。集群的重要参数，比如集群状态，分片状态等是集群健康的体现。elasticsearch提供了很对的现成api供我们管理和监控cluster。<br>其中，(1)marvel是一个很容易监控elasticsearch的工具。它可以整合大量的统计数据通过kibana。<br>(2) cluster health</p>\n<h3 id=\"2-生产环境部署（Production-Deploying）\"><a href=\"#2-生产环境部署（Production-Deploying）\" class=\"headerlink\" title=\"2. 生产环境部署（Production Deploying）\"></a>2. 生产环境部署（Production Deploying）</h3><p>生产环境的部署有很多考究的地方，接下来我从以下三个方面来说。</p>\n<h4 id=\"运维部署考虑（硬件以及部署策略）\"><a href=\"#运维部署考虑（硬件以及部署策略）\" class=\"headerlink\" title=\"运维部署考虑（硬件以及部署策略）\"></a>运维部署考虑（硬件以及部署策略）</h4><p>（1）memory，elasticsearch是比较吃内存的，尤其像排序、聚合操作，所以保证足够的heap内存是重要的。如果对内存不够的话，会交换到系统的缓存，由于lucene的数据结构是disk-based的格式，这势必会影响搜索的性能；一般建议使用16g-64gRAM的机器。如果大于64g，则会出现<a href=\"https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html\" target=\"_blank\" rel=\"external\">另外的一些问题</a><br>（2）cpus,和内存相比，搜索对cpu的要求不是特别高，一般使用多核cpu就行，比如2-8核的；<br>（3）disk，硬盘的性能对搜索集群非常重要，磁盘的性能直接影响索引的构建和读写操作，很多时候是搜索的一个瓶颈。ssd硬盘是目前最好的方式，但是由于其价钱看看阿里云，是同样的<code>喜人</code>，所以看业务需要，力所能及吧，我们目前使用的是高性能磁盘（high-performance server disks, 15k RPM drives），可以满足业务需求。<br>（4）network，一个快速稳定的网络环境对分布式系统非常的重要，低延迟、高带宽有利于节点间的交互以及分片的拷贝和恢复<br>（5）其他，尽量避免使用小配置机器组合一个超大的集群，这样管理起来就是一个大坑</p>\n<h4 id=\"优化配置参数\"><a href=\"#优化配置参数\" class=\"headerlink\" title=\"优化配置参数\"></a>优化配置参数</h4><p>(1)Java Virtual Machine<br>(2)Transport Client Versus Node Client<br>vs:<br>Transport Client 可以解耦你的应用和搜索服务，应用可以很快的创建和销毁连接；<br>Node Client 可以和搜索服务保持一个持久连接，可以查看搜索的结构信息；<br>(3)Important Configuration Changes<br>elasticsearch配置文件有非常好的默认设置，都是在实际的工作环境中实践过的。当遇到性能问题的时候，更多的是需要考虑数据存储布局和添加更多的node（elasticsearch文档中特意说明了配置文件的重要性，不让随便更改，大多数情况下是正确的）。</p>\n<ul>\n<li>name</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">1. Assign Names</div><div class=\"line\">cluster.name: elasticsearch_production</div><div class=\"line\">node.name: elasticsearch_005_data</div><div class=\"line\"></div><div class=\"line\">2. Paths</div><div class=\"line\">path.data: /path/to/data1,/path/to/data2 </div><div class=\"line\"></div><div class=\"line\"># Path to log files:</div><div class=\"line\">path.logs: /path/to/logs</div><div class=\"line\"></div><div class=\"line\"># Path to where plugins are installed:</div><div class=\"line\">path.plugins: /path/to/plugins</div></pre></td></tr></table></figure>\n<ul>\n<li><p>minimum_master_nodes，这个参数是在配置文件中比较重要的一个，如果配置不对的话，会发生split brains（俗称“脑裂”），就是说会存在多个master节点，继而可能发生丢失data现象。这个参数的计算公式：(number of master-eligible nodes / 2) + 1，举例说明：</p>\n<ul>\n<li>假如你有10个node（可存储数据，可成为master），则设置为6；</li>\n<li>假如你有三个可选为master的节点，100+个数据节点，则设置为2；</li>\n<li>假如你有2个常规节点，这个值设置为2，但是如果丢失一个则会造成集群不可用，如果设置为1，则不能保证脑裂的不存在，最好的方法是保证最小的节点数为3.</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">discovery.zen.minimum_master_nodes: 2</div></pre></td></tr></table></figure>\n<p>因为elasticsearch是自适应的，节点随时添加或者下线，不过还好，有api我们可以实时调整这个参数，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">PUT /_cluster/settings</div><div class=\"line\">&#123;</div><div class=\"line\">    &quot;persistent&quot; : &#123;</div><div class=\"line\">        &quot;discovery.zen.minimum_master_nodes&quot; : 2</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<ul>\n<li>Recovery Settings<br>恢复策略对elasticsearch是必不可少的，举例来说，假如现在集群（10 nodes）集体下线进行维修升级，当重新启动的时候，先启动了5 nodes，此时集群发现有5个node启动了，会执行shard的备份和交换，直到达到分片平衡，此时如果另外5 nodes加入到集群中，会发生什么呢？cluster会继续rebalance，新加入的节点发现数据集群中已经有了，首先删除本地数据，通知集群发动rebalance，平衡各个shards，这整个过程中shard会发生copy、sweap、delete等操作，耗费好多资源和时间，对一个大集群来说，耗费的更多，不可忍受。所以，elasticsearch有三个参数可以配置这些。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">gateway.recover_after_nodes: 8   // 集群中恢复的节点数，就是说当改集群启动了8个几点，才尽兴rebalance</div><div class=\"line\"></div><div class=\"line\">// 这两项说明，本集群有10的node，当10个nodes都启动或者启动了8个node且超过5分钟后就会发起rebalance</div><div class=\"line\">gateway.expected_nodes: 10</div><div class=\"line\">gateway.recover_after_time: 5m</div></pre></td></tr></table></figure>\n<p>这些策略只和<code>整个cluster重启</code>时生效。</p>\n<ul>\n<li>Prefer Unicast over Multicast<br>elasticsearch建议使用单播的方式，虽然依然提供了多播的方式，但存在找不到master等尴尬的问题，不建议使用。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">discovery.zen.ping.unicast.hosts: [&quot;host1&quot;, &quot;host2:port&quot;]</div></pre></td></tr></table></figure>\n<p>（4）不要轻易修改的参数</p>\n<ol>\n<li><p>Garbage Collector<br>elasticsearch中默认采用Concurrent-Mark and Sweep (CMS)的gc回收器；</p>\n</li>\n<li><p>Threadpools<br>elasticsearch中设置线程池非常合理的，如果没有特别情况下不要修改这个值</p>\n</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">Search gets a larger threadpool, and is configured to int((# of cores * 3) / 2) + 1</div></pre></td></tr></table></figure>\n<p>(5)Heap: Sizing and Swapping<br>(6)File Descriptors and MMap<br>elasticsearch混合使用nioFS和MMapFS。</p>\n<h3 id=\"3-插件\"><a href=\"#3-插件\" class=\"headerlink\" title=\"3. 插件\"></a>3. 插件</h3><ol>\n<li>使用<a href=\"https://github.com/mobz/elasticsearch-head\" target=\"_blank\" rel=\"external\">head</a>插件来查看索引数据</li>\n<li>使用<a href=\"https://github.com/lmenezes/elasticsearch-kopf\" target=\"_blank\" rel=\"external\">kopf</a>来备份集群节点</li>\n<li>使用<a href=\"https://github.com/lukas-vlcek/bigdesk\" target=\"_blank\" rel=\"external\">bigdesk</a>查看集群性能</li>\n<li><a href=\"https://github.com/NLPchina/elasticsearch-sql\" target=\"_blank\" rel=\"external\">elasticsearch-sql</a> 通过sql进行聚合检索, 可以将sql语句翻译成ES的JSON检索语句</li>\n<li>中文分词（ik、pinying）</li>\n<li><a href=\"https://www.elastic.co/guide/en/elasticsearch/client/curator/current/about.html\" target=\"_blank\" rel=\"external\">Curator</a></li>\n</ol>\n<h2 id=\"3-参数配置\"><a href=\"#3-参数配置\" class=\"headerlink\" title=\"3. 参数配置\"></a>3. 参数配置</h2><p>暂空（后补）</p>\n<h3 id=\"java优化配置\"><a href=\"#java优化配置\" class=\"headerlink\" title=\"java优化配置\"></a>java优化配置</h3><p>(1)Heap不要超过系统可用内存的一半，并且不要超过32GB。</p>\n<p>(2) cluster集群jvm调优<br>当时我们配置ES的JVM(Xms=Xmx=8G)的垃圾回收器主要是CMS,具体配置如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"># reduce the per-thread stack size</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -Xss256k&quot;</div><div class=\"line\"></div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UseParNewGC&quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UseConcMarkSweepGC&quot;</div><div class=\"line\"></div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:CMSInitiatingOccupancyFraction=75&quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UseCMSInitiatingOccupancyOnly&quot;</div></pre></td></tr></table></figure>\n<p>这块在官方说明中，特意强调了不建议替换java垃圾回收器，<a href=\"https://www.elastic.co/guide/en/elasticsearch/guide/current/_don_8217_t_touch_these_settings.html#_garbage_collector\" target=\"_blank\" rel=\"external\">官方并不推荐使用G1</a>。</p>\n<p><a href=\"https://www.geekhub.cn/a/1256.html\" target=\"_blank\" rel=\"external\">其他博文</a>中有试过使用其他垃圾回收器。他的G1的具体配置如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UseG1GC &quot;</div><div class=\"line\">#init_globals()末尾打印日志</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintFlagsFinal &quot;</div><div class=\"line\">#打印gc引用</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintReferenceGC &quot;</div><div class=\"line\">#输出虚拟机中GC的详细情况.</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -verbose:gc &quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintGCDetails &quot;</div><div class=\"line\">#Enables printing of time stamps at every GC. By default, this option is disabled.</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintGCTimeStamps &quot;</div><div class=\"line\">#Enables printing of information about adaptive generation sizing. By default, this option is disabled.</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintAdaptiveSizePolicy &quot;</div><div class=\"line\"># unlocks diagnostic JVM options</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UnlockDiagnosticVMOptions &quot;</div><div class=\"line\">#to measure where the time is spent</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+G1SummarizeConcMark &quot;</div><div class=\"line\">#设置触发标记周期的 Java 堆占用率阈值。默认占用率是整个 Java 堆的 45%。</div><div class=\"line\">#JAVA_OPTS=&quot;$JAVA_OPTS -XX:InitiatingHeapOccupancyPercent=45 &quot;</div></pre></td></tr></table></figure>\n<p>(3) elastic 开启jmx 监控<br>有时候监控是必不可少的，所以在有条件的时候可以加上jmx监控</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">/usr/local/elastic/bin/elasticsearch.in.sh</div><div class=\"line\">JMX_PORT=9305</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -Dcom.sun.management.jmxremote.port=$JMX_PORT&quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -Dcom.sun.management.jmxremote.ssl=false&quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -Dcom.sun.management.jmxremote.authenticate=false&quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -Djava.rmi.server.hostname=xx.xx.xx..xx&quot;</div></pre></td></tr></table></figure>\n<h3 id=\"elasticsearch-yml\"><a href=\"#elasticsearch-yml\" class=\"headerlink\" title=\"elasticsearch.yml\"></a>elasticsearch.yml</h3><p>这个是最重要的配置，只有在你明白之后在修改，之后我在单独写一篇文章介绍目前elasticsearch默认参数是如何影响系统的。</p>\n<p>目前配置包括以下几个部分：<br>（1）cluster<br>（2）节点node<br>（3）log／data路径<br>（4）内存<br>（5）网络<br>（5）发现Discovery<br>（6）Gateway<br>（7）其他变量</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div></pre></td><td class=\"code\"><pre><div class=\"line\"># ======================== Elasticsearch Configuration =========================</div><div class=\"line\">#</div><div class=\"line\"># NOTE: Elasticsearch comes with reasonable defaults for most settings.</div><div class=\"line\">#       Before you set out to tweak and tune the configuration, make sure you</div><div class=\"line\">#       understand what are you trying to accomplish and the consequences.</div><div class=\"line\">#</div><div class=\"line\"># The primary way of configuring a node is via this file. This template lists</div><div class=\"line\"># the most important settings you may want to configure for a production cluster.</div><div class=\"line\">#</div><div class=\"line\"># Please see the documentation for further information on configuration options:</div><div class=\"line\"># &lt;https://www.elastic.co/guide/en/elasticsearch/reference/5.0/settings.html&gt;</div><div class=\"line\">#</div><div class=\"line\"># ---------------------------------- Cluster -----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Use a descriptive name for your cluster:</div><div class=\"line\">#</div><div class=\"line\">cluster.name: elastic-pro</div><div class=\"line\">#</div><div class=\"line\"># ------------------------------------ Node ------------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Use a descriptive name for the node:</div><div class=\"line\">#</div><div class=\"line\">node.name: node-0</div><div class=\"line\">#</div><div class=\"line\"># Add custom attributes to the node:</div><div class=\"line\">#</div><div class=\"line\">node.attr.rack: r1</div><div class=\"line\">#</div><div class=\"line\"># ----------------------------------- Paths ------------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Path to directory where to store the data (separate multiple locations by comma):</div><div class=\"line\">#</div><div class=\"line\">path.data: /apps/home/worker/zhangxiaolong/data/index0</div><div class=\"line\">#</div><div class=\"line\"># Path to log files:</div><div class=\"line\">#</div><div class=\"line\">path.logs: /apps/home/worker/zhangxiaolong/data/log0</div><div class=\"line\">#</div><div class=\"line\"># ----------------------------------- Memory -----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Lock the memory on startup:</div><div class=\"line\">#</div><div class=\"line\">bootstrap.memory_lock: true</div><div class=\"line\">#</div><div class=\"line\"># Make sure that the heap size is set to about half the memory available</div><div class=\"line\"># on the system and that the owner of the process is allowed to use this</div><div class=\"line\"># limit.</div><div class=\"line\">#</div><div class=\"line\"># Elasticsearch performs poorly when the system is swapping the memory.</div><div class=\"line\">#</div><div class=\"line\"># ---------------------------------- Network -----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Set the bind address to a specific IP (IPv4 or IPv6):</div><div class=\"line\">#</div><div class=\"line\">network.host: 172.16.7.1</div><div class=\"line\">#</div><div class=\"line\"># Set a custom port for HTTP:</div><div class=\"line\">#</div><div class=\"line\">http.port: 9201</div><div class=\"line\">#</div><div class=\"line\"># For more information, see the documentation at:</div><div class=\"line\"># &lt;https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-network.html&gt;</div><div class=\"line\">#</div><div class=\"line\"># --------------------------------- Discovery ----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Pass an initial list of hosts to perform discovery when new node is started:</div><div class=\"line\">#The default list of hosts is [&quot;127.0.0.1&quot;, &quot;[::1]&quot;]</div><div class=\"line\">#</div><div class=\"line\">discovery.zen.ping.unicast.hosts: [&quot;172.16.7.1:9300&quot;]</div><div class=\"line\">#</div><div class=\"line\"># Prevent the &quot;split brain&quot; by configuring the majority of nodes (total number of nodes / 2 + 1):</div><div class=\"line\">#</div><div class=\"line\">discovery.zen.minimum_master_nodes: 2</div><div class=\"line\">#</div><div class=\"line\"># For more information, see the documentation at:</div><div class=\"line\"># &lt;https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-discovery-zen.html&gt;</div><div class=\"line\">#</div><div class=\"line\"># ---------------------------------- Gateway -----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Block initial recovery after a full cluster restart until N nodes are started:</div><div class=\"line\">#</div><div class=\"line\">gateway.recover_after_nodes: 2</div><div class=\"line\">#</div><div class=\"line\"># For more information, see the documentation at:</div><div class=\"line\"># &lt;https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-gateway.html&gt;</div><div class=\"line\">#</div><div class=\"line\"># ---------------------------------- Various -----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Require explicit names when deleting indices:</div><div class=\"line\">#</div><div class=\"line\">#action.destructive_requires_name: true</div></pre></td></tr></table></figure>\n<h3 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h3><p>（1）线程池设置成内核数，比如八核机器就设置成8，很多阻塞的操作都是Lucene来操作的，比如硬盘读写。搜索的线程设置可以设置成内核数的三倍<br>（2）内存交换<br>这个对于性能影响是致命的，可以使用命令sudo swapoff -a来暂时关闭，永久关闭需要编辑文件/etc/fstab，也可以在配置文件中添加配置bootstrap.mlockall: true，这样jvm可以锁定这些内存，避免被交换到物理存储介质<br>（3）其他</p>\n<ul>\n<li>如果你不需要近实时功能，则设置index的刷新时间；</li>\n<li>如果在进行一个大bulk导入，可以优先考虑设置副本数为0；</li>\n<li>如果在index中的doc你没有一个自然增长的id，可以使用Elasticsearch’s 的自动id做标示，如果有自己的id，尽量设计对lucene友好的id；</li>\n</ul>\n<h2 id=\"4-Rolling-Restarts-amp-备份数据-amp-备份恢复\"><a href=\"#4-Rolling-Restarts-amp-备份数据-amp-备份恢复\" class=\"headerlink\" title=\"4. Rolling Restarts &amp; 备份数据 &amp; 备份恢复\"></a>4. Rolling Restarts &amp; 备份数据 &amp; 备份恢复</h2><h3 id=\"Rolling-Restarts\"><a href=\"#Rolling-Restarts\" class=\"headerlink\" title=\"Rolling Restarts\"></a>Rolling Restarts</h3><p>一般下线一个node（升级、维修等），elasticsearch会进行rebalance操作，如果你是真正的下线一个node，这个操作是十分正确的，但是你知道这台node会之后重新加入到cluster中，则rebalance操作不恰当了，当shard比较大或者多的时候会严重耗费系统资源。</p>\n<p>那我们正确的操作是什么？</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div></pre></td><td class=\"code\"><pre><div class=\"line\">1. 查看集群设置</div><div class=\"line\">curl -XGET http://10.10.160.129:9200/_cluster/settings</div><div class=\"line\"></div><div class=\"line\">2. 如果可能的话，停止正在索引的数据；</div><div class=\"line\"></div><div class=\"line\">3. 停止分片同步，阻止elasticsearch进行rebalance操作</div><div class=\"line\">PUT /_cluster/settings</div><div class=\"line\">&#123;</div><div class=\"line\">    \"transient\" : &#123;</div><div class=\"line\">        \"cluster.routing.allocation.enable\" : \"none\"</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">4.关闭单个node</div><div class=\"line\"></div><div class=\"line\">5.维护或者升级节点node</div><div class=\"line\"></div><div class=\"line\">6.重启node，确认加入cluster</div><div class=\"line\"></div><div class=\"line\">7.重新打开分片同步</div><div class=\"line\">PUT /_cluster/settings</div><div class=\"line\">&#123;</div><div class=\"line\">    \"transient\" : &#123;</div><div class=\"line\">        \"cluster.routing.allocation.enable\" : \"all\"</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">8.针对需要的node重复执行3-7操作</div><div class=\"line\"></div><div class=\"line\">9.到这里就重新恢复了cluster；</div></pre></td></tr></table></figure>\n<h3 id=\"备份数据\"><a href=\"#备份数据\" class=\"headerlink\" title=\"备份数据\"></a>备份数据</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div></pre></td><td class=\"code\"><pre><div class=\"line\">1. 先导入一些数据进行备份</div><div class=\"line\">curl -XPOST 'http://192.168.56.11:9200/bank/account/_bulk?pretty' --data-binary @accounts.json</div><div class=\"line\">curl -XPOST 'http://192.168.56.11:9200/shakespeare/_bulk?pretty' --data-binary @shakespeare.json</div><div class=\"line\">curl -XPOST 'http://192.168.56.11:9200/_bulk?pretty' --data-binary @logs.jsonl</div><div class=\"line\"></div><div class=\"line\">2. 使用API创建一个镜像仓库</div><div class=\"line\">curl -XPOST http://192.168.56.11:9200/_snapshot/my_backup -d '</div><div class=\"line\">&#123;</div><div class=\"line\">    \"type\": \"fs\", </div><div class=\"line\">    \"settings\": &#123; </div><div class=\"line\">        \"location\": \"/data/mount\"</div><div class=\"line\">        \"compress\":  true </div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;'</div><div class=\"line\"><span class=\"meta\">#</span># 解释：</div><div class=\"line\">镜像仓库的名称：my_backup</div><div class=\"line\">镜像仓库的类型：fs。还支持curl，hdfs等。</div><div class=\"line\">镜像仓库的位置：/data/mount 。这个位置必须在配置文件中定义。</div><div class=\"line\">是否启用压缩：compres：true 表示启用压缩。</div><div class=\"line\"></div><div class=\"line\">3. 备份前检查配置</div><div class=\"line\">必须确定备份使用的目录在配置文件中声明了，否则会爆如下错误</div><div class=\"line\">&#123;</div><div class=\"line\">  \"error\": &#123;</div><div class=\"line\">    \"root_cause\": [</div><div class=\"line\">      &#123;</div><div class=\"line\">        \"type\": \"repository_exception\",</div><div class=\"line\">        \"reason\": \"[test-bakcup] failed to create repository\"</div><div class=\"line\">      &#125;</div><div class=\"line\">    ],</div><div class=\"line\">    \"type\": \"repository_exception\",</div><div class=\"line\">    \"reason\": \"[test-bakcup] failed to create repository\",</div><div class=\"line\">    \"caused_by\": &#123;</div><div class=\"line\">      \"type\": \"creation_exception\",</div><div class=\"line\">      \"reason\": \"Guice creation errors:\\n\\n1) Error injecting constructor, RepositoryException[[test-bakcup] location [/data/mount] doesn't match any of the locations specified by path.repo because this setting is empty]\\n  at org.elasticsearch.repositories.fs.FsRepository.&lt;init&gt;(Unknown Source)\\n  while locating org.elasticsearch.repositories.fs.FsRepository\\n  while locating org.elasticsearch.repositories.Repository\\n\\n1 error\",</div><div class=\"line\">      \"caused_by\": &#123;</div><div class=\"line\">        \"type\": \"repository_exception\",</div><div class=\"line\">        \"reason\": \"[test-bakcup] location [/data/mount] doesn't match any of the locations specified by path.repo because this setting is empty\"</div><div class=\"line\">      &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;,</div><div class=\"line\">  \"status\": 500</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">4. 开始创建一个快照</div><div class=\"line\"><span class=\"meta\">#</span>#在后头创建一个快照</div><div class=\"line\">curl -XPUT  http://192.168.56.20:9200/_snapshot/my_backup/snapshot_1 </div><div class=\"line\"><span class=\"meta\">#</span>#也可以在前台运行。</div><div class=\"line\">curl -XPUT  http://192.168.56.11:9200/_snapshot/my_backup/snapshot_1?wait_for_completion=true</div><div class=\"line\"><span class=\"meta\">#</span>#上面的参数会在my_backup仓库里创建一个snapshot_1 的快照。</div><div class=\"line\"></div><div class=\"line\">5. 可以选择相应的索引进行备份</div><div class=\"line\">curl -XPUT  http://192.168.56.20:9200/_snapshot/my_backup/snapshot_2 -d '</div><div class=\"line\">&#123;</div><div class=\"line\">    \"indices\": \"bank,logstash-2015.05.18\"</div><div class=\"line\">&#125;'</div><div class=\"line\"><span class=\"meta\">#</span># 解释：</div><div class=\"line\">创建一个snapshot_2的快照，只备份bank,logstash-2015.05.18这两个索引。</div><div class=\"line\"></div><div class=\"line\">6. 查看备份状态</div><div class=\"line\">整个备份过程中，可以通过如下命令查看备份进度</div><div class=\"line\"></div><div class=\"line\">curl -XGET http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_status</div><div class=\"line\">主要由如下几种状态：</div><div class=\"line\">a. INITIALIZING 集群状态检查，检查当前集群是否可以做快照，通常这个过程会非常快</div><div class=\"line\">b. STARTED 正在转移数据到仓库</div><div class=\"line\">c. FINALIZING 数据转移完成，正在转移元信息</div><div class=\"line\">d. DONE　完成</div><div class=\"line\">e. FAILED 备份失败</div><div class=\"line\"></div><div class=\"line\">7. 取消备份</div><div class=\"line\">curl -XDELETE http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812</div><div class=\"line\"></div><div class=\"line\">8. 获取所有快照信息。</div><div class=\"line\">curl -XGET http://192.168.56.20:9200/_snapshot/my_backup/_all |python -mjson.tool</div><div class=\"line\"><span class=\"meta\">#</span>#解释</div><div class=\"line\">查看my_backup仓库下的所有快照。</div><div class=\"line\"></div><div class=\"line\">9. 手动删除快照</div><div class=\"line\">curl -XDELETE http://192.168.56.20:9200/_snapshot/my_backup/snapshot_2</div><div class=\"line\"><span class=\"meta\">#</span># 解释</div><div class=\"line\">删除my_backup仓库下的snapshot_2的快照。</div></pre></td></tr></table></figure>\n<h3 id=\"备份恢复\"><a href=\"#备份恢复\" class=\"headerlink\" title=\"备份恢复\"></a>备份恢复</h3><figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div></pre></td><td class=\"code\"><pre><div class=\"line\">1. 恢复备份</div><div class=\"line\">curl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore</div><div class=\"line\">同备份一样，也可以设置wait_for_completion=true等待恢复结果</div><div class=\"line\"></div><div class=\"line\">curl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore?wait_for_completion=true</div><div class=\"line\">默认情况下，是恢复所有的索引，我们也可以设置一些参数来指定恢复的索引，以及重命令恢复的索引，这样可以避免覆盖原有的数据.</div><div class=\"line\"></div><div class=\"line\">curl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore</div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"attr\">\"indices\"</span>: <span class=\"string\">\"index_1\"</span>,</div><div class=\"line\">    <span class=\"attr\">\"rename_pattern\"</span>: <span class=\"string\">\"index_(.+)\"</span>,</div><div class=\"line\">    <span class=\"attr\">\"rename_replacement\"</span>: <span class=\"string\">\"restored_index_$1\"</span></div><div class=\"line\">&#125;</div><div class=\"line\">上面的indices, 表示只恢复索引’index_1’</div><div class=\"line\">rename_pattern: 表示重命名索引以’index_’开头的索引.</div><div class=\"line\">rename_replacement: 表示将所有的索引重命名为’restored_index_xxx’.如index_1会被重命名为restored_index_1.</div><div class=\"line\"></div><div class=\"line\">2. 查看所有索引的恢复进度</div><div class=\"line\">curl -XGET http://192.168.0.1:9200/_recovery/</div><div class=\"line\"></div><div class=\"line\">3. 查看索引restored_index_1的恢复进度</div><div class=\"line\">curl -XGET http://192.168.0.1:9200/_recovery/restored_index_1</div><div class=\"line\"></div><div class=\"line\">4. 取消恢复</div><div class=\"line\">只需要删除索引，即可取消恢复</div><div class=\"line\">curl -XDELETE http://192.168.0.1:9200/restored_index_1</div></pre></td></tr></table></figure>\n<h2 id=\"5-性能优化\"><a href=\"#5-性能优化\" class=\"headerlink\" title=\"5. 性能优化\"></a>5. 性能优化</h2><p>在讲性能优化之前，首先要知道：</p>\n<pre><code>过早的优化是万恶之源 Premature optimization is the root of all evil.\n                                                    —— Donald Knuth\n</code></pre><p><code>优化总是发生在目前的情况下不能满足当前的需求，其他我想不出什么理由去优化它。</code></p>\n<p><code>优化很多时候和业务是紧密关联的，优化业务可能比优化程序效率更高、成本更低！</code></p>\n<h3 id=\"索引性能优化\"><a href=\"#索引性能优化\" class=\"headerlink\" title=\"索引性能优化\"></a>索引性能优化</h3><p>索引性能（Index Performance），我们这样定义它，索引的速度是否提高，可以无缝的提供近实时的功能。<br>什么时候会发生索引慢呢？<br>（1）你读的慢（doc from db，file，inputstream等等）<br>（2）你处理的慢（中文下的分词等）<br>（3）你写的慢（还是老式的机械盘？！ 高性能的盘或者ssd）</p>\n<p>还有就是针对不同场景选择的判断，如果你索引的文件非常大，数量多，那应该选择elasticsearch提供的bulk接口，在create doc速度能跟上的时候，bulk 是可以提高速度的。</p>\n<h3 id=\"查询性能优化\"><a href=\"#查询性能优化\" class=\"headerlink\" title=\"查询性能优化\"></a>查询性能优化</h3><p>查询性能（Query Perofrmance），说起来比索引更麻烦一些，面对的场景也更多一些；</p>\n<p>面对海量数据以及不同的集群，针对业务需求去查询往往会很慢，有什么策略可以搞定这种情况？有，那就是<code>routing</code><a href=\"https://www.elastic.co/guide/en/elasticsearch/guide/current/routing-value.html\" target=\"_blank\" rel=\"external\">Routing a Document to a Shard</a>、<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/5.1/mapping-routing-field.html\" target=\"_blank\" rel=\"external\">_routing field</a>.</p>\n<p>查询策略，分别查询vs合并查询？索引越来越大，单个 shard 也很巨大，查询速度也越来越慢。这时候，是选择分索引还是更多的shards？在实践过程中，更多的 shards 会带来额外的索引压力，即 IO 压力。我们选择了分索引。比如按照每个大分类一个索引，或者主要的大城市一个索引。然后将他们进行合并查询。</p>\n<p>索引越来越大，资源使用也越来越多。若是要进行更细的集群分配，大索引使用的资源成倍增加。有什么办法能减小索引？<br>根据具体业务需求，减少某些大的索引，这是一个很好的办法，这样这个集群各方面占用的资源会有一定程度的下降，当让你要说这些少的索引怎么办，这些索引可以放在单独的集群中。</p>\n<h2 id=\"应用性能优化-from-youzan\"><a href=\"#应用性能优化-from-youzan\" class=\"headerlink\" title=\"应用性能优化 - from youzan\"></a>应用性能优化 - <a href=\"http://tech.youzan.com/search-engine1/\" target=\"_blank\" rel=\"external\">from youzan</a></h2><p>一、使用应用级队列防止雪崩<br>ES一个问题是在高峰期时候极容易发生雪崩. ES有健全的线程池系统来保证并发与稳定性问题. 但是在流量突变的情况下(比如双十一秒杀)还是很容易发生瘫痪的现象, 主要的原因如下:</p>\n<p>ES几乎为每类操作配置一个线程池; 只能保证每个线程池的资源使用时合理的, 当2个以上的线程池竞争资源时容易造成资源响应不过来.</p>\n<p>ES没有考虑网络负载导致稳定的问题.</p>\n<p>在AS里我们实现了面向请求的全局队列来保证稳定性. 它主要做了3件事情.<br><img src=\"http://image.zhangxiaolong.org/mweb/14979525149331.png!medium\" alt=\"\"></p>\n<ol>\n<li>根据业务把请求分成一个个slide, 每个slide对应一个队列. 默认一个应用就是一个slide, 一个应用也可以区分不同的slide, 这样可以保护一个应用内重要的查询.</li>\n<li>每个队列配置一个队列长度, 默认为50.</li>\n<li>每个队列计算这个队列的平均响应时间. 当队列平均响应时间超过200ms, 停止工作1s, 如果请求溢出就写入溢出日志留数据恢复使用. 如果连续10次队列平均响应时间超过500ms就报警, 以便工程师第一时间处理.</li>\n</ol>\n<p>二、自动降级<br>应用级队列解决雪崩问题有点粗暴, 如果一个应用本身查询就非常慢, 很容易让一个应用持续超时很久. 我们根据搜索引擎的特点编写了自动降级功能.</p>\n<p>比如商品搜索的例子, 商品搜索最基本的功能是布尔查询, 但是还需要按照相关性分数和质量度排序等功能, 甚至还有个性化需求. 完成简单的布尔查询, ES使用bitsets操作就可以做到, 但是如果如果需要相关性分, 就必须使用倒排索引, 并有大量CPU消耗来计算分数. ES的bitsets比倒排索引快50倍左右.</p>\n<p>对于有降级方案的slide, AS在队列响应过慢时候直接使用降级query代替正常query. 这种方法让我们在不扩容的情况下成功度过了双十一的流量陡增.</p>\n<p>三、善用filtered query<br>理解lucence filter工作原理对于写出高性能查询语句至关重要. 许多搜索性能优化都和filter的使用有关. filter使用bitsets进行布尔运算, quey使用倒排索引进行计算, 这是filter比query快的原因. bitsets的优势主要体现在: </p>\n<ol>\n<li>bitsetcache在内存里面, 永不消失(除非被LRU). </li>\n<li>bitsets利用CPU原生支持的位运算操作, 比倒排索引快个数量级 </li>\n<li>多个bitsets的与运算也是非常的快(一个64位CPU可以同时计算64个DOC的与运算) </li>\n<li>bitsets 在内存的存储是独立于query的, 有很强的复用性 </li>\n<li>如果一个bitset片段全是0, 计算会自动跳过这些片段, 让bitsets在数据稀疏情况下同样表现优于倒排索引.</li>\n</ol>\n<p>举个例子:<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">query:bool:  </div><div class=\"line\">    tag:<span class=\"string\">'mac'</span></div><div class=\"line\">    region:<span class=\"string\">'beijing'</span></div><div class=\"line\">    title: <span class=\"string\">\"apple\"</span></div></pre></td></tr></table></figure></p>\n<p>lucence处理这个query的方式是在倒排索引中寻找这三个term的倒排链 ,并使用跳指针技术求交, 在运算过程中需要对每个doc进行算分. 实际上tag和region对于算分并没有作用, 他们充当是过滤器的作用.</p>\n<p>这就是过滤器使用场景, 它只存储存在和不存在两种状态. 如果我们把tag和region使用bitsets进行存储, 这样这两个过滤器可以一直都被缓存在内存里面, 这样会快很多. 另外tag和region之间的求交非常迅速, 因为64位机器可以时间一个CPU周期同时处理64个doc的位运算.</p>\n<p>一个lucence金科玉律是: 能用filter就用filter, 除非必须使用query(当且仅当你需要算分的时候).<br>正确的写法为:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">query:  </div><div class=\"line\">    filtered: </div><div class=\"line\">        query:  </div><div class=\"line\">             title: <span class=\"string\">\"apple\"</span> </div><div class=\"line\">         filter:</div><div class=\"line\">            tag:<span class=\"string\">\"mac\"</span></div><div class=\"line\">             region:<span class=\"string\">\"beijing\"</span></div></pre></td></tr></table></figure>\n<p>四、其他</p>\n<ol>\n<li><p>线上集群关闭分片自动均衡. 分片的自动均衡主要目的防止更新造成各个分片数据分布不均匀. 但是如果线上一个节点挂掉后, 很容易触发自动均衡, 一时间集群内部的数据移动占用所有带宽. 建议采用闲时定时均衡策略来保证数据的均匀.</p>\n</li>\n<li><p>尽可能延长refresh时间间隔. 为了确保实时索引es索引刷新时间间隔默认为1秒, 索引刷新会导致查询性能受影响, 在确保业务时效性保证的基础上可以适当延长refresh时间间隔保证查询的性能.</p>\n</li>\n<li><p>除非有必要把all字段去掉. 索引默认除了索引每个字段外, 还有额外创建一个all的字段, 保存所有文本, 去掉这个字段可以把索引大小降低50%.</p>\n</li>\n<li><p>创建索引时候, 尽可能把查询比较慢的索引和快的索引物理分离.</p>\n</li>\n</ol>\n<p>##6. 参考（Reference）</p>\n<ol>\n<li><a href=\"http://www.cnblogs.com/guguli/p/5218297.html\" target=\"_blank\" rel=\"external\">elastic调优参考</a></li>\n<li><a href=\"https://github.com/Wprosdocimo/Elasticsearch-zabbix\" target=\"_blank\" rel=\"external\">elastic监控</a></li>\n<li><a href=\"http://udn.yyuap.com/doc/mastering-elasticsearch/chapter-4/41_README.html\" target=\"_blank\" rel=\"external\">Mastering Elasticsearch(中文版)</a></li>\n<li><a href=\"http://kibana.logstash.es/content/logstash/plugins/input/file.html\" target=\"_blank\" rel=\"external\">ELK-权威指南</a></li>\n<li><a href=\"http://www.learnes.net/index.html\" target=\"_blank\" rel=\"external\">Elasticsearch 权威指南</a></li>\n<li><a href=\"http://www.biglittleant.cn/2016/12/01/elastic-study1/\" target=\"_blank\" rel=\"external\">elasticsearch 生产环境配置</a></li>\n<li><a href=\"http://tech.youzan.com/search-engine1/\" target=\"_blank\" rel=\"external\">有赞搜索引擎实践(工程篇)</a></li>\n</ol>\n<p><strong>[更新于2017-05-22 - v1.0 ]<br>[更新于2017-09-26 - v1.01]</strong></p>\n<p>(完)</p>\n"},{"title":"自己动手实现推荐系统：一.常用推荐算法优势分析","date":"2017-09-28T09:15:17.000Z","english_title":"resys_common_algorithm_analyse","toc":true,"_content":"\n本文包含两部分，一是常见算法类（部分文字摘自《推荐系统实践-项亮》），二是分析目前各个大公司放出来的推荐系统机构。\n## 1、算法分析\n* 简介:通过在用户的一系列行为中寻找特定模式来产生用户特殊 推荐。\n\n\t算法的核心思想就是:如果 两个用户对于一些项的评分相似程度较高,那么一个用户对于一个新项的 评分很有可能类似于另一个用户。\r* 输入:仅仅依赖于惯用数据(例如评价、购买、下载等用户偏好 行为)。\r* 类型:\n\t* 基于邻域的协同过滤(基于用户和基于项);\n\t\t* 邻域方法(即基于内存的 CF)是使用用户 对已有项的评分直接预测该用户对新项的评分。基于邻域的 CF 方法意在找出项与项之间的联系(基于项的 CF),或 者用户与用户之间的联系(基于用户的 CF)。\n\t\t\t* 基于用户的 CF 通过找出对项的偏好与你相似的用户从而基于他们对于新项的喜好来为你进行推荐。\n\t\t\t* 基于项的 CF 会向用户推荐与用户喜欢的项相似的项,这种相似是基于项的共同出现几率(例如用户买了 X,通时也买了 Y)。\n\t* 基于模型的协同过滤(矩阵因子分解、受限玻尔兹曼机、贝叶斯网络等)。 \n\t\t* 基于模型的方 法是使用历史评分数据,基于学习出的预测模型,预测对新项的评分。基于模型的方法会在 使用评分去学习预测模型的基础上,去预测新项，一般的想法是使用机器 学习算法建立用户和项的相互作用模型,从而找出数据中的模式。贝叶斯网络、聚类、分类、回归、矩阵分解、受限玻尔兹曼机等等\n* 优点:\r\t* 需要最小域;\r\t* 不需要用户和项;\r\t* 大部分场景中能够产生足够好的结果。\r* 缺点:\r\t* 冷启动问题;\r\t* 需要标准化产品;\r\t* 需要很高的用户和项的比例(1:10);\r\t* 流行度偏见(有长尾的时候表现不够好); \n\t* 难于提供解释。\n\n## 2、基于内容的推荐算法\n* 简介:向用户推荐和其过去喜欢项的内容(例如元数据、描述、话题等等)相似的项。\n\n\t在基于内容的推荐中,假设可以获取到 item 的描述信息, 并将其作为 item 的特征向量(例如标题、年份、描述)。这些特征向量 被用于创建一个反映用户偏好的模型。各种信息检索(例如 TF-IDF)和 机器学习技术(例如朴素贝叶斯、支持向量机、决策树等)可被用于创建 用户模型,从而为用户产生推荐。\n\t\n* 输入:仅仅依赖于项和用户的内容/描述(除了惯用数据)。\n* 类型:\n\t* 信息检索(例如 tf-idf 和 Okapi BM25);\n\t* 机器学习(例如朴素贝叶斯、支持向量机、决策树等)。\n* 优点:\n\t* 没有冷启动问题;\n\t* 不需要惯用数据;\n\t* 没有流行度偏见,可以推荐有罕见特性的项; ο 可以使用用户内容特性来提供解释。\n* 缺点:\n\t* 项内容必须是机器可读的和有意义的; ο 容易归档用户;\n\t* 很难有意外,缺少多样性;\n\t* 很难联合多个项的特性。\n\n## 3、混合推荐算法\n* 简介:综合利用协同过滤推荐算法和基于内容的推荐算法各自的 优点同时抵消各自的缺点。\n* 输入:同时使用用户和项的内容特性与惯用数据,同时从两种输 入类型中获益。\n* 类型:\n\t* 加权;\n\t* 交换;\n\t* 混合;\n\t* 特性组合;\n\t* 案列\n\t* 特征增强\n\t* 元层次\n\t* ![](http://image.zhangxiaolong.org/mweb/14719522675930.jpg!medium)\n\n* 优点:\n\t* 由于单独使用协同过滤推荐算法和基于内容的推荐算法;\n\t* 没有冷启动问题;\n\t* 没有流行度偏见,可推荐有罕见特性的项;\n\t* 可产生意外,实现多样性。\n* 缺点:\n\t* 需要通过大量的工作才能得到正确的平衡。\n\n## 4、流行度推荐算法\n* 简介:这是一种推荐流行项的方法(例如最多下载、最多看过、最 大影响的项)。\n* 输入:使用惯用数据和项的内容(例如类目)。 \n* 优点:\n\t* 相对容易实现;\n\t* 良好的基准算法;\n\t* 有助于解决新用户冷启动问题。\n* 缺点:\n\t* 需要标准化产品;\n\t* 经常需要一些项的类型进行分类;\n\t* 不会推荐新项(很少有机会被观测到); \n\t* 推荐列表不会改变太大。\n\n## 5、高级非传统推荐算法\n* 类型\n\t* 深度学习\n\t* 学习等级\n\t* multi-armed bandits（探索／开发）\n\t* 上下文感知推荐\n\t* 张量分解\n\t* 分解机\n\t* 社会推荐\n* 优点：\n\t* 利于勉强维持最终性能百分点;\n\t* 你可以说你正在使用渐进的方式。\r* 缺点：\r\t* 难于理解;\n\t* 缺乏推荐工具支持\n\t* 没有为你的首个推荐系统提供推荐的方式。\n\n## 二、推荐系统结构实例\n### netfix\n首先是大名鼎鼎的netfix\n![](http://image.zhangxiaolong.org/mweb/a.png!origin)\n\n### 新浪微博\n国内我们看一下新浪\n![](http://image.zhangxiaolong.org/mweb/14720256571323.jpg!origin)\n\n### 基于内容的推荐\n基于内容和用户画像的个性化推荐属于基于内容的推荐。对于此种推荐，有两个实体：内容和用户，因此需要有一个联系这两者的东西，即为标签。内容转换为标签即为内容特征化，用户则称为用户特征化。对于此种推荐，主要分为以下几个关键部分：\n\n1. 标签库\n2. 内容特征化\n3. 用户特征化\n4. 隐语义推荐\n\n综合上面讲述的各个部分即可实现一个基于内容和用户画像的个性化推荐系统，\n![](http://image.zhangxiaolong.org/mweb/14728202025271.png!medium)\n\n（1）标签库\n标签是联系用户与物品、内容以及物品、内容之间的纽带，也是反应用户兴趣的重要数据源。标签库的最终用途在于对用户进行行为、属性标记。是将其他实体转换为计算机可以理解的语言关键的一步。\n\n标签库则是对标签进行聚合的系统，包括对标签的管理、更新等。\n\n一般来说，标签是以层级的形式组织的。可以有一级维度、二级维度等。\n标签的来源主要有：\n\n1. 已有内容的标签\n2. 网络抓取流行标签\n3. 对运营的内容进行关键词提取\n\n对于内容的关键词提取，使用结巴分词 + TFIDF即可。此外，也可以使用[TextRank](http://www.tuicool.com/articles/UZ77Z3)来提取内容关键词。\n\n这里需要注意的一点是对于**关联标签**的处理，比如用户的标签是足球，而内容的标签是德甲、英超，那么用户和内容是无法联系在一起的。最简单的方式是人工设置关联标签，此外也可以使用**word2vec**一类工具对标签做**聚类处理**，构建主题模型，将德甲、英超聚类到足球下面。\n（2） 内容特征化\n内容特征化即给内容打标签，目前有两种方式：人工打标签和机器自动打标签\n针对机器自动打标签，需要采取机器学习的相关算法来实现，即针对一系列给定的标签，给内容选取其中匹配度最高的几个标签。这不同于通常的分类和聚类算法。可以采取使用分词 + Word2Vec来实现，过程如下：\n\n1. 将文本语料进行分词，以空格,tab隔开都可以，使用结巴分词。\n2. 使用word2vec训练词的相似度模型。\n3. 使用tfidf提取内容的关键词A,B,C。\n4. 遍历每一个标签，计算关键词与此标签的相似度之和。\n5. 取出TopN相似度最高的标签即为此内容的标签。\n\n此外，可以使用文本主题挖掘相关技术，对内容进行特征化。这也分为两种情况:\n\n1. 通用情况下，只是为了效果优化的特征提取，那么可以使用非监督学习的主题模型算法。如LSA、PLSI和GaP模型或者LDA模型。\n2. 在和业务强相关时，需要在业务特定的标签体系下给内容打上适合的标签。这时候需要使用的是监督学习的主题模型。如sLDA、HSLDA等。\n\n（3） 用户特征化\n用户特征化即为用户打标签。通过用户的行为日志和一定的模型算法得到用户的每个标签的权重(泊松分布求解每个行为的权重；有监督的主题模型如SLDA；无监督的主题模型LSA)。\n\n1. 用户对内容的行为：点赞、不感兴趣、点击、浏览。对用户的反馈行为如点赞赋予权值1，不感兴趣赋予-1；对于用户的浏览行为，则可使用点击/浏览作为权值。\n2. 对内容发生的行为可以认为对此内容所带的标签的行为。\n3. 用户的兴趣是时间衰减的，即离当前时间越远的兴趣比重越低。时间衰减函数使用1/[log(t)+1], t为事件发生的时间距离当前时间的大小。\n4. 要考虑到热门内容会干预用户的标签，需要对热门内容进行降权。使用click/pv作为用户浏览行为权值即可达到此目的。\n5. 此外，还需要考虑噪声的干扰，如标题党等。\n\n另外，非业务强相关的情况下，还可以考虑使用LSA主题模型等矩阵分解的方式对用户进行标签化。\n\n（4） 隐语义推荐\n有了内容特征和用户特征，可以使用[隐语义模型](http://blog.csdn.net/harryhuang1990/article/details/9924377)进行推荐。这里可以使用其简化形式，以达到实时计算的目的。\n\n用户对于某一个内容的兴趣度(可以认为是CTR)：\n![](http://image.zhangxiaolong.org/mweb/14728206482938.jpg!origin)\n\n其中i=1…N是内容c具有的标签，m(ci)指的内容c和标签i的关联度(可以简单认为是1),n(ui)指的是用户u的标签i的权重值,当用户不具有此标签时n(ui)=0，q©指的是内容c的质量，可以使用点击率(click/pv)表示。\n\n（完）\n\n**- 写作于2017年9月28号，只是简稿**\n\n\n","source":"_posts/自己动手打造推荐系统-一-常用推荐算法优势分析.md","raw":"---\ntitle: '自己动手实现推荐系统：一.常用推荐算法优势分析'\ndate: 2017-09-28 17:15:17\ntags:\n  - resys\ncategories:\n  - resys\nenglish_title: resys_common_algorithm_analyse\ntoc: true\n---\n\n本文包含两部分，一是常见算法类（部分文字摘自《推荐系统实践-项亮》），二是分析目前各个大公司放出来的推荐系统机构。\n## 1、算法分析\n* 简介:通过在用户的一系列行为中寻找特定模式来产生用户特殊 推荐。\n\n\t算法的核心思想就是:如果 两个用户对于一些项的评分相似程度较高,那么一个用户对于一个新项的 评分很有可能类似于另一个用户。\r* 输入:仅仅依赖于惯用数据(例如评价、购买、下载等用户偏好 行为)。\r* 类型:\n\t* 基于邻域的协同过滤(基于用户和基于项);\n\t\t* 邻域方法(即基于内存的 CF)是使用用户 对已有项的评分直接预测该用户对新项的评分。基于邻域的 CF 方法意在找出项与项之间的联系(基于项的 CF),或 者用户与用户之间的联系(基于用户的 CF)。\n\t\t\t* 基于用户的 CF 通过找出对项的偏好与你相似的用户从而基于他们对于新项的喜好来为你进行推荐。\n\t\t\t* 基于项的 CF 会向用户推荐与用户喜欢的项相似的项,这种相似是基于项的共同出现几率(例如用户买了 X,通时也买了 Y)。\n\t* 基于模型的协同过滤(矩阵因子分解、受限玻尔兹曼机、贝叶斯网络等)。 \n\t\t* 基于模型的方 法是使用历史评分数据,基于学习出的预测模型,预测对新项的评分。基于模型的方法会在 使用评分去学习预测模型的基础上,去预测新项，一般的想法是使用机器 学习算法建立用户和项的相互作用模型,从而找出数据中的模式。贝叶斯网络、聚类、分类、回归、矩阵分解、受限玻尔兹曼机等等\n* 优点:\r\t* 需要最小域;\r\t* 不需要用户和项;\r\t* 大部分场景中能够产生足够好的结果。\r* 缺点:\r\t* 冷启动问题;\r\t* 需要标准化产品;\r\t* 需要很高的用户和项的比例(1:10);\r\t* 流行度偏见(有长尾的时候表现不够好); \n\t* 难于提供解释。\n\n## 2、基于内容的推荐算法\n* 简介:向用户推荐和其过去喜欢项的内容(例如元数据、描述、话题等等)相似的项。\n\n\t在基于内容的推荐中,假设可以获取到 item 的描述信息, 并将其作为 item 的特征向量(例如标题、年份、描述)。这些特征向量 被用于创建一个反映用户偏好的模型。各种信息检索(例如 TF-IDF)和 机器学习技术(例如朴素贝叶斯、支持向量机、决策树等)可被用于创建 用户模型,从而为用户产生推荐。\n\t\n* 输入:仅仅依赖于项和用户的内容/描述(除了惯用数据)。\n* 类型:\n\t* 信息检索(例如 tf-idf 和 Okapi BM25);\n\t* 机器学习(例如朴素贝叶斯、支持向量机、决策树等)。\n* 优点:\n\t* 没有冷启动问题;\n\t* 不需要惯用数据;\n\t* 没有流行度偏见,可以推荐有罕见特性的项; ο 可以使用用户内容特性来提供解释。\n* 缺点:\n\t* 项内容必须是机器可读的和有意义的; ο 容易归档用户;\n\t* 很难有意外,缺少多样性;\n\t* 很难联合多个项的特性。\n\n## 3、混合推荐算法\n* 简介:综合利用协同过滤推荐算法和基于内容的推荐算法各自的 优点同时抵消各自的缺点。\n* 输入:同时使用用户和项的内容特性与惯用数据,同时从两种输 入类型中获益。\n* 类型:\n\t* 加权;\n\t* 交换;\n\t* 混合;\n\t* 特性组合;\n\t* 案列\n\t* 特征增强\n\t* 元层次\n\t* ![](http://image.zhangxiaolong.org/mweb/14719522675930.jpg!medium)\n\n* 优点:\n\t* 由于单独使用协同过滤推荐算法和基于内容的推荐算法;\n\t* 没有冷启动问题;\n\t* 没有流行度偏见,可推荐有罕见特性的项;\n\t* 可产生意外,实现多样性。\n* 缺点:\n\t* 需要通过大量的工作才能得到正确的平衡。\n\n## 4、流行度推荐算法\n* 简介:这是一种推荐流行项的方法(例如最多下载、最多看过、最 大影响的项)。\n* 输入:使用惯用数据和项的内容(例如类目)。 \n* 优点:\n\t* 相对容易实现;\n\t* 良好的基准算法;\n\t* 有助于解决新用户冷启动问题。\n* 缺点:\n\t* 需要标准化产品;\n\t* 经常需要一些项的类型进行分类;\n\t* 不会推荐新项(很少有机会被观测到); \n\t* 推荐列表不会改变太大。\n\n## 5、高级非传统推荐算法\n* 类型\n\t* 深度学习\n\t* 学习等级\n\t* multi-armed bandits（探索／开发）\n\t* 上下文感知推荐\n\t* 张量分解\n\t* 分解机\n\t* 社会推荐\n* 优点：\n\t* 利于勉强维持最终性能百分点;\n\t* 你可以说你正在使用渐进的方式。\r* 缺点：\r\t* 难于理解;\n\t* 缺乏推荐工具支持\n\t* 没有为你的首个推荐系统提供推荐的方式。\n\n## 二、推荐系统结构实例\n### netfix\n首先是大名鼎鼎的netfix\n![](http://image.zhangxiaolong.org/mweb/a.png!origin)\n\n### 新浪微博\n国内我们看一下新浪\n![](http://image.zhangxiaolong.org/mweb/14720256571323.jpg!origin)\n\n### 基于内容的推荐\n基于内容和用户画像的个性化推荐属于基于内容的推荐。对于此种推荐，有两个实体：内容和用户，因此需要有一个联系这两者的东西，即为标签。内容转换为标签即为内容特征化，用户则称为用户特征化。对于此种推荐，主要分为以下几个关键部分：\n\n1. 标签库\n2. 内容特征化\n3. 用户特征化\n4. 隐语义推荐\n\n综合上面讲述的各个部分即可实现一个基于内容和用户画像的个性化推荐系统，\n![](http://image.zhangxiaolong.org/mweb/14728202025271.png!medium)\n\n（1）标签库\n标签是联系用户与物品、内容以及物品、内容之间的纽带，也是反应用户兴趣的重要数据源。标签库的最终用途在于对用户进行行为、属性标记。是将其他实体转换为计算机可以理解的语言关键的一步。\n\n标签库则是对标签进行聚合的系统，包括对标签的管理、更新等。\n\n一般来说，标签是以层级的形式组织的。可以有一级维度、二级维度等。\n标签的来源主要有：\n\n1. 已有内容的标签\n2. 网络抓取流行标签\n3. 对运营的内容进行关键词提取\n\n对于内容的关键词提取，使用结巴分词 + TFIDF即可。此外，也可以使用[TextRank](http://www.tuicool.com/articles/UZ77Z3)来提取内容关键词。\n\n这里需要注意的一点是对于**关联标签**的处理，比如用户的标签是足球，而内容的标签是德甲、英超，那么用户和内容是无法联系在一起的。最简单的方式是人工设置关联标签，此外也可以使用**word2vec**一类工具对标签做**聚类处理**，构建主题模型，将德甲、英超聚类到足球下面。\n（2） 内容特征化\n内容特征化即给内容打标签，目前有两种方式：人工打标签和机器自动打标签\n针对机器自动打标签，需要采取机器学习的相关算法来实现，即针对一系列给定的标签，给内容选取其中匹配度最高的几个标签。这不同于通常的分类和聚类算法。可以采取使用分词 + Word2Vec来实现，过程如下：\n\n1. 将文本语料进行分词，以空格,tab隔开都可以，使用结巴分词。\n2. 使用word2vec训练词的相似度模型。\n3. 使用tfidf提取内容的关键词A,B,C。\n4. 遍历每一个标签，计算关键词与此标签的相似度之和。\n5. 取出TopN相似度最高的标签即为此内容的标签。\n\n此外，可以使用文本主题挖掘相关技术，对内容进行特征化。这也分为两种情况:\n\n1. 通用情况下，只是为了效果优化的特征提取，那么可以使用非监督学习的主题模型算法。如LSA、PLSI和GaP模型或者LDA模型。\n2. 在和业务强相关时，需要在业务特定的标签体系下给内容打上适合的标签。这时候需要使用的是监督学习的主题模型。如sLDA、HSLDA等。\n\n（3） 用户特征化\n用户特征化即为用户打标签。通过用户的行为日志和一定的模型算法得到用户的每个标签的权重(泊松分布求解每个行为的权重；有监督的主题模型如SLDA；无监督的主题模型LSA)。\n\n1. 用户对内容的行为：点赞、不感兴趣、点击、浏览。对用户的反馈行为如点赞赋予权值1，不感兴趣赋予-1；对于用户的浏览行为，则可使用点击/浏览作为权值。\n2. 对内容发生的行为可以认为对此内容所带的标签的行为。\n3. 用户的兴趣是时间衰减的，即离当前时间越远的兴趣比重越低。时间衰减函数使用1/[log(t)+1], t为事件发生的时间距离当前时间的大小。\n4. 要考虑到热门内容会干预用户的标签，需要对热门内容进行降权。使用click/pv作为用户浏览行为权值即可达到此目的。\n5. 此外，还需要考虑噪声的干扰，如标题党等。\n\n另外，非业务强相关的情况下，还可以考虑使用LSA主题模型等矩阵分解的方式对用户进行标签化。\n\n（4） 隐语义推荐\n有了内容特征和用户特征，可以使用[隐语义模型](http://blog.csdn.net/harryhuang1990/article/details/9924377)进行推荐。这里可以使用其简化形式，以达到实时计算的目的。\n\n用户对于某一个内容的兴趣度(可以认为是CTR)：\n![](http://image.zhangxiaolong.org/mweb/14728206482938.jpg!origin)\n\n其中i=1…N是内容c具有的标签，m(ci)指的内容c和标签i的关联度(可以简单认为是1),n(ui)指的是用户u的标签i的权重值,当用户不具有此标签时n(ui)=0，q©指的是内容c的质量，可以使用点击率(click/pv)表示。\n\n（完）\n\n**- 写作于2017年9月28号，只是简稿**\n\n\n","slug":"自己动手打造推荐系统-一-常用推荐算法优势分析","published":1,"updated":"2017-09-30T08:58:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj8pb1nnr0007q9s6zfoeaf2v","content":"<p>本文包含两部分，一是常见算法类（部分文字摘自《推荐系统实践-项亮》），二是分析目前各个大公司放出来的推荐系统机构。</p>\n<h2 id=\"1、算法分析\"><a href=\"#1、算法分析\" class=\"headerlink\" title=\"1、算法分析\"></a>1、算法分析</h2><ul>\n<li><p>简介:通过在用户的一系列行为中寻找特定模式来产生用户特殊 推荐。</p>\n<p>  算法的核心思想就是:如果 两个用户对于一些项的评分相似程度较高,那么一个用户对于一个新项的 评分很有可能类似于另一个用户。</p>\n</li>\n<li>输入:仅仅依赖于惯用数据(例如评价、购买、下载等用户偏好 行为)。</li>\n<li>类型:<ul>\n<li>基于邻域的协同过滤(基于用户和基于项);<ul>\n<li>邻域方法(即基于内存的 CF)是使用用户 对已有项的评分直接预测该用户对新项的评分。基于邻域的 CF 方法意在找出项与项之间的联系(基于项的 CF),或 者用户与用户之间的联系(基于用户的 CF)。<ul>\n<li>基于用户的 CF 通过找出对项的偏好与你相似的用户从而基于他们对于新项的喜好来为你进行推荐。</li>\n<li>基于项的 CF 会向用户推荐与用户喜欢的项相似的项,这种相似是基于项的共同出现几率(例如用户买了 X,通时也买了 Y)。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>基于模型的协同过滤(矩阵因子分解、受限玻尔兹曼机、贝叶斯网络等)。 <ul>\n<li>基于模型的方 法是使用历史评分数据,基于学习出的预测模型,预测对新项的评分。基于模型的方法会在 使用评分去学习预测模型的基础上,去预测新项，一般的想法是使用机器 学习算法建立用户和项的相互作用模型,从而找出数据中的模式。贝叶斯网络、聚类、分类、回归、矩阵分解、受限玻尔兹曼机等等</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>优点:<ul>\n<li>需要最小域;</li>\n<li>不需要用户和项;</li>\n<li>大部分场景中能够产生足够好的结果。</li>\n</ul>\n</li>\n<li>缺点:<ul>\n<li>冷启动问题;</li>\n<li>需要标准化产品;</li>\n<li>需要很高的用户和项的比例(1:10);</li>\n<li>流行度偏见(有长尾的时候表现不够好); </li>\n<li>难于提供解释。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"2、基于内容的推荐算法\"><a href=\"#2、基于内容的推荐算法\" class=\"headerlink\" title=\"2、基于内容的推荐算法\"></a>2、基于内容的推荐算法</h2><ul>\n<li><p>简介:向用户推荐和其过去喜欢项的内容(例如元数据、描述、话题等等)相似的项。</p>\n<p>  在基于内容的推荐中,假设可以获取到 item 的描述信息, 并将其作为 item 的特征向量(例如标题、年份、描述)。这些特征向量 被用于创建一个反映用户偏好的模型。各种信息检索(例如 TF-IDF)和 机器学习技术(例如朴素贝叶斯、支持向量机、决策树等)可被用于创建 用户模型,从而为用户产生推荐。</p>\n</li>\n<li><p>输入:仅仅依赖于项和用户的内容/描述(除了惯用数据)。</p>\n</li>\n<li>类型:<ul>\n<li>信息检索(例如 tf-idf 和 Okapi BM25);</li>\n<li>机器学习(例如朴素贝叶斯、支持向量机、决策树等)。</li>\n</ul>\n</li>\n<li>优点:<ul>\n<li>没有冷启动问题;</li>\n<li>不需要惯用数据;</li>\n<li>没有流行度偏见,可以推荐有罕见特性的项; ο 可以使用用户内容特性来提供解释。</li>\n</ul>\n</li>\n<li>缺点:<ul>\n<li>项内容必须是机器可读的和有意义的; ο 容易归档用户;</li>\n<li>很难有意外,缺少多样性;</li>\n<li>很难联合多个项的特性。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"3、混合推荐算法\"><a href=\"#3、混合推荐算法\" class=\"headerlink\" title=\"3、混合推荐算法\"></a>3、混合推荐算法</h2><ul>\n<li>简介:综合利用协同过滤推荐算法和基于内容的推荐算法各自的 优点同时抵消各自的缺点。</li>\n<li>输入:同时使用用户和项的内容特性与惯用数据,同时从两种输 入类型中获益。</li>\n<li><p>类型:</p>\n<ul>\n<li>加权;</li>\n<li>交换;</li>\n<li>混合;</li>\n<li>特性组合;</li>\n<li>案列</li>\n<li>特征增强</li>\n<li>元层次</li>\n<li><img src=\"http://image.zhangxiaolong.org/mweb/14719522675930.jpg!medium\" alt=\"\"></li>\n</ul>\n</li>\n<li><p>优点:</p>\n<ul>\n<li>由于单独使用协同过滤推荐算法和基于内容的推荐算法;</li>\n<li>没有冷启动问题;</li>\n<li>没有流行度偏见,可推荐有罕见特性的项;</li>\n<li>可产生意外,实现多样性。</li>\n</ul>\n</li>\n<li>缺点:<ul>\n<li>需要通过大量的工作才能得到正确的平衡。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"4、流行度推荐算法\"><a href=\"#4、流行度推荐算法\" class=\"headerlink\" title=\"4、流行度推荐算法\"></a>4、流行度推荐算法</h2><ul>\n<li>简介:这是一种推荐流行项的方法(例如最多下载、最多看过、最 大影响的项)。</li>\n<li>输入:使用惯用数据和项的内容(例如类目)。 </li>\n<li>优点:<ul>\n<li>相对容易实现;</li>\n<li>良好的基准算法;</li>\n<li>有助于解决新用户冷启动问题。</li>\n</ul>\n</li>\n<li>缺点:<ul>\n<li>需要标准化产品;</li>\n<li>经常需要一些项的类型进行分类;</li>\n<li>不会推荐新项(很少有机会被观测到); </li>\n<li>推荐列表不会改变太大。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"5、高级非传统推荐算法\"><a href=\"#5、高级非传统推荐算法\" class=\"headerlink\" title=\"5、高级非传统推荐算法\"></a>5、高级非传统推荐算法</h2><ul>\n<li>类型<ul>\n<li>深度学习</li>\n<li>学习等级</li>\n<li>multi-armed bandits（探索／开发）</li>\n<li>上下文感知推荐</li>\n<li>张量分解</li>\n<li>分解机</li>\n<li>社会推荐</li>\n</ul>\n</li>\n<li>优点：<ul>\n<li>利于勉强维持最终性能百分点;</li>\n<li>你可以说你正在使用渐进的方式。</li>\n</ul>\n</li>\n<li>缺点：<ul>\n<li>难于理解;</li>\n<li>缺乏推荐工具支持</li>\n<li>没有为你的首个推荐系统提供推荐的方式。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"二、推荐系统结构实例\"><a href=\"#二、推荐系统结构实例\" class=\"headerlink\" title=\"二、推荐系统结构实例\"></a>二、推荐系统结构实例</h2><h3 id=\"netfix\"><a href=\"#netfix\" class=\"headerlink\" title=\"netfix\"></a>netfix</h3><p>首先是大名鼎鼎的netfix<br><img src=\"http://image.zhangxiaolong.org/mweb/a.png!origin\" alt=\"\"></p>\n<h3 id=\"新浪微博\"><a href=\"#新浪微博\" class=\"headerlink\" title=\"新浪微博\"></a>新浪微博</h3><p>国内我们看一下新浪<br><img src=\"http://image.zhangxiaolong.org/mweb/14720256571323.jpg!origin\" alt=\"\"></p>\n<h3 id=\"基于内容的推荐\"><a href=\"#基于内容的推荐\" class=\"headerlink\" title=\"基于内容的推荐\"></a>基于内容的推荐</h3><p>基于内容和用户画像的个性化推荐属于基于内容的推荐。对于此种推荐，有两个实体：内容和用户，因此需要有一个联系这两者的东西，即为标签。内容转换为标签即为内容特征化，用户则称为用户特征化。对于此种推荐，主要分为以下几个关键部分：</p>\n<ol>\n<li>标签库</li>\n<li>内容特征化</li>\n<li>用户特征化</li>\n<li>隐语义推荐</li>\n</ol>\n<p>综合上面讲述的各个部分即可实现一个基于内容和用户画像的个性化推荐系统，<br><img src=\"http://image.zhangxiaolong.org/mweb/14728202025271.png!medium\" alt=\"\"></p>\n<p>（1）标签库<br>标签是联系用户与物品、内容以及物品、内容之间的纽带，也是反应用户兴趣的重要数据源。标签库的最终用途在于对用户进行行为、属性标记。是将其他实体转换为计算机可以理解的语言关键的一步。</p>\n<p>标签库则是对标签进行聚合的系统，包括对标签的管理、更新等。</p>\n<p>一般来说，标签是以层级的形式组织的。可以有一级维度、二级维度等。<br>标签的来源主要有：</p>\n<ol>\n<li>已有内容的标签</li>\n<li>网络抓取流行标签</li>\n<li>对运营的内容进行关键词提取</li>\n</ol>\n<p>对于内容的关键词提取，使用结巴分词 + TFIDF即可。此外，也可以使用<a href=\"http://www.tuicool.com/articles/UZ77Z3\" target=\"_blank\" rel=\"external\">TextRank</a>来提取内容关键词。</p>\n<p>这里需要注意的一点是对于<strong>关联标签</strong>的处理，比如用户的标签是足球，而内容的标签是德甲、英超，那么用户和内容是无法联系在一起的。最简单的方式是人工设置关联标签，此外也可以使用<strong>word2vec</strong>一类工具对标签做<strong>聚类处理</strong>，构建主题模型，将德甲、英超聚类到足球下面。<br>（2） 内容特征化<br>内容特征化即给内容打标签，目前有两种方式：人工打标签和机器自动打标签<br>针对机器自动打标签，需要采取机器学习的相关算法来实现，即针对一系列给定的标签，给内容选取其中匹配度最高的几个标签。这不同于通常的分类和聚类算法。可以采取使用分词 + Word2Vec来实现，过程如下：</p>\n<ol>\n<li>将文本语料进行分词，以空格,tab隔开都可以，使用结巴分词。</li>\n<li>使用word2vec训练词的相似度模型。</li>\n<li>使用tfidf提取内容的关键词A,B,C。</li>\n<li>遍历每一个标签，计算关键词与此标签的相似度之和。</li>\n<li>取出TopN相似度最高的标签即为此内容的标签。</li>\n</ol>\n<p>此外，可以使用文本主题挖掘相关技术，对内容进行特征化。这也分为两种情况:</p>\n<ol>\n<li>通用情况下，只是为了效果优化的特征提取，那么可以使用非监督学习的主题模型算法。如LSA、PLSI和GaP模型或者LDA模型。</li>\n<li>在和业务强相关时，需要在业务特定的标签体系下给内容打上适合的标签。这时候需要使用的是监督学习的主题模型。如sLDA、HSLDA等。</li>\n</ol>\n<p>（3） 用户特征化<br>用户特征化即为用户打标签。通过用户的行为日志和一定的模型算法得到用户的每个标签的权重(泊松分布求解每个行为的权重；有监督的主题模型如SLDA；无监督的主题模型LSA)。</p>\n<ol>\n<li>用户对内容的行为：点赞、不感兴趣、点击、浏览。对用户的反馈行为如点赞赋予权值1，不感兴趣赋予-1；对于用户的浏览行为，则可使用点击/浏览作为权值。</li>\n<li>对内容发生的行为可以认为对此内容所带的标签的行为。</li>\n<li>用户的兴趣是时间衰减的，即离当前时间越远的兴趣比重越低。时间衰减函数使用1/[log(t)+1], t为事件发生的时间距离当前时间的大小。</li>\n<li>要考虑到热门内容会干预用户的标签，需要对热门内容进行降权。使用click/pv作为用户浏览行为权值即可达到此目的。</li>\n<li>此外，还需要考虑噪声的干扰，如标题党等。</li>\n</ol>\n<p>另外，非业务强相关的情况下，还可以考虑使用LSA主题模型等矩阵分解的方式对用户进行标签化。</p>\n<p>（4） 隐语义推荐<br>有了内容特征和用户特征，可以使用<a href=\"http://blog.csdn.net/harryhuang1990/article/details/9924377\" target=\"_blank\" rel=\"external\">隐语义模型</a>进行推荐。这里可以使用其简化形式，以达到实时计算的目的。</p>\n<p>用户对于某一个内容的兴趣度(可以认为是CTR)：<br><img src=\"http://image.zhangxiaolong.org/mweb/14728206482938.jpg!origin\" alt=\"\"></p>\n<p>其中i=1…N是内容c具有的标签，m(ci)指的内容c和标签i的关联度(可以简单认为是1),n(ui)指的是用户u的标签i的权重值,当用户不具有此标签时n(ui)=0，q©指的是内容c的质量，可以使用点击率(click/pv)表示。</p>\n<p>（完）</p>\n<p><strong>- 写作于2017年9月28号，只是简稿</strong></p>\n","site":{"data":{}},"excerpt":"","more":"<p>本文包含两部分，一是常见算法类（部分文字摘自《推荐系统实践-项亮》），二是分析目前各个大公司放出来的推荐系统机构。</p>\n<h2 id=\"1、算法分析\"><a href=\"#1、算法分析\" class=\"headerlink\" title=\"1、算法分析\"></a>1、算法分析</h2><ul>\n<li><p>简介:通过在用户的一系列行为中寻找特定模式来产生用户特殊 推荐。</p>\n<p>  算法的核心思想就是:如果 两个用户对于一些项的评分相似程度较高,那么一个用户对于一个新项的 评分很有可能类似于另一个用户。</p>\n</li>\n<li>输入:仅仅依赖于惯用数据(例如评价、购买、下载等用户偏好 行为)。</li>\n<li>类型:<ul>\n<li>基于邻域的协同过滤(基于用户和基于项);<ul>\n<li>邻域方法(即基于内存的 CF)是使用用户 对已有项的评分直接预测该用户对新项的评分。基于邻域的 CF 方法意在找出项与项之间的联系(基于项的 CF),或 者用户与用户之间的联系(基于用户的 CF)。<ul>\n<li>基于用户的 CF 通过找出对项的偏好与你相似的用户从而基于他们对于新项的喜好来为你进行推荐。</li>\n<li>基于项的 CF 会向用户推荐与用户喜欢的项相似的项,这种相似是基于项的共同出现几率(例如用户买了 X,通时也买了 Y)。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>基于模型的协同过滤(矩阵因子分解、受限玻尔兹曼机、贝叶斯网络等)。 <ul>\n<li>基于模型的方 法是使用历史评分数据,基于学习出的预测模型,预测对新项的评分。基于模型的方法会在 使用评分去学习预测模型的基础上,去预测新项，一般的想法是使用机器 学习算法建立用户和项的相互作用模型,从而找出数据中的模式。贝叶斯网络、聚类、分类、回归、矩阵分解、受限玻尔兹曼机等等</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>优点:<ul>\n<li>需要最小域;</li>\n<li>不需要用户和项;</li>\n<li>大部分场景中能够产生足够好的结果。</li>\n</ul>\n</li>\n<li>缺点:<ul>\n<li>冷启动问题;</li>\n<li>需要标准化产品;</li>\n<li>需要很高的用户和项的比例(1:10);</li>\n<li>流行度偏见(有长尾的时候表现不够好); </li>\n<li>难于提供解释。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"2、基于内容的推荐算法\"><a href=\"#2、基于内容的推荐算法\" class=\"headerlink\" title=\"2、基于内容的推荐算法\"></a>2、基于内容的推荐算法</h2><ul>\n<li><p>简介:向用户推荐和其过去喜欢项的内容(例如元数据、描述、话题等等)相似的项。</p>\n<p>  在基于内容的推荐中,假设可以获取到 item 的描述信息, 并将其作为 item 的特征向量(例如标题、年份、描述)。这些特征向量 被用于创建一个反映用户偏好的模型。各种信息检索(例如 TF-IDF)和 机器学习技术(例如朴素贝叶斯、支持向量机、决策树等)可被用于创建 用户模型,从而为用户产生推荐。</p>\n</li>\n<li><p>输入:仅仅依赖于项和用户的内容/描述(除了惯用数据)。</p>\n</li>\n<li>类型:<ul>\n<li>信息检索(例如 tf-idf 和 Okapi BM25);</li>\n<li>机器学习(例如朴素贝叶斯、支持向量机、决策树等)。</li>\n</ul>\n</li>\n<li>优点:<ul>\n<li>没有冷启动问题;</li>\n<li>不需要惯用数据;</li>\n<li>没有流行度偏见,可以推荐有罕见特性的项; ο 可以使用用户内容特性来提供解释。</li>\n</ul>\n</li>\n<li>缺点:<ul>\n<li>项内容必须是机器可读的和有意义的; ο 容易归档用户;</li>\n<li>很难有意外,缺少多样性;</li>\n<li>很难联合多个项的特性。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"3、混合推荐算法\"><a href=\"#3、混合推荐算法\" class=\"headerlink\" title=\"3、混合推荐算法\"></a>3、混合推荐算法</h2><ul>\n<li>简介:综合利用协同过滤推荐算法和基于内容的推荐算法各自的 优点同时抵消各自的缺点。</li>\n<li>输入:同时使用用户和项的内容特性与惯用数据,同时从两种输 入类型中获益。</li>\n<li><p>类型:</p>\n<ul>\n<li>加权;</li>\n<li>交换;</li>\n<li>混合;</li>\n<li>特性组合;</li>\n<li>案列</li>\n<li>特征增强</li>\n<li>元层次</li>\n<li><img src=\"http://image.zhangxiaolong.org/mweb/14719522675930.jpg!medium\" alt=\"\"></li>\n</ul>\n</li>\n<li><p>优点:</p>\n<ul>\n<li>由于单独使用协同过滤推荐算法和基于内容的推荐算法;</li>\n<li>没有冷启动问题;</li>\n<li>没有流行度偏见,可推荐有罕见特性的项;</li>\n<li>可产生意外,实现多样性。</li>\n</ul>\n</li>\n<li>缺点:<ul>\n<li>需要通过大量的工作才能得到正确的平衡。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"4、流行度推荐算法\"><a href=\"#4、流行度推荐算法\" class=\"headerlink\" title=\"4、流行度推荐算法\"></a>4、流行度推荐算法</h2><ul>\n<li>简介:这是一种推荐流行项的方法(例如最多下载、最多看过、最 大影响的项)。</li>\n<li>输入:使用惯用数据和项的内容(例如类目)。 </li>\n<li>优点:<ul>\n<li>相对容易实现;</li>\n<li>良好的基准算法;</li>\n<li>有助于解决新用户冷启动问题。</li>\n</ul>\n</li>\n<li>缺点:<ul>\n<li>需要标准化产品;</li>\n<li>经常需要一些项的类型进行分类;</li>\n<li>不会推荐新项(很少有机会被观测到); </li>\n<li>推荐列表不会改变太大。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"5、高级非传统推荐算法\"><a href=\"#5、高级非传统推荐算法\" class=\"headerlink\" title=\"5、高级非传统推荐算法\"></a>5、高级非传统推荐算法</h2><ul>\n<li>类型<ul>\n<li>深度学习</li>\n<li>学习等级</li>\n<li>multi-armed bandits（探索／开发）</li>\n<li>上下文感知推荐</li>\n<li>张量分解</li>\n<li>分解机</li>\n<li>社会推荐</li>\n</ul>\n</li>\n<li>优点：<ul>\n<li>利于勉强维持最终性能百分点;</li>\n<li>你可以说你正在使用渐进的方式。</li>\n</ul>\n</li>\n<li>缺点：<ul>\n<li>难于理解;</li>\n<li>缺乏推荐工具支持</li>\n<li>没有为你的首个推荐系统提供推荐的方式。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"二、推荐系统结构实例\"><a href=\"#二、推荐系统结构实例\" class=\"headerlink\" title=\"二、推荐系统结构实例\"></a>二、推荐系统结构实例</h2><h3 id=\"netfix\"><a href=\"#netfix\" class=\"headerlink\" title=\"netfix\"></a>netfix</h3><p>首先是大名鼎鼎的netfix<br><img src=\"http://image.zhangxiaolong.org/mweb/a.png!origin\" alt=\"\"></p>\n<h3 id=\"新浪微博\"><a href=\"#新浪微博\" class=\"headerlink\" title=\"新浪微博\"></a>新浪微博</h3><p>国内我们看一下新浪<br><img src=\"http://image.zhangxiaolong.org/mweb/14720256571323.jpg!origin\" alt=\"\"></p>\n<h3 id=\"基于内容的推荐\"><a href=\"#基于内容的推荐\" class=\"headerlink\" title=\"基于内容的推荐\"></a>基于内容的推荐</h3><p>基于内容和用户画像的个性化推荐属于基于内容的推荐。对于此种推荐，有两个实体：内容和用户，因此需要有一个联系这两者的东西，即为标签。内容转换为标签即为内容特征化，用户则称为用户特征化。对于此种推荐，主要分为以下几个关键部分：</p>\n<ol>\n<li>标签库</li>\n<li>内容特征化</li>\n<li>用户特征化</li>\n<li>隐语义推荐</li>\n</ol>\n<p>综合上面讲述的各个部分即可实现一个基于内容和用户画像的个性化推荐系统，<br><img src=\"http://image.zhangxiaolong.org/mweb/14728202025271.png!medium\" alt=\"\"></p>\n<p>（1）标签库<br>标签是联系用户与物品、内容以及物品、内容之间的纽带，也是反应用户兴趣的重要数据源。标签库的最终用途在于对用户进行行为、属性标记。是将其他实体转换为计算机可以理解的语言关键的一步。</p>\n<p>标签库则是对标签进行聚合的系统，包括对标签的管理、更新等。</p>\n<p>一般来说，标签是以层级的形式组织的。可以有一级维度、二级维度等。<br>标签的来源主要有：</p>\n<ol>\n<li>已有内容的标签</li>\n<li>网络抓取流行标签</li>\n<li>对运营的内容进行关键词提取</li>\n</ol>\n<p>对于内容的关键词提取，使用结巴分词 + TFIDF即可。此外，也可以使用<a href=\"http://www.tuicool.com/articles/UZ77Z3\" target=\"_blank\" rel=\"external\">TextRank</a>来提取内容关键词。</p>\n<p>这里需要注意的一点是对于<strong>关联标签</strong>的处理，比如用户的标签是足球，而内容的标签是德甲、英超，那么用户和内容是无法联系在一起的。最简单的方式是人工设置关联标签，此外也可以使用<strong>word2vec</strong>一类工具对标签做<strong>聚类处理</strong>，构建主题模型，将德甲、英超聚类到足球下面。<br>（2） 内容特征化<br>内容特征化即给内容打标签，目前有两种方式：人工打标签和机器自动打标签<br>针对机器自动打标签，需要采取机器学习的相关算法来实现，即针对一系列给定的标签，给内容选取其中匹配度最高的几个标签。这不同于通常的分类和聚类算法。可以采取使用分词 + Word2Vec来实现，过程如下：</p>\n<ol>\n<li>将文本语料进行分词，以空格,tab隔开都可以，使用结巴分词。</li>\n<li>使用word2vec训练词的相似度模型。</li>\n<li>使用tfidf提取内容的关键词A,B,C。</li>\n<li>遍历每一个标签，计算关键词与此标签的相似度之和。</li>\n<li>取出TopN相似度最高的标签即为此内容的标签。</li>\n</ol>\n<p>此外，可以使用文本主题挖掘相关技术，对内容进行特征化。这也分为两种情况:</p>\n<ol>\n<li>通用情况下，只是为了效果优化的特征提取，那么可以使用非监督学习的主题模型算法。如LSA、PLSI和GaP模型或者LDA模型。</li>\n<li>在和业务强相关时，需要在业务特定的标签体系下给内容打上适合的标签。这时候需要使用的是监督学习的主题模型。如sLDA、HSLDA等。</li>\n</ol>\n<p>（3） 用户特征化<br>用户特征化即为用户打标签。通过用户的行为日志和一定的模型算法得到用户的每个标签的权重(泊松分布求解每个行为的权重；有监督的主题模型如SLDA；无监督的主题模型LSA)。</p>\n<ol>\n<li>用户对内容的行为：点赞、不感兴趣、点击、浏览。对用户的反馈行为如点赞赋予权值1，不感兴趣赋予-1；对于用户的浏览行为，则可使用点击/浏览作为权值。</li>\n<li>对内容发生的行为可以认为对此内容所带的标签的行为。</li>\n<li>用户的兴趣是时间衰减的，即离当前时间越远的兴趣比重越低。时间衰减函数使用1/[log(t)+1], t为事件发生的时间距离当前时间的大小。</li>\n<li>要考虑到热门内容会干预用户的标签，需要对热门内容进行降权。使用click/pv作为用户浏览行为权值即可达到此目的。</li>\n<li>此外，还需要考虑噪声的干扰，如标题党等。</li>\n</ol>\n<p>另外，非业务强相关的情况下，还可以考虑使用LSA主题模型等矩阵分解的方式对用户进行标签化。</p>\n<p>（4） 隐语义推荐<br>有了内容特征和用户特征，可以使用<a href=\"http://blog.csdn.net/harryhuang1990/article/details/9924377\" target=\"_blank\" rel=\"external\">隐语义模型</a>进行推荐。这里可以使用其简化形式，以达到实时计算的目的。</p>\n<p>用户对于某一个内容的兴趣度(可以认为是CTR)：<br><img src=\"http://image.zhangxiaolong.org/mweb/14728206482938.jpg!origin\" alt=\"\"></p>\n<p>其中i=1…N是内容c具有的标签，m(ci)指的内容c和标签i的关联度(可以简单认为是1),n(ui)指的是用户u的标签i的权重值,当用户不具有此标签时n(ui)=0，q©指的是内容c的质量，可以使用点击率(click/pv)表示。</p>\n<p>（完）</p>\n<p><strong>- 写作于2017年9月28号，只是简稿</strong></p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cj8pb1nnj0001q9s6jpsz3ukm","category_id":"cj8pb1nnp0004q9s6m8yc6ve8","_id":"cj8pb1nnv000dq9s6m47a3n80"},{"post_id":"cj8pb1nnn0003q9s6yppsqwkc","category_id":"cj8pb1nnu000aq9s6tjgxq7wg","_id":"cj8pb1nnx000hq9s6nbjm8994"},{"post_id":"cj8pb1nnr0007q9s6zfoeaf2v","category_id":"cj8pb1nnw000eq9s6wmwcbyb7","_id":"cj8pb1nny000lq9s6fw3vzoi2"}],"PostTag":[{"post_id":"cj8pb1nnj0001q9s6jpsz3ukm","tag_id":"cj8pb1nnq0005q9s664h9qw57","_id":"cj8pb1nnx000gq9s6i6f90oxd"},{"post_id":"cj8pb1nnj0001q9s6jpsz3ukm","tag_id":"cj8pb1nnu000bq9s6anhoep4u","_id":"cj8pb1nnx000iq9s6sfi9gshc"},{"post_id":"cj8pb1nnn0003q9s6yppsqwkc","tag_id":"cj8pb1nnw000fq9s6q2t28mcn","_id":"cj8pb1nny000kq9s6qtqh8nss"},{"post_id":"cj8pb1nnr0007q9s6zfoeaf2v","tag_id":"cj8pb1nnx000jq9s6fgisqm8r","_id":"cj8pb1nnz000mq9s6f7q0jnbi"}],"Tag":[{"name":"deep learning","_id":"cj8pb1nnq0005q9s664h9qw57"},{"name":"GAN","_id":"cj8pb1nnu000bq9s6anhoep4u"},{"name":"search","_id":"cj8pb1nnw000fq9s6q2t28mcn"},{"name":"resys","_id":"cj8pb1nnx000jq9s6fgisqm8r"}]}}
{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/vexo/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/vexo/source/js/script.js","path":"js/script.js","modified":0,"renderable":1},{"_id":"themes/vexo/source/js/qrious.js","path":"js/qrious.js","modified":0,"renderable":1},{"_id":"themes/vexo/source/css/images/menu.png","path":"css/images/menu.png","modified":0,"renderable":1},{"_id":"themes/vexo/source/css/images/escheres.png","path":"css/images/escheres.png","modified":0,"renderable":1},{"_id":"themes/vexo/source/css/images/top.png","path":"css/images/top.png","modified":0,"renderable":1},{"_id":"themes/vexo/source/css/plugins/gitment.css","path":"css/plugins/gitment.css","modified":0,"renderable":1},{"_id":"themes/vexo/source/css/images/alipay.png","path":"css/images/alipay.png","modified":0,"renderable":1},{"_id":"themes/vexo/source/css/images/wechat.png","path":"css/images/wechat.png","modified":0,"renderable":1},{"_id":"themes/vexo/source/js/gitment.js","path":"js/gitment.js","modified":0,"renderable":1},{"_id":"themes/vexo/source/fonts/SourceSansPro.ttf","path":"fonts/SourceSansPro.ttf","modified":0,"renderable":1},{"_id":"themes/vexo/source/css/images/logo.png","path":"css/images/logo.png","modified":0,"renderable":1},{"_id":"source/robots.txt","path":"robots.txt","modified":0,"renderable":0}],"Cache":[{"_id":"source/.DS_Store","hash":"b48c4f7d61a5928be717d4bd654481ff1eab36ee","modified":1506398227000},{"_id":"themes/vexo/.gitignore","hash":"37fb9fd49e7f944716efd3284a6bf55adb6dd0c2","modified":1506395539000},{"_id":"themes/vexo/.travis.yml","hash":"ade5797c6eb124979b4af6f94e86c1431337b5d7","modified":1506395539000},{"_id":"themes/vexo/LICENSE","hash":"3e135cd69c0e02c0a49dd43d571f600223cc61d1","modified":1506395534000},{"_id":"themes/vexo/README.md","hash":"9c72a193211a48689e7c700ed7d7aa54123d862c","modified":1506395543000},{"_id":"themes/vexo/_config.yml","hash":"c8970cf47ce40843c9b5da6d0563501098dd3b2b","modified":1506410715000},{"_id":"themes/vexo/lint.sh","hash":"f580302e4aa9ccfb95a253851da6501d145613fe","modified":1506395539000},{"_id":"themes/vexo/package.json","hash":"4a839847a872079d154a4884182a7bc773e76535","modified":1506395543000},{"_id":"source/_posts/how-to-be-a-geeker.md","hash":"12df737e8a6854f07f2019f2a5c5d6cf61fb95c1","modified":1506395533000},{"_id":"source/_posts/test.md","hash":"9a315c557e64975b91ccb3796ed9f969edc3421c","modified":1506403200000},{"_id":"source/_posts/test3.md","hash":"6dc64d5b0b220361c7a6e8cc80cfd07ddb7bfc2a","modified":1506398223000},{"_id":"source/about/index.md","hash":"68c8af0453deca5f6b03eb18ee6f89fb0c1f1f75","modified":1506395533000},{"_id":"source/_posts/test2.md","hash":"197fa93f9c263e552ce98baedd789e4e196368cd","modified":1506395533000},{"_id":"source/bookshelf/index.md","hash":"a431cd000eb907a570e4d08c1629ff938fd0317b","modified":1506395533000},{"_id":"source/search/index.md","hash":"25f79ca74c25c2fd943e9761aebd1c9b45c92252","modified":1506395532000},{"_id":"source/resys/index.md","hash":"5b9e423d3737bb3852498e860d2c056dacb9ee8c","modified":1506395533000},{"_id":"source/tags/index.md","hash":"80a15f1b5daff22b04849109e976bc91a410b83e","modified":1506395533000},{"_id":"themes/vexo/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1506395538000},{"_id":"themes/vexo/.git/config","hash":"85b0752953f75d6b59eb0ac5f1a1b61a4b48ca00","modified":1506395536000},{"_id":"themes/vexo/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1506395535000},{"_id":"themes/vexo/.git/index","hash":"c369630adb2eda0c04d01816caa8d1fe8d8c88c3","modified":1506399061000},{"_id":"themes/vexo/.git/packed-refs","hash":"104d2c2c94d832902c078ae982aba2c4d34ecd01","modified":1506395534000},{"_id":"themes/vexo/layout/index.ejs","hash":"6c7358c1d6a3fb5ae19dea47cea708c9896809a2","modified":1506395533000},{"_id":"themes/vexo/layout/about.ejs","hash":"9d0f12efdc59859aec21fd7c4acab9ac150a4cd5","modified":1506395533000},{"_id":"themes/vexo/layout/archive.ejs","hash":"cb12abb19cb70e90d410a6233933eedb3f2c033a","modified":1506395534000},{"_id":"themes/vexo/layout/layout.ejs","hash":"a7b8f1debdca12d667ecd1bcc3d4bc6e13a23d7b","modified":1506395533000},{"_id":"themes/vexo/layout/page.ejs","hash":"c953764278ac03794e08cfe6d7cc0d378d5e8406","modified":1506395533000},{"_id":"themes/vexo/layout/tags.ejs","hash":"5b326e2bd3292b3015d0666b796544d7126acfda","modified":1506395533000},{"_id":"themes/vexo/.git/hooks/applypatch-msg.sample","hash":"86b9655a9ebbde13ac8dd5795eb4d5b539edab0f","modified":1506395536000},{"_id":"themes/vexo/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1506395535000},{"_id":"themes/vexo/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1506395536000},{"_id":"themes/vexo/.git/hooks/pre-applypatch.sample","hash":"42fa41564917b44183a50c4d94bb03e1768ddad8","modified":1506395536000},{"_id":"themes/vexo/.git/hooks/pre-push.sample","hash":"503c3d2cd9066c2329ae84309c03a4c274f6d90e","modified":1506395536000},{"_id":"themes/vexo/.git/hooks/pre-commit.sample","hash":"e6c9fe47f7506171be08ed90baaf91d49bc7fe0c","modified":1506395535000},{"_id":"themes/vexo/.git/hooks/pre-rebase.sample","hash":"5885a56ab4fca8075a05a562d005e922cde9853b","modified":1506395536000},{"_id":"themes/vexo/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1506395536000},{"_id":"themes/vexo/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1506395535000},{"_id":"themes/vexo/.git/hooks/update.sample","hash":"39355a075977d05708ef74e1b66d09a36e486df1","modified":1506395536000},{"_id":"themes/vexo/.git/logs/HEAD","hash":"eafb8b087d529997eed94a846d8cc2f64862efe4","modified":1506395535000},{"_id":"themes/vexo/_source/about/index.md","hash":"68c8af0453deca5f6b03eb18ee6f89fb0c1f1f75","modified":1506395539000},{"_id":"themes/vexo/_source/tags/index.md","hash":"80a15f1b5daff22b04849109e976bc91a410b83e","modified":1506395539000},{"_id":"themes/vexo/_source/project/index.md","hash":"b8f5482c157514bd2df4ce8a4e4d01a957497924","modified":1506395539000},{"_id":"themes/vexo/layout/_partial/archive.ejs","hash":"9abbf14034d581569c0b6c992fe22035cb5306b3","modified":1506395534000},{"_id":"themes/vexo/layout/_partial/footer.ejs","hash":"e3895e20c4c8a24cefd108f681ddb25998c9e625","modified":1506410942000},{"_id":"themes/vexo/layout/_partial/head.ejs","hash":"9c2cb91d07c78657eb6723a1629fee96dc5b2176","modified":1506395533000},{"_id":"themes/vexo/layout/_partial/header.ejs","hash":"e544f516b23bc609cc6367190f380c879b935c21","modified":1506395534000},{"_id":"themes/vexo/layout/_partial/pager.ejs","hash":"3a1b9680fbfa3baa76933c7c17216996381ad241","modified":1506395534000},{"_id":"themes/vexo/layout/_partial/top.ejs","hash":"f09dea486246a580213005b21d4b38810dd16fb3","modified":1506395534000},{"_id":"themes/vexo/layout/_partial/tag.ejs","hash":"5d2a2c3f8ca7000945ab426a0c6939421974b224","modified":1506395534000},{"_id":"themes/vexo/source/css/_config.styl","hash":"ac69c720d1699d2c93982b81c233c02982fc01be","modified":1506395542000},{"_id":"themes/vexo/source/css/style.styl","hash":"f2a32891e67d53d0414daa3255167296204d7f51","modified":1506395542000},{"_id":"themes/vexo/source/js/script.js","hash":"a19ed5f3c1d9c64855f162bce7ec66b47aada780","modified":1506395540000},{"_id":"themes/vexo/source/js/qrious.js","hash":"a9271e81e2ac6a692b1c133811afa33f0f3d7dc5","modified":1506395539000},{"_id":"themes/vexo/.git/objects/pack/pack-d44dd37d3af2471e8252d8ae7ee49d1d06ae37a5.idx","hash":"2c7f9275cdc6b9c9b8c807b390b28a1c5bdd05b4","modified":1506395538000},{"_id":"themes/vexo/.git/refs/heads/master","hash":"daab59e07919301fe79e877aa08b31b4fdf37fd7","modified":1506395538000},{"_id":"themes/vexo/source/css/_partial/about.styl","hash":"e4a9bffe9c44c3179c021e2d924386ff9f758399","modified":1506395542000},{"_id":"themes/vexo/source/css/_partial/footer.styl","hash":"acc26664e5b3bdb40534496234a66fca2994e905","modified":1506395542000},{"_id":"themes/vexo/source/css/_partial/archive.styl","hash":"e80ddf26f2af3523632afeabd57f81592537985a","modified":1506395542000},{"_id":"themes/vexo/source/css/_partial/header.styl","hash":"def3a6938d925c585a7da6256a6f2e90f3b7d61e","modified":1506395542000},{"_id":"themes/vexo/source/css/_partial/markdown.styl","hash":"c141d008eae51b55eb0ea0526860046974f3be49","modified":1506395542000},{"_id":"themes/vexo/source/css/_partial/project.styl","hash":"e9b6faadf4852bce3a4141cba0a102a7afb81e9f","modified":1506395542000},{"_id":"themes/vexo/source/css/_partial/tags.styl","hash":"5198a7f7c221341138ae5c65185e86b6e13e8e26","modified":1506395542000},{"_id":"themes/vexo/source/css/_partial/pager.styl","hash":"888384c67429c7568aa38b5ebe5acae3cc4de367","modified":1506395542000},{"_id":"themes/vexo/source/css/images/menu.png","hash":"bdaa35eb1ed119caeb934e15a05b9f4a5396d957","modified":1506395541000},{"_id":"themes/vexo/source/css/images/logo.png.bak","hash":"718c6e48956249121cf3cca1a22a99f8372a3f0d","modified":1506395542000},{"_id":"themes/vexo/source/css/images/escheres.png","hash":"55deece3236dcc2fb44c28dec3e8bacbb7b46542","modified":1506395542000},{"_id":"themes/vexo/source/css/images/alipay.jpg.bak","hash":"c49822ea6f06f868c2404fb00a93f913c8fff7b5","modified":1506395541000},{"_id":"themes/vexo/source/css/images/top.png","hash":"611a257907474ca02828319f81b006c1d818bb84","modified":1506395541000},{"_id":"themes/vexo/source/css/plugins/gitment.css","hash":"541ff18d7f3542b5663dc6aad06d43e135332b71","modified":1506395541000},{"_id":"themes/vexo/source/css/images/wechat.jpg.bak","hash":"5bed6d3eb9f71b227b0ea0187c1a7ba8caf5ee64","modified":1506395542000},{"_id":"themes/vexo/source/css/images/alipay.png","hash":"9f6b1c1389daf4d4725e1dd0649882463940687b","modified":1506395541000},{"_id":"themes/vexo/source/css/images/wechat.png","hash":"047933e41de09c3931e5c16fb008038bb55aec8e","modified":1506395542000},{"_id":"themes/vexo/source/js/gitment.js","hash":"376446d9c5930576016f97dd63e5e6616c94d8d4","modified":1506395540000},{"_id":"themes/vexo/source/fonts/SourceSansPro.ttf","hash":"1e9f0372c269da205fdbac8cf27cb9cf59f6ad45","modified":1506395539000},{"_id":"themes/vexo/.git/logs/refs/heads/master","hash":"eafb8b087d529997eed94a846d8cc2f64862efe4","modified":1506395535000},{"_id":"themes/vexo/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1506395539000},{"_id":"themes/vexo/.git/logs/refs/remotes/origin/HEAD","hash":"eafb8b087d529997eed94a846d8cc2f64862efe4","modified":1506395535000},{"_id":"themes/vexo/.git/objects/pack/pack-d44dd37d3af2471e8252d8ae7ee49d1d06ae37a5.pack","hash":"c8d50f49b877fed5ed96d6fb858c8ed4f7445295","modified":1506395538000},{"_id":"public/atom.xml","hash":"d96008e1334eb258f67452501845c4822e48063f","modified":1506410318248},{"_id":"public/sitemap.xml","hash":"83580bcc4a1a89388895a90c9edbcfc4c70a7b94","modified":1506410318250},{"_id":"public/about/index.html","hash":"3944087f6a2d9d3ad0467d8f01cc6da81d1e8113","modified":1506410964106},{"_id":"public/tags/index.html","hash":"8df6a2749ab046e39220b1e0f077798917306566","modified":1506410964107},{"_id":"public/resys/index.html","hash":"1e20f21aa6a5b8fca04ae1f735dc0d42a43a9610","modified":1506410964107},{"_id":"public/2017/09/23/test3/index.html","hash":"2f7d7eb210632d99eb768e6b1aadcc959d6fb129","modified":1506410964107},{"_id":"public/archives/index.html","hash":"e2f4c679cad0030a88588e602488d22fcb68722a","modified":1506410964107},{"_id":"public/2017/06/03/how-to-be-a-geeker/index.html","hash":"620ab5cc3fb7f4136baf135116726131fd29df32","modified":1506410964107},{"_id":"public/archives/2017/index.html","hash":"e3978661be05314b55b01d1937e0282339ce5050","modified":1506410964107},{"_id":"public/archives/2017/06/index.html","hash":"17064c59302028406904069a8ca7b3388d8c7927","modified":1506410964107},{"_id":"public/archives/2017/09/index.html","hash":"6966d11d975c75ff7c23e99553c36b59227155be","modified":1506410964108},{"_id":"public/index.html","hash":"ae77c84820f2f230c1c3601c5cb51b8f40ebcc68","modified":1506410964108},{"_id":"public/categories/Thought/index.html","hash":"c6d7b5921ed610c7a1da0932ac32c7fdeb930e85","modified":1506410964108},{"_id":"public/tags/geeker/index.html","hash":"5a630fd67f8578534a3693f1312c80a5efd4d5d1","modified":1506410964108},{"_id":"public/search/index.html","hash":"0bafc63433167456a301ac63f108882b309107ca","modified":1506410964107},{"_id":"public/bookshelf/index.html","hash":"6ba81976575b2aecf004dff792de68a7431d91d4","modified":1506410964106},{"_id":"public/tags/rec/index.html","hash":"382b359516d0868f6f27b2a94c92344a4c26001b","modified":1506410964108},{"_id":"public/2017/09/26/test2/index.html","hash":"ea13abfea7656575703a1eee537fe4e838c34f79","modified":1506410964108},{"_id":"public/2017/09/26/test/index.html","hash":"7471c36ce3d531e22f2feae5104b688ce5567be3","modified":1506410964108},{"_id":"public/css/images/menu.png","hash":"bdaa35eb1ed119caeb934e15a05b9f4a5396d957","modified":1506401567926},{"_id":"public/css/images/alipay.jpg.bak","hash":"c49822ea6f06f868c2404fb00a93f913c8fff7b5","modified":1506401567926},{"_id":"public/css/images/top.png","hash":"611a257907474ca02828319f81b006c1d818bb84","modified":1506401567927},{"_id":"public/css/images/wechat.jpg.bak","hash":"5bed6d3eb9f71b227b0ea0187c1a7ba8caf5ee64","modified":1506401567927},{"_id":"public/css/images/alipay.png","hash":"9f6b1c1389daf4d4725e1dd0649882463940687b","modified":1506401567927},{"_id":"public/css/images/wechat.png","hash":"047933e41de09c3931e5c16fb008038bb55aec8e","modified":1506401567927},{"_id":"public/css/images/escheres.png","hash":"55deece3236dcc2fb44c28dec3e8bacbb7b46542","modified":1506401567927},{"_id":"public/css/images/logo.png.bak","hash":"718c6e48956249121cf3cca1a22a99f8372a3f0d","modified":1506401567927},{"_id":"public/js/script.js","hash":"a19ed5f3c1d9c64855f162bce7ec66b47aada780","modified":1506401567929},{"_id":"public/css/style.css","hash":"91599cbf54c671afad2ec2c6a23bafc132e54050","modified":1506401567930},{"_id":"public/js/qrious.js","hash":"a9271e81e2ac6a692b1c133811afa33f0f3d7dc5","modified":1506401567932},{"_id":"public/css/plugins/gitment.css","hash":"541ff18d7f3542b5663dc6aad06d43e135332b71","modified":1506401567932},{"_id":"public/js/gitment.js","hash":"376446d9c5930576016f97dd63e5e6616c94d8d4","modified":1506401567932},{"_id":"public/fonts/SourceSansPro.ttf","hash":"1e9f0372c269da205fdbac8cf27cb9cf59f6ad45","modified":1506401567933},{"_id":"themes/vexo/source/css/images/logo.png","hash":"3cc2fc6bda241e89369e1cef5887c31368528663","modified":1506405841000},{"_id":"public/css/images/logo.png","hash":"3cc2fc6bda241e89369e1cef5887c31368528663","modified":1506405866890},{"_id":"source/robots.txt","hash":"9631979ef280b534d113141d3752eb719b56f824","modified":1506408836000},{"_id":"public/baidusitemap.xml","hash":"5e8655e30c51afa7eb4cdf4bf5e45b661a2d7c1e","modified":1506410318202},{"_id":"public/robots.txt","hash":"9631979ef280b534d113141d3752eb719b56f824","modified":1506408883750}],"Category":[{"name":"Thought","_id":"cj814lkcn0004pjs6j6w32492"}],"Data":[],"Page":[{"title":"About","layout":"about","_content":"","source":"about/index.md","raw":"---\ntitle: About\nlayout: about\n---","date":"2017-09-26T03:12:13.000Z","updated":"2017-09-26T03:12:13.000Z","path":"about/index.html","comments":1,"_id":"cj814lkck0001pjs6mlclzz9r","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Bookshelf","id":1949,"comment":false,"date":"2017-06-03T06:12:10.000Z","_content":"\n## 那些年度过的时间\n\n## Book\n\n(1) **Tcp/ip 详解（卷1）** – 评分：7.0\n\n读后评：介绍计算机网络的比较基础的一本书，在学校或多或少都学过，这里不展开讲了。如果在互联网公司，还是请看第二卷、三卷吧。\n\n(2)Java编程思想\n\n(3)Python CookBook\n\n(4) 大型网站技术架构 – 核心原理与案例分析\n\n(4) 本色（乐嘉）\n\n读后评：通过各方面的了解，我还是比较喜欢乐嘉这个人的，他写的这本书买来读了一下，很是通透。\n(6) **请给我结果**\n\n读后评：直白的语言，有些地方不适合互联网公司。\n(7)**番茄工作方法图解**\n\n读后评：经典的方法，以番茄钟来高效的利用自己的时间，尝试了一段时间。但是，还是被自己码代码的投入忘了时间。\n(8)**黑客与画家**\n\n读后评：我对这本书印象最深的是关于财富、创业、语言的部分，很深刻，有共鸣。\n\n(9) **三体** – 刘慈欣\n\n读后评：在一开始就深深的吸引了我，花了一个周末看完了，其中各种的问题真的很令人深思！\n\n(10) **趁年轻，折腾吧（袁岳）**\n\n读后评：一句话概括：趁年轻，折腾吧！！ 推荐一读\n\n(11) **看见（柴静）**\n\n读后评：以自己的经历（看见的）讲到的近几年的各种事情，让我看到了当年各个事件的另一个方面（好的或者坏的或者更坏的）。推荐阅读\n\n## Paper\n\n(1) Bigtable:A Distributed Storage System for Structured Data ([download](http://document-save.qiniudn.com/zhangxiaolong.orgbigtable-osdi06.pdf))\n(2) GFS:The Google File System ([download](http://document-save.qiniudn.com/zhangxiaolong.orggfs-sosp2003.pdf))\n(3) MapReduce:MapReduce: Simplied Data Processing on Large Clusters ([download](http://document-save.qiniudn.com/zhangxiaolong.orgmapreduce-osdi04.pdf))\n(4) Spanner:Google’s Globally-Distributed Database ([download](http://document-save.qiniudn.com/zhangxiaolong.orgspanner-osdi2012.pdf))\n(5) Megastore: Providing Scalable, Highly Available Storage for Interactive Services ([download](http://document-save.qiniudn.com/zhangxiaolong.orgmegastore.pdf))\n(6) Pregel:A System for Large-Scale Graph Processing ([download](http://document-save.qiniudn.com/zhangxiaolong.orgPregel.pdf))\n(7) Dremel: Interactive Analysis of Web-Scale Datasets ([download](http://document-save.qiniudn.com/zhangxiaolong.orgDremel.pdf))\n(8) Caffeine: Large-scale Incremental Processing Using Distributed Transactions and Notications ([download](http://document-save.qiniudn.com/zhangxiaolong.orgCaffeine%20-1.pdf))\n(9) Search The Web ([download](http://document-save.qiniudn.com/web%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%A6%82%E8%AE%BA%E2%80%94%E2%80%94searching_the_web.pdf))","source":"bookshelf/index.md","raw":"---\ntitle: Bookshelf\nid: 1949\ncomment: false\ndate: 2017-06-03 14:12:10\n---\n\n## 那些年度过的时间\n\n## Book\n\n(1) **Tcp/ip 详解（卷1）** – 评分：7.0\n\n读后评：介绍计算机网络的比较基础的一本书，在学校或多或少都学过，这里不展开讲了。如果在互联网公司，还是请看第二卷、三卷吧。\n\n(2)Java编程思想\n\n(3)Python CookBook\n\n(4) 大型网站技术架构 – 核心原理与案例分析\n\n(4) 本色（乐嘉）\n\n读后评：通过各方面的了解，我还是比较喜欢乐嘉这个人的，他写的这本书买来读了一下，很是通透。\n(6) **请给我结果**\n\n读后评：直白的语言，有些地方不适合互联网公司。\n(7)**番茄工作方法图解**\n\n读后评：经典的方法，以番茄钟来高效的利用自己的时间，尝试了一段时间。但是，还是被自己码代码的投入忘了时间。\n(8)**黑客与画家**\n\n读后评：我对这本书印象最深的是关于财富、创业、语言的部分，很深刻，有共鸣。\n\n(9) **三体** – 刘慈欣\n\n读后评：在一开始就深深的吸引了我，花了一个周末看完了，其中各种的问题真的很令人深思！\n\n(10) **趁年轻，折腾吧（袁岳）**\n\n读后评：一句话概括：趁年轻，折腾吧！！ 推荐一读\n\n(11) **看见（柴静）**\n\n读后评：以自己的经历（看见的）讲到的近几年的各种事情，让我看到了当年各个事件的另一个方面（好的或者坏的或者更坏的）。推荐阅读\n\n## Paper\n\n(1) Bigtable:A Distributed Storage System for Structured Data ([download](http://document-save.qiniudn.com/zhangxiaolong.orgbigtable-osdi06.pdf))\n(2) GFS:The Google File System ([download](http://document-save.qiniudn.com/zhangxiaolong.orggfs-sosp2003.pdf))\n(3) MapReduce:MapReduce: Simplied Data Processing on Large Clusters ([download](http://document-save.qiniudn.com/zhangxiaolong.orgmapreduce-osdi04.pdf))\n(4) Spanner:Google’s Globally-Distributed Database ([download](http://document-save.qiniudn.com/zhangxiaolong.orgspanner-osdi2012.pdf))\n(5) Megastore: Providing Scalable, Highly Available Storage for Interactive Services ([download](http://document-save.qiniudn.com/zhangxiaolong.orgmegastore.pdf))\n(6) Pregel:A System for Large-Scale Graph Processing ([download](http://document-save.qiniudn.com/zhangxiaolong.orgPregel.pdf))\n(7) Dremel: Interactive Analysis of Web-Scale Datasets ([download](http://document-save.qiniudn.com/zhangxiaolong.orgDremel.pdf))\n(8) Caffeine: Large-scale Incremental Processing Using Distributed Transactions and Notications ([download](http://document-save.qiniudn.com/zhangxiaolong.orgCaffeine%20-1.pdf))\n(9) Search The Web ([download](http://document-save.qiniudn.com/web%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%A6%82%E8%AE%BA%E2%80%94%E2%80%94searching_the_web.pdf))","updated":"2017-09-26T03:12:13.000Z","path":"bookshelf/index.html","comments":1,"layout":"page","_id":"cj814lkcm0003pjs6qxx7z31z","content":"<h2 id=\"那些年度过的时间\"><a href=\"#那些年度过的时间\" class=\"headerlink\" title=\"那些年度过的时间\"></a>那些年度过的时间</h2><h2 id=\"Book\"><a href=\"#Book\" class=\"headerlink\" title=\"Book\"></a>Book</h2><p>(1) <strong>Tcp/ip 详解（卷1）</strong> – 评分：7.0</p>\n<p>读后评：介绍计算机网络的比较基础的一本书，在学校或多或少都学过，这里不展开讲了。如果在互联网公司，还是请看第二卷、三卷吧。</p>\n<p>(2)Java编程思想</p>\n<p>(3)Python CookBook</p>\n<p>(4) 大型网站技术架构 – 核心原理与案例分析</p>\n<p>(4) 本色（乐嘉）</p>\n<p>读后评：通过各方面的了解，我还是比较喜欢乐嘉这个人的，他写的这本书买来读了一下，很是通透。<br>(6) <strong>请给我结果</strong></p>\n<p>读后评：直白的语言，有些地方不适合互联网公司。<br>(7)<strong>番茄工作方法图解</strong></p>\n<p>读后评：经典的方法，以番茄钟来高效的利用自己的时间，尝试了一段时间。但是，还是被自己码代码的投入忘了时间。<br>(8)<strong>黑客与画家</strong></p>\n<p>读后评：我对这本书印象最深的是关于财富、创业、语言的部分，很深刻，有共鸣。</p>\n<p>(9) <strong>三体</strong> – 刘慈欣</p>\n<p>读后评：在一开始就深深的吸引了我，花了一个周末看完了，其中各种的问题真的很令人深思！</p>\n<p>(10) <strong>趁年轻，折腾吧（袁岳）</strong></p>\n<p>读后评：一句话概括：趁年轻，折腾吧！！ 推荐一读</p>\n<p>(11) <strong>看见（柴静）</strong></p>\n<p>读后评：以自己的经历（看见的）讲到的近几年的各种事情，让我看到了当年各个事件的另一个方面（好的或者坏的或者更坏的）。推荐阅读</p>\n<h2 id=\"Paper\"><a href=\"#Paper\" class=\"headerlink\" title=\"Paper\"></a>Paper</h2><p>(1) Bigtable:A Distributed Storage System for Structured Data (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgbigtable-osdi06.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(2) GFS:The Google File System (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orggfs-sosp2003.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(3) MapReduce:MapReduce: Simplied Data Processing on Large Clusters (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgmapreduce-osdi04.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(4) Spanner:Google’s Globally-Distributed Database (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgspanner-osdi2012.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(5) Megastore: Providing Scalable, Highly Available Storage for Interactive Services (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgmegastore.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(6) Pregel:A System for Large-Scale Graph Processing (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgPregel.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(7) Dremel: Interactive Analysis of Web-Scale Datasets (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgDremel.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(8) Caffeine: Large-scale Incremental Processing Using Distributed Transactions and Notications (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgCaffeine%20-1.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(9) Search The Web (<a href=\"http://document-save.qiniudn.com/web%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%A6%82%E8%AE%BA%E2%80%94%E2%80%94searching_the_web.pdf\" target=\"_blank\" rel=\"external\">download</a>)</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"那些年度过的时间\"><a href=\"#那些年度过的时间\" class=\"headerlink\" title=\"那些年度过的时间\"></a>那些年度过的时间</h2><h2 id=\"Book\"><a href=\"#Book\" class=\"headerlink\" title=\"Book\"></a>Book</h2><p>(1) <strong>Tcp/ip 详解（卷1）</strong> – 评分：7.0</p>\n<p>读后评：介绍计算机网络的比较基础的一本书，在学校或多或少都学过，这里不展开讲了。如果在互联网公司，还是请看第二卷、三卷吧。</p>\n<p>(2)Java编程思想</p>\n<p>(3)Python CookBook</p>\n<p>(4) 大型网站技术架构 – 核心原理与案例分析</p>\n<p>(4) 本色（乐嘉）</p>\n<p>读后评：通过各方面的了解，我还是比较喜欢乐嘉这个人的，他写的这本书买来读了一下，很是通透。<br>(6) <strong>请给我结果</strong></p>\n<p>读后评：直白的语言，有些地方不适合互联网公司。<br>(7)<strong>番茄工作方法图解</strong></p>\n<p>读后评：经典的方法，以番茄钟来高效的利用自己的时间，尝试了一段时间。但是，还是被自己码代码的投入忘了时间。<br>(8)<strong>黑客与画家</strong></p>\n<p>读后评：我对这本书印象最深的是关于财富、创业、语言的部分，很深刻，有共鸣。</p>\n<p>(9) <strong>三体</strong> – 刘慈欣</p>\n<p>读后评：在一开始就深深的吸引了我，花了一个周末看完了，其中各种的问题真的很令人深思！</p>\n<p>(10) <strong>趁年轻，折腾吧（袁岳）</strong></p>\n<p>读后评：一句话概括：趁年轻，折腾吧！！ 推荐一读</p>\n<p>(11) <strong>看见（柴静）</strong></p>\n<p>读后评：以自己的经历（看见的）讲到的近几年的各种事情，让我看到了当年各个事件的另一个方面（好的或者坏的或者更坏的）。推荐阅读</p>\n<h2 id=\"Paper\"><a href=\"#Paper\" class=\"headerlink\" title=\"Paper\"></a>Paper</h2><p>(1) Bigtable:A Distributed Storage System for Structured Data (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgbigtable-osdi06.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(2) GFS:The Google File System (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orggfs-sosp2003.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(3) MapReduce:MapReduce: Simplied Data Processing on Large Clusters (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgmapreduce-osdi04.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(4) Spanner:Google’s Globally-Distributed Database (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgspanner-osdi2012.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(5) Megastore: Providing Scalable, Highly Available Storage for Interactive Services (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgmegastore.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(6) Pregel:A System for Large-Scale Graph Processing (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgPregel.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(7) Dremel: Interactive Analysis of Web-Scale Datasets (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgDremel.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(8) Caffeine: Large-scale Incremental Processing Using Distributed Transactions and Notications (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgCaffeine%20-1.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(9) Search The Web (<a href=\"http://document-save.qiniudn.com/web%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%A6%82%E8%AE%BA%E2%80%94%E2%80%94searching_the_web.pdf\" target=\"_blank\" rel=\"external\">download</a>)</p>\n"},{"title":"Search","id":1842,"comment":false,"date":"2017-05-22T04:05:33.000Z","_content":"","source":"search/index.md","raw":"---\ntitle: Search\nid: 1842\ncomment: false\ndate: 2017-05-22 12:05:33\n---\n","updated":"2017-09-26T03:12:12.000Z","path":"search/index.html","comments":1,"layout":"page","_id":"cj814lkcq0007pjs6igh0afuw","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"resys","date":"2017-09-26T01:52:24.000Z","_content":"### 自己动手打造推荐系统系列\n\n包含论文阅读和代码实现","source":"resys/index.md","raw":"title: resys\ndate: 2017-09-26 09:52:24\n---\n### 自己动手打造推荐系统系列\n\n包含论文阅读和代码实现","updated":"2017-09-26T03:12:13.000Z","path":"resys/index.html","comments":1,"layout":"page","_id":"cj814lkcs0009pjs6sl2utoxy","content":"<h3 id=\"自己动手打造推荐系统系列\"><a href=\"#自己动手打造推荐系统系列\" class=\"headerlink\" title=\"自己动手打造推荐系统系列\"></a>自己动手打造推荐系统系列</h3><p>包含论文阅读和代码实现</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"自己动手打造推荐系统系列\"><a href=\"#自己动手打造推荐系统系列\" class=\"headerlink\" title=\"自己动手打造推荐系统系列\"></a>自己动手打造推荐系统系列</h3><p>包含论文阅读和代码实现</p>\n"},{"title":"Tags","layout":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: Tags\nlayout: tags\n---\n","date":"2017-09-26T03:12:13.000Z","updated":"2017-09-26T03:12:13.000Z","path":"tags/index.html","comments":1,"_id":"cj814lkct000cpjs66u86l7cz","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"How to be a Geeker?","id":"1945","date":"2017-06-03T05:50:17.000Z","_content":"\n看到这篇以前的文章，回忆一下，2014年7月毕业开始了北漂的\"码农\"的生活，有幸被公司邀请写一篇文章，随写之。\n\n非常感谢@内部沟通部发来的约稿邮件，让我聊一聊程序员的那些事儿。作为一名程序猿，有很多有关技术方面的ideas可以拿来和大家进行分享和探讨。我是一个特别爱折腾的人，对于新技术、新产品都会去尝试一下，所以在技术学习、工作、程序开发方面，我有一些想法，和大家交流一下。\n\n1.做自己`喜欢并且擅长`的事情\n这句话是我在一位技术大牛身上学到的，我们每做一个件事情都是有驱动的，如果你做了自己喜欢并且擅长的事情，那很可能取得你想要的成功。在雏鹰培训的时候，吴正老师给我们上的培训叫发现自己的优势，我觉得很有意义，可以找到自己优势和不足，让我们在擅长的方面找到自己喜欢去做的，并且将它做到极致，那也是一种成功，一种geek精神的体现吧。\n\n2.做一个自己的技术博客\n作为一个技术人，搭建一个属于自己的博客是很有意思和意义的事情。在搭建博客的过程中你可以学习到一些技术知识，比如域名解析、博客主机配置、编写博客程序等等，自由度非常大，动手去实现收获也是非常巨大的。当自己对某些技术有独到的见解可以通过博客的形式分享出去和别人交流。在做博客的过程中，我也会去关注圈内大牛的技术博客（酷壳等）、百度，阿里等官方博客，RSS订阅一些博客，随时学习和接触领域中的新知识。\n\n3.怎样迅速加入一个技术圈\n如果在某一领域是技术“小白”，怎么才能够迅速加入呢。你可以从以下两个方面入手。一是是自我学习，二是和该领域中的技术牛人交流。\n自我学习方式我在实践中总结了一下:\n\n*   Wiki，了解其介绍、使用、API、文档等等；\n*   Presentation，学习大牛的技术分享，特别推荐slideshare.net；\n*   Paper，技术领域都有很多的paper可以去深入学习，比如在大数据领域中google的“前三后三”6篇经典论文；\n*   Video，一提这个可能会想到网易公开课等视频网站，但我会更加推荐你去Youtube或者confreaks.com，特别强大和丰富；\n*   Blog，关注该领域大牛的博客。\n\n当自我学习到一定程度时，你可能希望和这些大牛进行“有深度”的交流，但是如何去找到这些大牛呢？首先google一下该领域大牛，在facebook、twitter、Boogle（maybe sina）中找到，由他们可以带你进入一个Group，此时，可以说你加入了这个技术圈（更重要的是去研究、交流，而不是止于形式）。\n\n4.一天可以学会的实用技能\n如果给你一天时间，你能学会哪些实用的计算机相关技能？这是我在Quora看到的一个问题，下面有很多的回复。我曾经尝试去做过一些，比如学会正则表达式、写一个网络爬虫，解析基本数据等等，可能你会觉得某些技术难，不好下手，不妨试试这种带有挑战意义的方式。尝试后你可能就会发现学习技术并不是不难，只要你有兴趣去发现、去尝试、去研究！\n\n5.我们不只是会写代码的程序员\n如果说掌握一门技术是我们的首要任务的话，那么，我认为技术人员要学会一些更重要的东西，不是技术，而是业务、交流与协作。如果立志要成为一名架构师，后面的是我们更需要学习的东西。架构师需要根据业务需求和扩展，能够了解其未来的发展趋势，理解架构系统所涉及的方方面面，才能设计出更可靠安全的的系统架构。所以我们不要把程序员定位为写代码一类人，我们是发现新技术、创造新产品的superman。\n\n不知不觉已经写了好多内容，还有很多想和大家分享的东西没有讲到，限于篇幅我就不展开讨论了，欢迎大家随时和我进行分享交流，共同进步成为大牛！","source":"_posts/how-to-be-a-geeker.md","raw":"---\ntitle: How to be a Geeker?\ntags:\n  - geeker\nid: 1945\ncategories:\n  - Thought\ndate: 2017-06-03 13:50:17\n---\n\n看到这篇以前的文章，回忆一下，2014年7月毕业开始了北漂的\"码农\"的生活，有幸被公司邀请写一篇文章，随写之。\n\n非常感谢@内部沟通部发来的约稿邮件，让我聊一聊程序员的那些事儿。作为一名程序猿，有很多有关技术方面的ideas可以拿来和大家进行分享和探讨。我是一个特别爱折腾的人，对于新技术、新产品都会去尝试一下，所以在技术学习、工作、程序开发方面，我有一些想法，和大家交流一下。\n\n1.做自己`喜欢并且擅长`的事情\n这句话是我在一位技术大牛身上学到的，我们每做一个件事情都是有驱动的，如果你做了自己喜欢并且擅长的事情，那很可能取得你想要的成功。在雏鹰培训的时候，吴正老师给我们上的培训叫发现自己的优势，我觉得很有意义，可以找到自己优势和不足，让我们在擅长的方面找到自己喜欢去做的，并且将它做到极致，那也是一种成功，一种geek精神的体现吧。\n\n2.做一个自己的技术博客\n作为一个技术人，搭建一个属于自己的博客是很有意思和意义的事情。在搭建博客的过程中你可以学习到一些技术知识，比如域名解析、博客主机配置、编写博客程序等等，自由度非常大，动手去实现收获也是非常巨大的。当自己对某些技术有独到的见解可以通过博客的形式分享出去和别人交流。在做博客的过程中，我也会去关注圈内大牛的技术博客（酷壳等）、百度，阿里等官方博客，RSS订阅一些博客，随时学习和接触领域中的新知识。\n\n3.怎样迅速加入一个技术圈\n如果在某一领域是技术“小白”，怎么才能够迅速加入呢。你可以从以下两个方面入手。一是是自我学习，二是和该领域中的技术牛人交流。\n自我学习方式我在实践中总结了一下:\n\n*   Wiki，了解其介绍、使用、API、文档等等；\n*   Presentation，学习大牛的技术分享，特别推荐slideshare.net；\n*   Paper，技术领域都有很多的paper可以去深入学习，比如在大数据领域中google的“前三后三”6篇经典论文；\n*   Video，一提这个可能会想到网易公开课等视频网站，但我会更加推荐你去Youtube或者confreaks.com，特别强大和丰富；\n*   Blog，关注该领域大牛的博客。\n\n当自我学习到一定程度时，你可能希望和这些大牛进行“有深度”的交流，但是如何去找到这些大牛呢？首先google一下该领域大牛，在facebook、twitter、Boogle（maybe sina）中找到，由他们可以带你进入一个Group，此时，可以说你加入了这个技术圈（更重要的是去研究、交流，而不是止于形式）。\n\n4.一天可以学会的实用技能\n如果给你一天时间，你能学会哪些实用的计算机相关技能？这是我在Quora看到的一个问题，下面有很多的回复。我曾经尝试去做过一些，比如学会正则表达式、写一个网络爬虫，解析基本数据等等，可能你会觉得某些技术难，不好下手，不妨试试这种带有挑战意义的方式。尝试后你可能就会发现学习技术并不是不难，只要你有兴趣去发现、去尝试、去研究！\n\n5.我们不只是会写代码的程序员\n如果说掌握一门技术是我们的首要任务的话，那么，我认为技术人员要学会一些更重要的东西，不是技术，而是业务、交流与协作。如果立志要成为一名架构师，后面的是我们更需要学习的东西。架构师需要根据业务需求和扩展，能够了解其未来的发展趋势，理解架构系统所涉及的方方面面，才能设计出更可靠安全的的系统架构。所以我们不要把程序员定位为写代码一类人，我们是发现新技术、创造新产品的superman。\n\n不知不觉已经写了好多内容，还有很多想和大家分享的东西没有讲到，限于篇幅我就不展开讨论了，欢迎大家随时和我进行分享交流，共同进步成为大牛！","slug":"how-to-be-a-geeker","published":1,"updated":"2017-09-26T03:12:13.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj814lkce0000pjs6jwpjkson","content":"<p>看到这篇以前的文章，回忆一下，2014年7月毕业开始了北漂的”码农”的生活，有幸被公司邀请写一篇文章，随写之。</p>\n<p>非常感谢@内部沟通部发来的约稿邮件，让我聊一聊程序员的那些事儿。作为一名程序猿，有很多有关技术方面的ideas可以拿来和大家进行分享和探讨。我是一个特别爱折腾的人，对于新技术、新产品都会去尝试一下，所以在技术学习、工作、程序开发方面，我有一些想法，和大家交流一下。</p>\n<p>1.做自己<code>喜欢并且擅长</code>的事情<br>这句话是我在一位技术大牛身上学到的，我们每做一个件事情都是有驱动的，如果你做了自己喜欢并且擅长的事情，那很可能取得你想要的成功。在雏鹰培训的时候，吴正老师给我们上的培训叫发现自己的优势，我觉得很有意义，可以找到自己优势和不足，让我们在擅长的方面找到自己喜欢去做的，并且将它做到极致，那也是一种成功，一种geek精神的体现吧。</p>\n<p>2.做一个自己的技术博客<br>作为一个技术人，搭建一个属于自己的博客是很有意思和意义的事情。在搭建博客的过程中你可以学习到一些技术知识，比如域名解析、博客主机配置、编写博客程序等等，自由度非常大，动手去实现收获也是非常巨大的。当自己对某些技术有独到的见解可以通过博客的形式分享出去和别人交流。在做博客的过程中，我也会去关注圈内大牛的技术博客（酷壳等）、百度，阿里等官方博客，RSS订阅一些博客，随时学习和接触领域中的新知识。</p>\n<p>3.怎样迅速加入一个技术圈<br>如果在某一领域是技术“小白”，怎么才能够迅速加入呢。你可以从以下两个方面入手。一是是自我学习，二是和该领域中的技术牛人交流。<br>自我学习方式我在实践中总结了一下:</p>\n<ul>\n<li>Wiki，了解其介绍、使用、API、文档等等；</li>\n<li>Presentation，学习大牛的技术分享，特别推荐slideshare.net；</li>\n<li>Paper，技术领域都有很多的paper可以去深入学习，比如在大数据领域中google的“前三后三”6篇经典论文；</li>\n<li>Video，一提这个可能会想到网易公开课等视频网站，但我会更加推荐你去Youtube或者confreaks.com，特别强大和丰富；</li>\n<li>Blog，关注该领域大牛的博客。</li>\n</ul>\n<p>当自我学习到一定程度时，你可能希望和这些大牛进行“有深度”的交流，但是如何去找到这些大牛呢？首先google一下该领域大牛，在facebook、twitter、Boogle（maybe sina）中找到，由他们可以带你进入一个Group，此时，可以说你加入了这个技术圈（更重要的是去研究、交流，而不是止于形式）。</p>\n<p>4.一天可以学会的实用技能<br>如果给你一天时间，你能学会哪些实用的计算机相关技能？这是我在Quora看到的一个问题，下面有很多的回复。我曾经尝试去做过一些，比如学会正则表达式、写一个网络爬虫，解析基本数据等等，可能你会觉得某些技术难，不好下手，不妨试试这种带有挑战意义的方式。尝试后你可能就会发现学习技术并不是不难，只要你有兴趣去发现、去尝试、去研究！</p>\n<p>5.我们不只是会写代码的程序员<br>如果说掌握一门技术是我们的首要任务的话，那么，我认为技术人员要学会一些更重要的东西，不是技术，而是业务、交流与协作。如果立志要成为一名架构师，后面的是我们更需要学习的东西。架构师需要根据业务需求和扩展，能够了解其未来的发展趋势，理解架构系统所涉及的方方面面，才能设计出更可靠安全的的系统架构。所以我们不要把程序员定位为写代码一类人，我们是发现新技术、创造新产品的superman。</p>\n<p>不知不觉已经写了好多内容，还有很多想和大家分享的东西没有讲到，限于篇幅我就不展开讨论了，欢迎大家随时和我进行分享交流，共同进步成为大牛！</p>\n","site":{"data":{}},"excerpt":"","more":"<p>看到这篇以前的文章，回忆一下，2014年7月毕业开始了北漂的”码农”的生活，有幸被公司邀请写一篇文章，随写之。</p>\n<p>非常感谢@内部沟通部发来的约稿邮件，让我聊一聊程序员的那些事儿。作为一名程序猿，有很多有关技术方面的ideas可以拿来和大家进行分享和探讨。我是一个特别爱折腾的人，对于新技术、新产品都会去尝试一下，所以在技术学习、工作、程序开发方面，我有一些想法，和大家交流一下。</p>\n<p>1.做自己<code>喜欢并且擅长</code>的事情<br>这句话是我在一位技术大牛身上学到的，我们每做一个件事情都是有驱动的，如果你做了自己喜欢并且擅长的事情，那很可能取得你想要的成功。在雏鹰培训的时候，吴正老师给我们上的培训叫发现自己的优势，我觉得很有意义，可以找到自己优势和不足，让我们在擅长的方面找到自己喜欢去做的，并且将它做到极致，那也是一种成功，一种geek精神的体现吧。</p>\n<p>2.做一个自己的技术博客<br>作为一个技术人，搭建一个属于自己的博客是很有意思和意义的事情。在搭建博客的过程中你可以学习到一些技术知识，比如域名解析、博客主机配置、编写博客程序等等，自由度非常大，动手去实现收获也是非常巨大的。当自己对某些技术有独到的见解可以通过博客的形式分享出去和别人交流。在做博客的过程中，我也会去关注圈内大牛的技术博客（酷壳等）、百度，阿里等官方博客，RSS订阅一些博客，随时学习和接触领域中的新知识。</p>\n<p>3.怎样迅速加入一个技术圈<br>如果在某一领域是技术“小白”，怎么才能够迅速加入呢。你可以从以下两个方面入手。一是是自我学习，二是和该领域中的技术牛人交流。<br>自我学习方式我在实践中总结了一下:</p>\n<ul>\n<li>Wiki，了解其介绍、使用、API、文档等等；</li>\n<li>Presentation，学习大牛的技术分享，特别推荐slideshare.net；</li>\n<li>Paper，技术领域都有很多的paper可以去深入学习，比如在大数据领域中google的“前三后三”6篇经典论文；</li>\n<li>Video，一提这个可能会想到网易公开课等视频网站，但我会更加推荐你去Youtube或者confreaks.com，特别强大和丰富；</li>\n<li>Blog，关注该领域大牛的博客。</li>\n</ul>\n<p>当自我学习到一定程度时，你可能希望和这些大牛进行“有深度”的交流，但是如何去找到这些大牛呢？首先google一下该领域大牛，在facebook、twitter、Boogle（maybe sina）中找到，由他们可以带你进入一个Group，此时，可以说你加入了这个技术圈（更重要的是去研究、交流，而不是止于形式）。</p>\n<p>4.一天可以学会的实用技能<br>如果给你一天时间，你能学会哪些实用的计算机相关技能？这是我在Quora看到的一个问题，下面有很多的回复。我曾经尝试去做过一些，比如学会正则表达式、写一个网络爬虫，解析基本数据等等，可能你会觉得某些技术难，不好下手，不妨试试这种带有挑战意义的方式。尝试后你可能就会发现学习技术并不是不难，只要你有兴趣去发现、去尝试、去研究！</p>\n<p>5.我们不只是会写代码的程序员<br>如果说掌握一门技术是我们的首要任务的话，那么，我认为技术人员要学会一些更重要的东西，不是技术，而是业务、交流与协作。如果立志要成为一名架构师，后面的是我们更需要学习的东西。架构师需要根据业务需求和扩展，能够了解其未来的发展趋势，理解架构系统所涉及的方方面面，才能设计出更可靠安全的的系统架构。所以我们不要把程序员定位为写代码一类人，我们是发现新技术、创造新产品的superman。</p>\n<p>不知不觉已经写了好多内容，还有很多想和大家分享的东西没有讲到，限于篇幅我就不展开讨论了，欢迎大家随时和我进行分享交流，共同进步成为大牛！</p>\n"},{"title":"test","author":"Atlas","author_id":"Atlas","date":"2017-09-26T02:47:00.000Z","language":null,"_content":"\n# 推荐系统杂谈\n\ntest test\n test test test\n test\n test\n test\n test\n test\n \n首先需要明确的就是推荐系统的目标，一般来说不外乎以下几个：\n\n- **用户满意性**：首当其冲的，推荐系统主要就是为了满足用户的需求，因此准确率是评判一个推荐系统好坏的最关键指标。\n- **多样性**：虽然推荐系统最主要还是满足用户的兴趣，但是也要兼顾内容的多样性，对于权重不同的兴趣都要做到兼顾。\n- 新颖性：用户看到的内容是那些他们之前没有听说过的物品。简单的做法就是在推荐列表去掉用户之前有过行为的那些内容。\n- 惊喜度：和新颖性类似，但新颖性只是用户没看到过的但是确实是和他行为是相关的，而惊喜度是用户既没有看过和他之前的行为也不相关，但用户看到后的确是喜欢的。\n- 实时性：推荐系统要根据用户的上下文来实时更新推荐内容，用户的兴趣也是随着时间而改变的，需要实时更新。\n- 推荐透明度：对于用户看到的最终结果，要让用户知道推荐此内容的原因。比如，“买过这本书的人同时也买过”、”你购买过的xx和此商品类似”。\n- 覆盖率：挖掘长尾内容也是推荐系统很重要的目标。因此，推荐的内容覆盖到的内容越多越好。\n\n基于这些目标，推荐系统包括四种推荐方式：\n\n- 热门推荐：就是热门排行榜的概念。这种推荐方式不仅仅在IT系统，在平常的生活中也是处处存在的。这应该是效果最好的一种推荐方式，毕竟热门推荐的物品都是位于曝光量比较高的位置的。\n- 人工推荐：人工干预的推荐内容。相比于依赖热门和算法来进行推荐。一些热点时事如世界杯、nba总决赛等就需要人工加入推荐列表。另一方面，热点新闻带来的推荐效果也是很高的。\n- 相关推荐：相关推荐有点类似于关联规则的个性化推荐，就是在你阅读一个内容的时候，会提示你阅读与此相关的内容。\n- 个性化推荐：基于用户的历史行为做出的内容推荐。也是本文主要讲述的内容。\n\n其中，前三者是和机器学习没有任何关系的，但却是推荐效果最好的三种方式。一般说来，这部分内容应该占到总的推荐内容的80%左右，另外20%则是对长尾内容的个性化推荐。\n\n## 个性化推荐系统\n\n个性化推荐是机器学习应用的一个典型场景。在本质上和搜索引擎是一样的，同样是为了解决信息过载的问题。搜索引擎某种意义上也是一个个性化推荐系统，但是其输入特征是可以从搜索关键字直接可以得到的。而一般的推荐系统，输入特征则是需要机器学习才能得到。\n\n个性化推荐系统一般由日志系统、推荐算法、内容展示UI三部分组成。\n\n日志系统：这是推荐系统的输入源，是一个推荐系统所有信息的源头。\n\n推荐算法：这是推荐系统的核心，根据输入数据得出最终的推荐结果的具体过程就在这里。\n\n内容展示UI：对于推荐结果如何展示，也是一个值得权衡的地方。以更好地满足推荐系统的目标，并能更好的收集用户的行为信息等。\n\n其中，个性化推荐中最为核心的推荐算法，目前比较流行的有以下几种：\n\n基于内容的推荐：根据内容本身的属性(特征向量)所作的推荐。\n\n基于关联规则的推荐：“啤酒与尿布”的方式，是一种动态的推荐，能够实时对用户的行为作出推荐。是基于物品之间的特征关联性所做的推荐，在某种情况下会退化为物品协同过滤推荐。\n\n协同过滤推荐：与基于关联规则的推荐相比是一种静态方式的推荐，是根据用户已有的历史行为作分析的基础上做的推荐。可分为物品协同过滤、用户协同过滤、基于模型的协同过滤。其中，基于模型的协同又可以分为以下几种类型：基于距离的协同过滤；基于矩阵分解的协同过滤，即Latent Factor Model(SVD)；基于图模型协同，即Graph，也叫社会网络图模型。\n\n个性化推荐系统的典型架构如下图所示:\n\t![](media/14916210822379/14916212822908.jpg)\n在线业务系统的日志接入数据高速公路，再由数据高速公路迅速运转到离线数据处理平台和在线流计算平台；离线数据处理平台周期性地以批处理方式加工过去一段时间的数据，得到人群标签和其他模型参数，存放在高速缓存中，供在线业务系统使用，与此同时，在线流计算平台实时对线上的日志数据做处理，对离线计算出的数据进行补充、修正等；在线业务系统综合离线特征和在线特征使用一定的逻辑得到输出供业务使用，产生的日志流入数据高速公路。\n\n基于此框架，个性化推荐系统的典型流程如下所示：\n![](media/14916210822379/14916213291910.jpg)\n可知，一个推荐系统主要有以下模块组成：\n\n用户行为日志：此部分主要是用户行为日志的存储，属于数据统计的一部分, 存储在hive中。在此不做赘述。\n\n数据ETL-1：将用户日志转换为推荐算法所需要的数据格式。\n\n推荐算法：是个性化推荐最主要的部分，包括通过用户行为计算相关内容以及推荐结果等。\n\n数据ETL-2: 将推荐算法得到的结果进一步加工为存储模块的输入数据。\n\n用户画像存储：存储用户的偏好以及行为数据，如对内容关键字的偏好、点击过哪些内容等。\n\n推荐结果存储：存储各种推荐算法产生的推荐结果，可以分为两部分：{用户 : itemList}推荐结果，为用户推荐的内容列表；{item : itemList}推荐结果，与item相关的内容列表。\n\n服务调用模块：整合推荐结构，对外提供提供推荐的调用接口。\n\n### 数据ETL-1\n\n对原始的用户行为等数据进行清洗、加工，如字段、属性、格式化等，作为下一步推荐算法的输入。\n\n### 推荐算法\n\n对于个性化推荐系统来说，推荐算法应该是其最核心的部分。目前有很多流行的算法，比如：\n\n基于内容和用户画像的推荐：此种算法，可见之前的一篇文章：http://www.rowkey.me/blog/2016/04/07/up-recommend/。\n\n基于矩阵分解的推荐: 基于SVD/ALS算法对用户进行内容推荐。相比起SVD，ALS更加适合解决稀疏矩阵的问题。Spark mlib中已经集成了对als算法的实现，需要做的就是在etl-1中把数据转换为als需要的数据格式以及调整als算法的各种参数。这里有一篇文章比较具体地描述了如何使用spark来做基于ALS的推荐：http://colobu.com/2015/11/30/movie-recommendation-for-douban-users-by-spark-mllib/。\n\n用户&物品协同过滤推荐：包括UserBased CF和ItemBased CF。对于这两者，需要根据业务的不同来选择不同的算法。当用户非常多的时候，考虑到维护用户矩阵的成本，一般是不推荐选择用户协同过滤的，而对于候选item很多的时候，则不推荐使用物品协同过滤。\n\n推荐算法的输出结果一般是一个用户对应一个item列表或者是一个item对应一个item列表。此部分主要考虑的是算法的时间复杂度，不管是哪一种算法，一旦用户或者内容数据上了百万级别，都需要通过分布式计算如MapReduce、Spark等来进行解决。\n\n推荐算法的基本流程如下图所示：\n![](media/14916210822379/14916213667849.jpg)\n\n### 数据ETL-2\n\n对推荐算法产生的结果进行清洗、格式化等，作为下一步存储模块的输入。\n\n### 用户画像存储\n\n存储用户的偏好以及行为数据等信息。对于偏好，采用标签量化来表示，是一种随着时间衰减的值。对于用户画像，是批量写入、实时读取，所以存储要着重考虑读的性能。可以选择使用Redis集群作为技术方案，能够最大满足读的性能，缺点是Redis的成本昂贵且不支持auto index。也可使用Hbase作为存储，使用ElasricSearch构建二级索引，以应对根据多种维度聚集用户的需求(比如过滤某一个标签下的所有用户)。\n\n### 推荐结果存储\n\n对各种推荐算法计算出的推荐结果的存储。存储空间要求大，格式复杂。对于存储的容量和读写性能要求都比较高。可以选择使用Redis集群作为此部分的存储方案。\n\n### 服务调用\n\n整合用户画像和推荐结果两部分数据，向外提供推荐调用的接口。主要是数据库IO调用开销。\n\n根据用户id，获取推荐的item列表。\n\n根据item，获取相关联的item列表。\n\n根据用户id, 获取用户画像。\n\n该模块需要采取一定的策略聚合多种推荐算法的推荐结果，直接面向业务。策略由于会随着面向的业务不同而不同，需要可配置化。同时也提供对外暴露用户画像的接口，使得业务方可以使用用户画像做针对性的处理。可以采用RPC机制对外暴露服务接口。\n\n### 需要考虑的问题\n\n对于一个推荐系统，结合其实现目标，还有一些需要注重考虑的问题。\n\n#### 实时性问题\n\n由于计算用户、item矩阵或者进行矩阵分解是需要离线进行且比较耗时，因此协同的推荐算法是很难达到实时性的。实时部分的推荐主要依靠基于用户画像的推荐来进行。最终的推荐列表是根据一定的策略对这两部分进行聚合的结果。\n\n#### 时效性内容问题\n\n时效性内容指的是那些与时间强相关的内容，比如新闻、时事等。如果一条10天前xx球员获得冠军的新闻现在被推荐了出来，可想用户肯定是莫名其妙或者是很失望的。因此，对于时效性内容，需要与普通的待推荐的内容区分开，做单独的推荐或者不走个性化推荐。\n\n#### 冷启动问题\n\n不管使用何种推荐算法，都会面临冷启动问题：当用户是新用户，如何给用户推荐item呢？当内容是新内容，如何推荐给用户？\n\n对于新用户，可以采取的一种策略就是采用热门推荐或者人工推荐，把绝大多人关心的内容推荐出来。\n\n对于内容，可以将内容分为新内容池和待推荐内容池。新内容产生时，首先进入新内容池。每次推荐的时候，先从新内容池做候选推荐，并给此内容的传播度+1，直到其传播度大于一个阈值的时候，将其移至待推荐内容池。这样既可以解决新内容的冷启动问题也在一定程度上可以保证新内容的曝光量。\n\n#### 多样性问题\n\n在基于用户画像的推荐算法中，取出用户的多个标签，然后根据相关度从不同的标签中取不同数量的内容，这样既兼顾了用户的多种兴趣也能够在一定程度上解决多样性的问题。\n\n如：用户具有tag:A B C D,相关度为wA wB wC wD，Total推荐为总共需要推荐的条数，那么\n\nRecommendList(u) = A[Total推荐 * wA] + B[Total推荐 * wB] + C[Total推荐 * wC] + D[Total推荐 * wD]\n\n#### 内容质量\n\n不管是热门推荐、人工推荐还是取某一标签下的内容列表都牵扯到的一个问题就是：如何给内容排序？\n\n当用户对内容的喜好不一样，可以按照兴趣度来排序；但当无法区分兴趣度的时候(比如：用户是新用户；内容都是新内容；用户对于某一标签下的内容兴趣度一样)，可以使用内容质量来做排序。click/pv是一种评判内容质量的方式。此外，使用卷积神经网络相关算法也可以构建内容质量模型。\n\n#### 惊喜问题\n\n推荐系统的惊喜目标一直是一个难题，被称作EE(Exploit & Explore)问题，bandit算法是解决这个问题的一个派系，就是估计置信区间的做法，然后按照置信区间的上界来进行推荐，以UCB、LinUCB为代表的。简单点说就是先不考虑你喜不喜欢就把质量高的内容推荐给你，后面根据用户的行为反馈对推荐内容作调整。具体的可以参见此篇文章：推荐系统的苟且和远方。\n\n### 总结\n\n借用推荐系统的那点事一文的几句话做为结语：\n\n实力派的【算法工程师】往往都是ABC[always be coding]，这样的算法工程师才能根据实际问题建立模型或者建立规则库，是真正能解决问题的人。往往是一些有研究背景，经验丰富的研究员，更加重视工程，因为工程架构上一些恰当合理的设计，效果往往就能远远高过于模型算法优化。\n\n学院派的【算法工程师】往往是为了算法而算法，而不是为了解决推荐系统的问题去找最适合算法。这也是为什么大公司经常招了一些博士毕业的算法工程师后，不是研究算法而是让他们整天在那看数据报表？【因为发现算法没啥好研究，只能让他们在那看看报表找找规律了。】\n\n【几乎所有所谓的智能推荐算法都是花拳绣腿】\n\n当一个做推荐系统的部门开始重视【数据清理，数据标柱，效果评测，数据统计，数据分析】这些所谓的脏活累活，这样的推荐系统才会有救。\n\n","source":"_posts/test.md","raw":"---\ntitle: test\nauthor: Atlas\nauthor_id: Atlas\ntags:\n  - rec\ncategories:\n  - Thought\ndate: 2017-09-26 10:47:00\nlanguage:\n---\n\n# 推荐系统杂谈\n\ntest test\n test test test\n test\n test\n test\n test\n test\n \n首先需要明确的就是推荐系统的目标，一般来说不外乎以下几个：\n\n- **用户满意性**：首当其冲的，推荐系统主要就是为了满足用户的需求，因此准确率是评判一个推荐系统好坏的最关键指标。\n- **多样性**：虽然推荐系统最主要还是满足用户的兴趣，但是也要兼顾内容的多样性，对于权重不同的兴趣都要做到兼顾。\n- 新颖性：用户看到的内容是那些他们之前没有听说过的物品。简单的做法就是在推荐列表去掉用户之前有过行为的那些内容。\n- 惊喜度：和新颖性类似，但新颖性只是用户没看到过的但是确实是和他行为是相关的，而惊喜度是用户既没有看过和他之前的行为也不相关，但用户看到后的确是喜欢的。\n- 实时性：推荐系统要根据用户的上下文来实时更新推荐内容，用户的兴趣也是随着时间而改变的，需要实时更新。\n- 推荐透明度：对于用户看到的最终结果，要让用户知道推荐此内容的原因。比如，“买过这本书的人同时也买过”、”你购买过的xx和此商品类似”。\n- 覆盖率：挖掘长尾内容也是推荐系统很重要的目标。因此，推荐的内容覆盖到的内容越多越好。\n\n基于这些目标，推荐系统包括四种推荐方式：\n\n- 热门推荐：就是热门排行榜的概念。这种推荐方式不仅仅在IT系统，在平常的生活中也是处处存在的。这应该是效果最好的一种推荐方式，毕竟热门推荐的物品都是位于曝光量比较高的位置的。\n- 人工推荐：人工干预的推荐内容。相比于依赖热门和算法来进行推荐。一些热点时事如世界杯、nba总决赛等就需要人工加入推荐列表。另一方面，热点新闻带来的推荐效果也是很高的。\n- 相关推荐：相关推荐有点类似于关联规则的个性化推荐，就是在你阅读一个内容的时候，会提示你阅读与此相关的内容。\n- 个性化推荐：基于用户的历史行为做出的内容推荐。也是本文主要讲述的内容。\n\n其中，前三者是和机器学习没有任何关系的，但却是推荐效果最好的三种方式。一般说来，这部分内容应该占到总的推荐内容的80%左右，另外20%则是对长尾内容的个性化推荐。\n\n## 个性化推荐系统\n\n个性化推荐是机器学习应用的一个典型场景。在本质上和搜索引擎是一样的，同样是为了解决信息过载的问题。搜索引擎某种意义上也是一个个性化推荐系统，但是其输入特征是可以从搜索关键字直接可以得到的。而一般的推荐系统，输入特征则是需要机器学习才能得到。\n\n个性化推荐系统一般由日志系统、推荐算法、内容展示UI三部分组成。\n\n日志系统：这是推荐系统的输入源，是一个推荐系统所有信息的源头。\n\n推荐算法：这是推荐系统的核心，根据输入数据得出最终的推荐结果的具体过程就在这里。\n\n内容展示UI：对于推荐结果如何展示，也是一个值得权衡的地方。以更好地满足推荐系统的目标，并能更好的收集用户的行为信息等。\n\n其中，个性化推荐中最为核心的推荐算法，目前比较流行的有以下几种：\n\n基于内容的推荐：根据内容本身的属性(特征向量)所作的推荐。\n\n基于关联规则的推荐：“啤酒与尿布”的方式，是一种动态的推荐，能够实时对用户的行为作出推荐。是基于物品之间的特征关联性所做的推荐，在某种情况下会退化为物品协同过滤推荐。\n\n协同过滤推荐：与基于关联规则的推荐相比是一种静态方式的推荐，是根据用户已有的历史行为作分析的基础上做的推荐。可分为物品协同过滤、用户协同过滤、基于模型的协同过滤。其中，基于模型的协同又可以分为以下几种类型：基于距离的协同过滤；基于矩阵分解的协同过滤，即Latent Factor Model(SVD)；基于图模型协同，即Graph，也叫社会网络图模型。\n\n个性化推荐系统的典型架构如下图所示:\n\t![](media/14916210822379/14916212822908.jpg)\n在线业务系统的日志接入数据高速公路，再由数据高速公路迅速运转到离线数据处理平台和在线流计算平台；离线数据处理平台周期性地以批处理方式加工过去一段时间的数据，得到人群标签和其他模型参数，存放在高速缓存中，供在线业务系统使用，与此同时，在线流计算平台实时对线上的日志数据做处理，对离线计算出的数据进行补充、修正等；在线业务系统综合离线特征和在线特征使用一定的逻辑得到输出供业务使用，产生的日志流入数据高速公路。\n\n基于此框架，个性化推荐系统的典型流程如下所示：\n![](media/14916210822379/14916213291910.jpg)\n可知，一个推荐系统主要有以下模块组成：\n\n用户行为日志：此部分主要是用户行为日志的存储，属于数据统计的一部分, 存储在hive中。在此不做赘述。\n\n数据ETL-1：将用户日志转换为推荐算法所需要的数据格式。\n\n推荐算法：是个性化推荐最主要的部分，包括通过用户行为计算相关内容以及推荐结果等。\n\n数据ETL-2: 将推荐算法得到的结果进一步加工为存储模块的输入数据。\n\n用户画像存储：存储用户的偏好以及行为数据，如对内容关键字的偏好、点击过哪些内容等。\n\n推荐结果存储：存储各种推荐算法产生的推荐结果，可以分为两部分：{用户 : itemList}推荐结果，为用户推荐的内容列表；{item : itemList}推荐结果，与item相关的内容列表。\n\n服务调用模块：整合推荐结构，对外提供提供推荐的调用接口。\n\n### 数据ETL-1\n\n对原始的用户行为等数据进行清洗、加工，如字段、属性、格式化等，作为下一步推荐算法的输入。\n\n### 推荐算法\n\n对于个性化推荐系统来说，推荐算法应该是其最核心的部分。目前有很多流行的算法，比如：\n\n基于内容和用户画像的推荐：此种算法，可见之前的一篇文章：http://www.rowkey.me/blog/2016/04/07/up-recommend/。\n\n基于矩阵分解的推荐: 基于SVD/ALS算法对用户进行内容推荐。相比起SVD，ALS更加适合解决稀疏矩阵的问题。Spark mlib中已经集成了对als算法的实现，需要做的就是在etl-1中把数据转换为als需要的数据格式以及调整als算法的各种参数。这里有一篇文章比较具体地描述了如何使用spark来做基于ALS的推荐：http://colobu.com/2015/11/30/movie-recommendation-for-douban-users-by-spark-mllib/。\n\n用户&物品协同过滤推荐：包括UserBased CF和ItemBased CF。对于这两者，需要根据业务的不同来选择不同的算法。当用户非常多的时候，考虑到维护用户矩阵的成本，一般是不推荐选择用户协同过滤的，而对于候选item很多的时候，则不推荐使用物品协同过滤。\n\n推荐算法的输出结果一般是一个用户对应一个item列表或者是一个item对应一个item列表。此部分主要考虑的是算法的时间复杂度，不管是哪一种算法，一旦用户或者内容数据上了百万级别，都需要通过分布式计算如MapReduce、Spark等来进行解决。\n\n推荐算法的基本流程如下图所示：\n![](media/14916210822379/14916213667849.jpg)\n\n### 数据ETL-2\n\n对推荐算法产生的结果进行清洗、格式化等，作为下一步存储模块的输入。\n\n### 用户画像存储\n\n存储用户的偏好以及行为数据等信息。对于偏好，采用标签量化来表示，是一种随着时间衰减的值。对于用户画像，是批量写入、实时读取，所以存储要着重考虑读的性能。可以选择使用Redis集群作为技术方案，能够最大满足读的性能，缺点是Redis的成本昂贵且不支持auto index。也可使用Hbase作为存储，使用ElasricSearch构建二级索引，以应对根据多种维度聚集用户的需求(比如过滤某一个标签下的所有用户)。\n\n### 推荐结果存储\n\n对各种推荐算法计算出的推荐结果的存储。存储空间要求大，格式复杂。对于存储的容量和读写性能要求都比较高。可以选择使用Redis集群作为此部分的存储方案。\n\n### 服务调用\n\n整合用户画像和推荐结果两部分数据，向外提供推荐调用的接口。主要是数据库IO调用开销。\n\n根据用户id，获取推荐的item列表。\n\n根据item，获取相关联的item列表。\n\n根据用户id, 获取用户画像。\n\n该模块需要采取一定的策略聚合多种推荐算法的推荐结果，直接面向业务。策略由于会随着面向的业务不同而不同，需要可配置化。同时也提供对外暴露用户画像的接口，使得业务方可以使用用户画像做针对性的处理。可以采用RPC机制对外暴露服务接口。\n\n### 需要考虑的问题\n\n对于一个推荐系统，结合其实现目标，还有一些需要注重考虑的问题。\n\n#### 实时性问题\n\n由于计算用户、item矩阵或者进行矩阵分解是需要离线进行且比较耗时，因此协同的推荐算法是很难达到实时性的。实时部分的推荐主要依靠基于用户画像的推荐来进行。最终的推荐列表是根据一定的策略对这两部分进行聚合的结果。\n\n#### 时效性内容问题\n\n时效性内容指的是那些与时间强相关的内容，比如新闻、时事等。如果一条10天前xx球员获得冠军的新闻现在被推荐了出来，可想用户肯定是莫名其妙或者是很失望的。因此，对于时效性内容，需要与普通的待推荐的内容区分开，做单独的推荐或者不走个性化推荐。\n\n#### 冷启动问题\n\n不管使用何种推荐算法，都会面临冷启动问题：当用户是新用户，如何给用户推荐item呢？当内容是新内容，如何推荐给用户？\n\n对于新用户，可以采取的一种策略就是采用热门推荐或者人工推荐，把绝大多人关心的内容推荐出来。\n\n对于内容，可以将内容分为新内容池和待推荐内容池。新内容产生时，首先进入新内容池。每次推荐的时候，先从新内容池做候选推荐，并给此内容的传播度+1，直到其传播度大于一个阈值的时候，将其移至待推荐内容池。这样既可以解决新内容的冷启动问题也在一定程度上可以保证新内容的曝光量。\n\n#### 多样性问题\n\n在基于用户画像的推荐算法中，取出用户的多个标签，然后根据相关度从不同的标签中取不同数量的内容，这样既兼顾了用户的多种兴趣也能够在一定程度上解决多样性的问题。\n\n如：用户具有tag:A B C D,相关度为wA wB wC wD，Total推荐为总共需要推荐的条数，那么\n\nRecommendList(u) = A[Total推荐 * wA] + B[Total推荐 * wB] + C[Total推荐 * wC] + D[Total推荐 * wD]\n\n#### 内容质量\n\n不管是热门推荐、人工推荐还是取某一标签下的内容列表都牵扯到的一个问题就是：如何给内容排序？\n\n当用户对内容的喜好不一样，可以按照兴趣度来排序；但当无法区分兴趣度的时候(比如：用户是新用户；内容都是新内容；用户对于某一标签下的内容兴趣度一样)，可以使用内容质量来做排序。click/pv是一种评判内容质量的方式。此外，使用卷积神经网络相关算法也可以构建内容质量模型。\n\n#### 惊喜问题\n\n推荐系统的惊喜目标一直是一个难题，被称作EE(Exploit & Explore)问题，bandit算法是解决这个问题的一个派系，就是估计置信区间的做法，然后按照置信区间的上界来进行推荐，以UCB、LinUCB为代表的。简单点说就是先不考虑你喜不喜欢就把质量高的内容推荐给你，后面根据用户的行为反馈对推荐内容作调整。具体的可以参见此篇文章：推荐系统的苟且和远方。\n\n### 总结\n\n借用推荐系统的那点事一文的几句话做为结语：\n\n实力派的【算法工程师】往往都是ABC[always be coding]，这样的算法工程师才能根据实际问题建立模型或者建立规则库，是真正能解决问题的人。往往是一些有研究背景，经验丰富的研究员，更加重视工程，因为工程架构上一些恰当合理的设计，效果往往就能远远高过于模型算法优化。\n\n学院派的【算法工程师】往往是为了算法而算法，而不是为了解决推荐系统的问题去找最适合算法。这也是为什么大公司经常招了一些博士毕业的算法工程师后，不是研究算法而是让他们整天在那看数据报表？【因为发现算法没啥好研究，只能让他们在那看看报表找找规律了。】\n\n【几乎所有所谓的智能推荐算法都是花拳绣腿】\n\n当一个做推荐系统的部门开始重视【数据清理，数据标柱，效果评测，数据统计，数据分析】这些所谓的脏活累活，这样的推荐系统才会有救。\n\n","slug":"test","published":1,"updated":"2017-09-26T05:20:00.000Z","_id":"cj814lkcl0002pjs6ah38leva","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"推荐系统杂谈\"><a href=\"#推荐系统杂谈\" class=\"headerlink\" title=\"推荐系统杂谈\"></a>推荐系统杂谈</h1><p>test test<br> test test test<br> test<br> test<br> test<br> test<br> test</p>\n<p>首先需要明确的就是推荐系统的目标，一般来说不外乎以下几个：</p>\n<ul>\n<li><strong>用户满意性</strong>：首当其冲的，推荐系统主要就是为了满足用户的需求，因此准确率是评判一个推荐系统好坏的最关键指标。</li>\n<li><strong>多样性</strong>：虽然推荐系统最主要还是满足用户的兴趣，但是也要兼顾内容的多样性，对于权重不同的兴趣都要做到兼顾。</li>\n<li>新颖性：用户看到的内容是那些他们之前没有听说过的物品。简单的做法就是在推荐列表去掉用户之前有过行为的那些内容。</li>\n<li>惊喜度：和新颖性类似，但新颖性只是用户没看到过的但是确实是和他行为是相关的，而惊喜度是用户既没有看过和他之前的行为也不相关，但用户看到后的确是喜欢的。</li>\n<li>实时性：推荐系统要根据用户的上下文来实时更新推荐内容，用户的兴趣也是随着时间而改变的，需要实时更新。</li>\n<li>推荐透明度：对于用户看到的最终结果，要让用户知道推荐此内容的原因。比如，“买过这本书的人同时也买过”、”你购买过的xx和此商品类似”。</li>\n<li>覆盖率：挖掘长尾内容也是推荐系统很重要的目标。因此，推荐的内容覆盖到的内容越多越好。</li>\n</ul>\n<p>基于这些目标，推荐系统包括四种推荐方式：</p>\n<ul>\n<li>热门推荐：就是热门排行榜的概念。这种推荐方式不仅仅在IT系统，在平常的生活中也是处处存在的。这应该是效果最好的一种推荐方式，毕竟热门推荐的物品都是位于曝光量比较高的位置的。</li>\n<li>人工推荐：人工干预的推荐内容。相比于依赖热门和算法来进行推荐。一些热点时事如世界杯、nba总决赛等就需要人工加入推荐列表。另一方面，热点新闻带来的推荐效果也是很高的。</li>\n<li>相关推荐：相关推荐有点类似于关联规则的个性化推荐，就是在你阅读一个内容的时候，会提示你阅读与此相关的内容。</li>\n<li>个性化推荐：基于用户的历史行为做出的内容推荐。也是本文主要讲述的内容。</li>\n</ul>\n<p>其中，前三者是和机器学习没有任何关系的，但却是推荐效果最好的三种方式。一般说来，这部分内容应该占到总的推荐内容的80%左右，另外20%则是对长尾内容的个性化推荐。</p>\n<h2 id=\"个性化推荐系统\"><a href=\"#个性化推荐系统\" class=\"headerlink\" title=\"个性化推荐系统\"></a>个性化推荐系统</h2><p>个性化推荐是机器学习应用的一个典型场景。在本质上和搜索引擎是一样的，同样是为了解决信息过载的问题。搜索引擎某种意义上也是一个个性化推荐系统，但是其输入特征是可以从搜索关键字直接可以得到的。而一般的推荐系统，输入特征则是需要机器学习才能得到。</p>\n<p>个性化推荐系统一般由日志系统、推荐算法、内容展示UI三部分组成。</p>\n<p>日志系统：这是推荐系统的输入源，是一个推荐系统所有信息的源头。</p>\n<p>推荐算法：这是推荐系统的核心，根据输入数据得出最终的推荐结果的具体过程就在这里。</p>\n<p>内容展示UI：对于推荐结果如何展示，也是一个值得权衡的地方。以更好地满足推荐系统的目标，并能更好的收集用户的行为信息等。</p>\n<p>其中，个性化推荐中最为核心的推荐算法，目前比较流行的有以下几种：</p>\n<p>基于内容的推荐：根据内容本身的属性(特征向量)所作的推荐。</p>\n<p>基于关联规则的推荐：“啤酒与尿布”的方式，是一种动态的推荐，能够实时对用户的行为作出推荐。是基于物品之间的特征关联性所做的推荐，在某种情况下会退化为物品协同过滤推荐。</p>\n<p>协同过滤推荐：与基于关联规则的推荐相比是一种静态方式的推荐，是根据用户已有的历史行为作分析的基础上做的推荐。可分为物品协同过滤、用户协同过滤、基于模型的协同过滤。其中，基于模型的协同又可以分为以下几种类型：基于距离的协同过滤；基于矩阵分解的协同过滤，即Latent Factor Model(SVD)；基于图模型协同，即Graph，也叫社会网络图模型。</p>\n<p>个性化推荐系统的典型架构如下图所示:<br>    <img src=\"media/14916210822379/14916212822908.jpg\" alt=\"\"><br>在线业务系统的日志接入数据高速公路，再由数据高速公路迅速运转到离线数据处理平台和在线流计算平台；离线数据处理平台周期性地以批处理方式加工过去一段时间的数据，得到人群标签和其他模型参数，存放在高速缓存中，供在线业务系统使用，与此同时，在线流计算平台实时对线上的日志数据做处理，对离线计算出的数据进行补充、修正等；在线业务系统综合离线特征和在线特征使用一定的逻辑得到输出供业务使用，产生的日志流入数据高速公路。</p>\n<p>基于此框架，个性化推荐系统的典型流程如下所示：<br><img src=\"media/14916210822379/14916213291910.jpg\" alt=\"\"><br>可知，一个推荐系统主要有以下模块组成：</p>\n<p>用户行为日志：此部分主要是用户行为日志的存储，属于数据统计的一部分, 存储在hive中。在此不做赘述。</p>\n<p>数据ETL-1：将用户日志转换为推荐算法所需要的数据格式。</p>\n<p>推荐算法：是个性化推荐最主要的部分，包括通过用户行为计算相关内容以及推荐结果等。</p>\n<p>数据ETL-2: 将推荐算法得到的结果进一步加工为存储模块的输入数据。</p>\n<p>用户画像存储：存储用户的偏好以及行为数据，如对内容关键字的偏好、点击过哪些内容等。</p>\n<p>推荐结果存储：存储各种推荐算法产生的推荐结果，可以分为两部分：{用户 : itemList}推荐结果，为用户推荐的内容列表；{item : itemList}推荐结果，与item相关的内容列表。</p>\n<p>服务调用模块：整合推荐结构，对外提供提供推荐的调用接口。</p>\n<h3 id=\"数据ETL-1\"><a href=\"#数据ETL-1\" class=\"headerlink\" title=\"数据ETL-1\"></a>数据ETL-1</h3><p>对原始的用户行为等数据进行清洗、加工，如字段、属性、格式化等，作为下一步推荐算法的输入。</p>\n<h3 id=\"推荐算法\"><a href=\"#推荐算法\" class=\"headerlink\" title=\"推荐算法\"></a>推荐算法</h3><p>对于个性化推荐系统来说，推荐算法应该是其最核心的部分。目前有很多流行的算法，比如：</p>\n<p>基于内容和用户画像的推荐：此种算法，可见之前的一篇文章：<a href=\"http://www.rowkey.me/blog/2016/04/07/up-recommend/。\" target=\"_blank\" rel=\"external\">http://www.rowkey.me/blog/2016/04/07/up-recommend/。</a></p>\n<p>基于矩阵分解的推荐: 基于SVD/ALS算法对用户进行内容推荐。相比起SVD，ALS更加适合解决稀疏矩阵的问题。Spark mlib中已经集成了对als算法的实现，需要做的就是在etl-1中把数据转换为als需要的数据格式以及调整als算法的各种参数。这里有一篇文章比较具体地描述了如何使用spark来做基于ALS的推荐：<a href=\"http://colobu.com/2015/11/30/movie-recommendation-for-douban-users-by-spark-mllib/。\" target=\"_blank\" rel=\"external\">http://colobu.com/2015/11/30/movie-recommendation-for-douban-users-by-spark-mllib/。</a></p>\n<p>用户&amp;物品协同过滤推荐：包括UserBased CF和ItemBased CF。对于这两者，需要根据业务的不同来选择不同的算法。当用户非常多的时候，考虑到维护用户矩阵的成本，一般是不推荐选择用户协同过滤的，而对于候选item很多的时候，则不推荐使用物品协同过滤。</p>\n<p>推荐算法的输出结果一般是一个用户对应一个item列表或者是一个item对应一个item列表。此部分主要考虑的是算法的时间复杂度，不管是哪一种算法，一旦用户或者内容数据上了百万级别，都需要通过分布式计算如MapReduce、Spark等来进行解决。</p>\n<p>推荐算法的基本流程如下图所示：<br><img src=\"media/14916210822379/14916213667849.jpg\" alt=\"\"></p>\n<h3 id=\"数据ETL-2\"><a href=\"#数据ETL-2\" class=\"headerlink\" title=\"数据ETL-2\"></a>数据ETL-2</h3><p>对推荐算法产生的结果进行清洗、格式化等，作为下一步存储模块的输入。</p>\n<h3 id=\"用户画像存储\"><a href=\"#用户画像存储\" class=\"headerlink\" title=\"用户画像存储\"></a>用户画像存储</h3><p>存储用户的偏好以及行为数据等信息。对于偏好，采用标签量化来表示，是一种随着时间衰减的值。对于用户画像，是批量写入、实时读取，所以存储要着重考虑读的性能。可以选择使用Redis集群作为技术方案，能够最大满足读的性能，缺点是Redis的成本昂贵且不支持auto index。也可使用Hbase作为存储，使用ElasricSearch构建二级索引，以应对根据多种维度聚集用户的需求(比如过滤某一个标签下的所有用户)。</p>\n<h3 id=\"推荐结果存储\"><a href=\"#推荐结果存储\" class=\"headerlink\" title=\"推荐结果存储\"></a>推荐结果存储</h3><p>对各种推荐算法计算出的推荐结果的存储。存储空间要求大，格式复杂。对于存储的容量和读写性能要求都比较高。可以选择使用Redis集群作为此部分的存储方案。</p>\n<h3 id=\"服务调用\"><a href=\"#服务调用\" class=\"headerlink\" title=\"服务调用\"></a>服务调用</h3><p>整合用户画像和推荐结果两部分数据，向外提供推荐调用的接口。主要是数据库IO调用开销。</p>\n<p>根据用户id，获取推荐的item列表。</p>\n<p>根据item，获取相关联的item列表。</p>\n<p>根据用户id, 获取用户画像。</p>\n<p>该模块需要采取一定的策略聚合多种推荐算法的推荐结果，直接面向业务。策略由于会随着面向的业务不同而不同，需要可配置化。同时也提供对外暴露用户画像的接口，使得业务方可以使用用户画像做针对性的处理。可以采用RPC机制对外暴露服务接口。</p>\n<h3 id=\"需要考虑的问题\"><a href=\"#需要考虑的问题\" class=\"headerlink\" title=\"需要考虑的问题\"></a>需要考虑的问题</h3><p>对于一个推荐系统，结合其实现目标，还有一些需要注重考虑的问题。</p>\n<h4 id=\"实时性问题\"><a href=\"#实时性问题\" class=\"headerlink\" title=\"实时性问题\"></a>实时性问题</h4><p>由于计算用户、item矩阵或者进行矩阵分解是需要离线进行且比较耗时，因此协同的推荐算法是很难达到实时性的。实时部分的推荐主要依靠基于用户画像的推荐来进行。最终的推荐列表是根据一定的策略对这两部分进行聚合的结果。</p>\n<h4 id=\"时效性内容问题\"><a href=\"#时效性内容问题\" class=\"headerlink\" title=\"时效性内容问题\"></a>时效性内容问题</h4><p>时效性内容指的是那些与时间强相关的内容，比如新闻、时事等。如果一条10天前xx球员获得冠军的新闻现在被推荐了出来，可想用户肯定是莫名其妙或者是很失望的。因此，对于时效性内容，需要与普通的待推荐的内容区分开，做单独的推荐或者不走个性化推荐。</p>\n<h4 id=\"冷启动问题\"><a href=\"#冷启动问题\" class=\"headerlink\" title=\"冷启动问题\"></a>冷启动问题</h4><p>不管使用何种推荐算法，都会面临冷启动问题：当用户是新用户，如何给用户推荐item呢？当内容是新内容，如何推荐给用户？</p>\n<p>对于新用户，可以采取的一种策略就是采用热门推荐或者人工推荐，把绝大多人关心的内容推荐出来。</p>\n<p>对于内容，可以将内容分为新内容池和待推荐内容池。新内容产生时，首先进入新内容池。每次推荐的时候，先从新内容池做候选推荐，并给此内容的传播度+1，直到其传播度大于一个阈值的时候，将其移至待推荐内容池。这样既可以解决新内容的冷启动问题也在一定程度上可以保证新内容的曝光量。</p>\n<h4 id=\"多样性问题\"><a href=\"#多样性问题\" class=\"headerlink\" title=\"多样性问题\"></a>多样性问题</h4><p>在基于用户画像的推荐算法中，取出用户的多个标签，然后根据相关度从不同的标签中取不同数量的内容，这样既兼顾了用户的多种兴趣也能够在一定程度上解决多样性的问题。</p>\n<p>如：用户具有tag:A B C D,相关度为wA wB wC wD，Total推荐为总共需要推荐的条数，那么</p>\n<p>RecommendList(u) = A[Total推荐 <em> wA] + B[Total推荐 </em> wB] + C[Total推荐 <em> wC] + D[Total推荐 </em> wD]</p>\n<h4 id=\"内容质量\"><a href=\"#内容质量\" class=\"headerlink\" title=\"内容质量\"></a>内容质量</h4><p>不管是热门推荐、人工推荐还是取某一标签下的内容列表都牵扯到的一个问题就是：如何给内容排序？</p>\n<p>当用户对内容的喜好不一样，可以按照兴趣度来排序；但当无法区分兴趣度的时候(比如：用户是新用户；内容都是新内容；用户对于某一标签下的内容兴趣度一样)，可以使用内容质量来做排序。click/pv是一种评判内容质量的方式。此外，使用卷积神经网络相关算法也可以构建内容质量模型。</p>\n<h4 id=\"惊喜问题\"><a href=\"#惊喜问题\" class=\"headerlink\" title=\"惊喜问题\"></a>惊喜问题</h4><p>推荐系统的惊喜目标一直是一个难题，被称作EE(Exploit &amp; Explore)问题，bandit算法是解决这个问题的一个派系，就是估计置信区间的做法，然后按照置信区间的上界来进行推荐，以UCB、LinUCB为代表的。简单点说就是先不考虑你喜不喜欢就把质量高的内容推荐给你，后面根据用户的行为反馈对推荐内容作调整。具体的可以参见此篇文章：推荐系统的苟且和远方。</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>借用推荐系统的那点事一文的几句话做为结语：</p>\n<p>实力派的【算法工程师】往往都是ABC[always be coding]，这样的算法工程师才能根据实际问题建立模型或者建立规则库，是真正能解决问题的人。往往是一些有研究背景，经验丰富的研究员，更加重视工程，因为工程架构上一些恰当合理的设计，效果往往就能远远高过于模型算法优化。</p>\n<p>学院派的【算法工程师】往往是为了算法而算法，而不是为了解决推荐系统的问题去找最适合算法。这也是为什么大公司经常招了一些博士毕业的算法工程师后，不是研究算法而是让他们整天在那看数据报表？【因为发现算法没啥好研究，只能让他们在那看看报表找找规律了。】</p>\n<p>【几乎所有所谓的智能推荐算法都是花拳绣腿】</p>\n<p>当一个做推荐系统的部门开始重视【数据清理，数据标柱，效果评测，数据统计，数据分析】这些所谓的脏活累活，这样的推荐系统才会有救。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"推荐系统杂谈\"><a href=\"#推荐系统杂谈\" class=\"headerlink\" title=\"推荐系统杂谈\"></a>推荐系统杂谈</h1><p>test test<br> test test test<br> test<br> test<br> test<br> test<br> test</p>\n<p>首先需要明确的就是推荐系统的目标，一般来说不外乎以下几个：</p>\n<ul>\n<li><strong>用户满意性</strong>：首当其冲的，推荐系统主要就是为了满足用户的需求，因此准确率是评判一个推荐系统好坏的最关键指标。</li>\n<li><strong>多样性</strong>：虽然推荐系统最主要还是满足用户的兴趣，但是也要兼顾内容的多样性，对于权重不同的兴趣都要做到兼顾。</li>\n<li>新颖性：用户看到的内容是那些他们之前没有听说过的物品。简单的做法就是在推荐列表去掉用户之前有过行为的那些内容。</li>\n<li>惊喜度：和新颖性类似，但新颖性只是用户没看到过的但是确实是和他行为是相关的，而惊喜度是用户既没有看过和他之前的行为也不相关，但用户看到后的确是喜欢的。</li>\n<li>实时性：推荐系统要根据用户的上下文来实时更新推荐内容，用户的兴趣也是随着时间而改变的，需要实时更新。</li>\n<li>推荐透明度：对于用户看到的最终结果，要让用户知道推荐此内容的原因。比如，“买过这本书的人同时也买过”、”你购买过的xx和此商品类似”。</li>\n<li>覆盖率：挖掘长尾内容也是推荐系统很重要的目标。因此，推荐的内容覆盖到的内容越多越好。</li>\n</ul>\n<p>基于这些目标，推荐系统包括四种推荐方式：</p>\n<ul>\n<li>热门推荐：就是热门排行榜的概念。这种推荐方式不仅仅在IT系统，在平常的生活中也是处处存在的。这应该是效果最好的一种推荐方式，毕竟热门推荐的物品都是位于曝光量比较高的位置的。</li>\n<li>人工推荐：人工干预的推荐内容。相比于依赖热门和算法来进行推荐。一些热点时事如世界杯、nba总决赛等就需要人工加入推荐列表。另一方面，热点新闻带来的推荐效果也是很高的。</li>\n<li>相关推荐：相关推荐有点类似于关联规则的个性化推荐，就是在你阅读一个内容的时候，会提示你阅读与此相关的内容。</li>\n<li>个性化推荐：基于用户的历史行为做出的内容推荐。也是本文主要讲述的内容。</li>\n</ul>\n<p>其中，前三者是和机器学习没有任何关系的，但却是推荐效果最好的三种方式。一般说来，这部分内容应该占到总的推荐内容的80%左右，另外20%则是对长尾内容的个性化推荐。</p>\n<h2 id=\"个性化推荐系统\"><a href=\"#个性化推荐系统\" class=\"headerlink\" title=\"个性化推荐系统\"></a>个性化推荐系统</h2><p>个性化推荐是机器学习应用的一个典型场景。在本质上和搜索引擎是一样的，同样是为了解决信息过载的问题。搜索引擎某种意义上也是一个个性化推荐系统，但是其输入特征是可以从搜索关键字直接可以得到的。而一般的推荐系统，输入特征则是需要机器学习才能得到。</p>\n<p>个性化推荐系统一般由日志系统、推荐算法、内容展示UI三部分组成。</p>\n<p>日志系统：这是推荐系统的输入源，是一个推荐系统所有信息的源头。</p>\n<p>推荐算法：这是推荐系统的核心，根据输入数据得出最终的推荐结果的具体过程就在这里。</p>\n<p>内容展示UI：对于推荐结果如何展示，也是一个值得权衡的地方。以更好地满足推荐系统的目标，并能更好的收集用户的行为信息等。</p>\n<p>其中，个性化推荐中最为核心的推荐算法，目前比较流行的有以下几种：</p>\n<p>基于内容的推荐：根据内容本身的属性(特征向量)所作的推荐。</p>\n<p>基于关联规则的推荐：“啤酒与尿布”的方式，是一种动态的推荐，能够实时对用户的行为作出推荐。是基于物品之间的特征关联性所做的推荐，在某种情况下会退化为物品协同过滤推荐。</p>\n<p>协同过滤推荐：与基于关联规则的推荐相比是一种静态方式的推荐，是根据用户已有的历史行为作分析的基础上做的推荐。可分为物品协同过滤、用户协同过滤、基于模型的协同过滤。其中，基于模型的协同又可以分为以下几种类型：基于距离的协同过滤；基于矩阵分解的协同过滤，即Latent Factor Model(SVD)；基于图模型协同，即Graph，也叫社会网络图模型。</p>\n<p>个性化推荐系统的典型架构如下图所示:<br>    <img src=\"media/14916210822379/14916212822908.jpg\" alt=\"\"><br>在线业务系统的日志接入数据高速公路，再由数据高速公路迅速运转到离线数据处理平台和在线流计算平台；离线数据处理平台周期性地以批处理方式加工过去一段时间的数据，得到人群标签和其他模型参数，存放在高速缓存中，供在线业务系统使用，与此同时，在线流计算平台实时对线上的日志数据做处理，对离线计算出的数据进行补充、修正等；在线业务系统综合离线特征和在线特征使用一定的逻辑得到输出供业务使用，产生的日志流入数据高速公路。</p>\n<p>基于此框架，个性化推荐系统的典型流程如下所示：<br><img src=\"media/14916210822379/14916213291910.jpg\" alt=\"\"><br>可知，一个推荐系统主要有以下模块组成：</p>\n<p>用户行为日志：此部分主要是用户行为日志的存储，属于数据统计的一部分, 存储在hive中。在此不做赘述。</p>\n<p>数据ETL-1：将用户日志转换为推荐算法所需要的数据格式。</p>\n<p>推荐算法：是个性化推荐最主要的部分，包括通过用户行为计算相关内容以及推荐结果等。</p>\n<p>数据ETL-2: 将推荐算法得到的结果进一步加工为存储模块的输入数据。</p>\n<p>用户画像存储：存储用户的偏好以及行为数据，如对内容关键字的偏好、点击过哪些内容等。</p>\n<p>推荐结果存储：存储各种推荐算法产生的推荐结果，可以分为两部分：{用户 : itemList}推荐结果，为用户推荐的内容列表；{item : itemList}推荐结果，与item相关的内容列表。</p>\n<p>服务调用模块：整合推荐结构，对外提供提供推荐的调用接口。</p>\n<h3 id=\"数据ETL-1\"><a href=\"#数据ETL-1\" class=\"headerlink\" title=\"数据ETL-1\"></a>数据ETL-1</h3><p>对原始的用户行为等数据进行清洗、加工，如字段、属性、格式化等，作为下一步推荐算法的输入。</p>\n<h3 id=\"推荐算法\"><a href=\"#推荐算法\" class=\"headerlink\" title=\"推荐算法\"></a>推荐算法</h3><p>对于个性化推荐系统来说，推荐算法应该是其最核心的部分。目前有很多流行的算法，比如：</p>\n<p>基于内容和用户画像的推荐：此种算法，可见之前的一篇文章：<a href=\"http://www.rowkey.me/blog/2016/04/07/up-recommend/。\" target=\"_blank\" rel=\"external\">http://www.rowkey.me/blog/2016/04/07/up-recommend/。</a></p>\n<p>基于矩阵分解的推荐: 基于SVD/ALS算法对用户进行内容推荐。相比起SVD，ALS更加适合解决稀疏矩阵的问题。Spark mlib中已经集成了对als算法的实现，需要做的就是在etl-1中把数据转换为als需要的数据格式以及调整als算法的各种参数。这里有一篇文章比较具体地描述了如何使用spark来做基于ALS的推荐：<a href=\"http://colobu.com/2015/11/30/movie-recommendation-for-douban-users-by-spark-mllib/。\" target=\"_blank\" rel=\"external\">http://colobu.com/2015/11/30/movie-recommendation-for-douban-users-by-spark-mllib/。</a></p>\n<p>用户&amp;物品协同过滤推荐：包括UserBased CF和ItemBased CF。对于这两者，需要根据业务的不同来选择不同的算法。当用户非常多的时候，考虑到维护用户矩阵的成本，一般是不推荐选择用户协同过滤的，而对于候选item很多的时候，则不推荐使用物品协同过滤。</p>\n<p>推荐算法的输出结果一般是一个用户对应一个item列表或者是一个item对应一个item列表。此部分主要考虑的是算法的时间复杂度，不管是哪一种算法，一旦用户或者内容数据上了百万级别，都需要通过分布式计算如MapReduce、Spark等来进行解决。</p>\n<p>推荐算法的基本流程如下图所示：<br><img src=\"media/14916210822379/14916213667849.jpg\" alt=\"\"></p>\n<h3 id=\"数据ETL-2\"><a href=\"#数据ETL-2\" class=\"headerlink\" title=\"数据ETL-2\"></a>数据ETL-2</h3><p>对推荐算法产生的结果进行清洗、格式化等，作为下一步存储模块的输入。</p>\n<h3 id=\"用户画像存储\"><a href=\"#用户画像存储\" class=\"headerlink\" title=\"用户画像存储\"></a>用户画像存储</h3><p>存储用户的偏好以及行为数据等信息。对于偏好，采用标签量化来表示，是一种随着时间衰减的值。对于用户画像，是批量写入、实时读取，所以存储要着重考虑读的性能。可以选择使用Redis集群作为技术方案，能够最大满足读的性能，缺点是Redis的成本昂贵且不支持auto index。也可使用Hbase作为存储，使用ElasricSearch构建二级索引，以应对根据多种维度聚集用户的需求(比如过滤某一个标签下的所有用户)。</p>\n<h3 id=\"推荐结果存储\"><a href=\"#推荐结果存储\" class=\"headerlink\" title=\"推荐结果存储\"></a>推荐结果存储</h3><p>对各种推荐算法计算出的推荐结果的存储。存储空间要求大，格式复杂。对于存储的容量和读写性能要求都比较高。可以选择使用Redis集群作为此部分的存储方案。</p>\n<h3 id=\"服务调用\"><a href=\"#服务调用\" class=\"headerlink\" title=\"服务调用\"></a>服务调用</h3><p>整合用户画像和推荐结果两部分数据，向外提供推荐调用的接口。主要是数据库IO调用开销。</p>\n<p>根据用户id，获取推荐的item列表。</p>\n<p>根据item，获取相关联的item列表。</p>\n<p>根据用户id, 获取用户画像。</p>\n<p>该模块需要采取一定的策略聚合多种推荐算法的推荐结果，直接面向业务。策略由于会随着面向的业务不同而不同，需要可配置化。同时也提供对外暴露用户画像的接口，使得业务方可以使用用户画像做针对性的处理。可以采用RPC机制对外暴露服务接口。</p>\n<h3 id=\"需要考虑的问题\"><a href=\"#需要考虑的问题\" class=\"headerlink\" title=\"需要考虑的问题\"></a>需要考虑的问题</h3><p>对于一个推荐系统，结合其实现目标，还有一些需要注重考虑的问题。</p>\n<h4 id=\"实时性问题\"><a href=\"#实时性问题\" class=\"headerlink\" title=\"实时性问题\"></a>实时性问题</h4><p>由于计算用户、item矩阵或者进行矩阵分解是需要离线进行且比较耗时，因此协同的推荐算法是很难达到实时性的。实时部分的推荐主要依靠基于用户画像的推荐来进行。最终的推荐列表是根据一定的策略对这两部分进行聚合的结果。</p>\n<h4 id=\"时效性内容问题\"><a href=\"#时效性内容问题\" class=\"headerlink\" title=\"时效性内容问题\"></a>时效性内容问题</h4><p>时效性内容指的是那些与时间强相关的内容，比如新闻、时事等。如果一条10天前xx球员获得冠军的新闻现在被推荐了出来，可想用户肯定是莫名其妙或者是很失望的。因此，对于时效性内容，需要与普通的待推荐的内容区分开，做单独的推荐或者不走个性化推荐。</p>\n<h4 id=\"冷启动问题\"><a href=\"#冷启动问题\" class=\"headerlink\" title=\"冷启动问题\"></a>冷启动问题</h4><p>不管使用何种推荐算法，都会面临冷启动问题：当用户是新用户，如何给用户推荐item呢？当内容是新内容，如何推荐给用户？</p>\n<p>对于新用户，可以采取的一种策略就是采用热门推荐或者人工推荐，把绝大多人关心的内容推荐出来。</p>\n<p>对于内容，可以将内容分为新内容池和待推荐内容池。新内容产生时，首先进入新内容池。每次推荐的时候，先从新内容池做候选推荐，并给此内容的传播度+1，直到其传播度大于一个阈值的时候，将其移至待推荐内容池。这样既可以解决新内容的冷启动问题也在一定程度上可以保证新内容的曝光量。</p>\n<h4 id=\"多样性问题\"><a href=\"#多样性问题\" class=\"headerlink\" title=\"多样性问题\"></a>多样性问题</h4><p>在基于用户画像的推荐算法中，取出用户的多个标签，然后根据相关度从不同的标签中取不同数量的内容，这样既兼顾了用户的多种兴趣也能够在一定程度上解决多样性的问题。</p>\n<p>如：用户具有tag:A B C D,相关度为wA wB wC wD，Total推荐为总共需要推荐的条数，那么</p>\n<p>RecommendList(u) = A[Total推荐 <em> wA] + B[Total推荐 </em> wB] + C[Total推荐 <em> wC] + D[Total推荐 </em> wD]</p>\n<h4 id=\"内容质量\"><a href=\"#内容质量\" class=\"headerlink\" title=\"内容质量\"></a>内容质量</h4><p>不管是热门推荐、人工推荐还是取某一标签下的内容列表都牵扯到的一个问题就是：如何给内容排序？</p>\n<p>当用户对内容的喜好不一样，可以按照兴趣度来排序；但当无法区分兴趣度的时候(比如：用户是新用户；内容都是新内容；用户对于某一标签下的内容兴趣度一样)，可以使用内容质量来做排序。click/pv是一种评判内容质量的方式。此外，使用卷积神经网络相关算法也可以构建内容质量模型。</p>\n<h4 id=\"惊喜问题\"><a href=\"#惊喜问题\" class=\"headerlink\" title=\"惊喜问题\"></a>惊喜问题</h4><p>推荐系统的惊喜目标一直是一个难题，被称作EE(Exploit &amp; Explore)问题，bandit算法是解决这个问题的一个派系，就是估计置信区间的做法，然后按照置信区间的上界来进行推荐，以UCB、LinUCB为代表的。简单点说就是先不考虑你喜不喜欢就把质量高的内容推荐给你，后面根据用户的行为反馈对推荐内容作调整。具体的可以参见此篇文章：推荐系统的苟且和远方。</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>借用推荐系统的那点事一文的几句话做为结语：</p>\n<p>实力派的【算法工程师】往往都是ABC[always be coding]，这样的算法工程师才能根据实际问题建立模型或者建立规则库，是真正能解决问题的人。往往是一些有研究背景，经验丰富的研究员，更加重视工程，因为工程架构上一些恰当合理的设计，效果往往就能远远高过于模型算法优化。</p>\n<p>学院派的【算法工程师】往往是为了算法而算法，而不是为了解决推荐系统的问题去找最适合算法。这也是为什么大公司经常招了一些博士毕业的算法工程师后，不是研究算法而是让他们整天在那看数据报表？【因为发现算法没啥好研究，只能让他们在那看看报表找找规律了。】</p>\n<p>【几乎所有所谓的智能推荐算法都是花拳绣腿】</p>\n<p>当一个做推荐系统的部门开始重视【数据清理，数据标柱，效果评测，数据统计，数据分析】这些所谓的脏活累活，这样的推荐系统才会有救。</p>\n"},{"title":"test3","date":"2017-09-23T05:50:17.000Z","_content":"\n看到这篇以前的文章，回忆一下，2014年7月毕业开始了北漂的\"码农\"的生活，有幸被公司邀请写一篇文章，随写之。\n\n*   Wiki，了解其介绍、使用、API、文档等等；\n*   Presentation，学习大牛的技术分享，特别推荐slideshare.net；\n*   Paper，技术领域都有很多的paper可以去深入学习，比如在大数据领域中google的“前三后三”6篇经典论文；\n*   Video，一提这个可能会想到网易公开课等视频网站，但我会更加推荐你去Youtube或者confreaks.com，特别强大和丰富；\n*   Blog，关注该领域大牛的博客。\n\n\n","source":"_posts/test3.md","raw":"---\ntitle: test3\ntags:\n  - geeker\ncategories:\n  - Thought\ndate: 2017-09-23 13:50:17\n---\n\n看到这篇以前的文章，回忆一下，2014年7月毕业开始了北漂的\"码农\"的生活，有幸被公司邀请写一篇文章，随写之。\n\n*   Wiki，了解其介绍、使用、API、文档等等；\n*   Presentation，学习大牛的技术分享，特别推荐slideshare.net；\n*   Paper，技术领域都有很多的paper可以去深入学习，比如在大数据领域中google的“前三后三”6篇经典论文；\n*   Video，一提这个可能会想到网易公开课等视频网站，但我会更加推荐你去Youtube或者confreaks.com，特别强大和丰富；\n*   Blog，关注该领域大牛的博客。\n\n\n","slug":"test3","published":1,"updated":"2017-09-26T03:57:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj814lkcp0006pjs66cch88hm","content":"<p>看到这篇以前的文章，回忆一下，2014年7月毕业开始了北漂的”码农”的生活，有幸被公司邀请写一篇文章，随写之。</p>\n<ul>\n<li>Wiki，了解其介绍、使用、API、文档等等；</li>\n<li>Presentation，学习大牛的技术分享，特别推荐slideshare.net；</li>\n<li>Paper，技术领域都有很多的paper可以去深入学习，比如在大数据领域中google的“前三后三”6篇经典论文；</li>\n<li>Video，一提这个可能会想到网易公开课等视频网站，但我会更加推荐你去Youtube或者confreaks.com，特别强大和丰富；</li>\n<li>Blog，关注该领域大牛的博客。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>看到这篇以前的文章，回忆一下，2014年7月毕业开始了北漂的”码农”的生活，有幸被公司邀请写一篇文章，随写之。</p>\n<ul>\n<li>Wiki，了解其介绍、使用、API、文档等等；</li>\n<li>Presentation，学习大牛的技术分享，特别推荐slideshare.net；</li>\n<li>Paper，技术领域都有很多的paper可以去深入学习，比如在大数据领域中google的“前三后三”6篇经典论文；</li>\n<li>Video，一提这个可能会想到网易公开课等视频网站，但我会更加推荐你去Youtube或者confreaks.com，特别强大和丰富；</li>\n<li>Blog，关注该领域大牛的博客。</li>\n</ul>\n"},{"title":"test2","date":"2017-09-26T02:59:00.000Z","_content":"# 推荐系统杂谈\n首先需要明确的就是推荐系统的目标，一般来说不外乎以下几个：\n\n- **用户满意性**：首当其冲的，推荐系统主要就是为了满足用户的需求，因此准确率是评判一个推荐系统好坏的最关键指标。\n- **多样性**：虽然推荐系统最主要还是满足用户的兴趣，但是也要兼顾内容的多样性，对于权重不同的兴趣都要做到兼顾。\n- 新颖性：用户看到的内容是那些他们之前没有听说过的物品。简单的做法就是在推荐列表去掉用户之前有过行为的那些内容。\n- 惊喜度：和新颖性类似，但新颖性只是用户没看到过的但是确实是和他行为是相关的，而惊喜度是用户既没有看过和他之前的行为也不相关，但用户看到后的确是喜欢的。\n- 实时性：推荐系统要根据用户的上下文来实时更新推荐内容，用户的兴趣也是随着时间而改变的，需要实时更新。\n- 推荐透明度：对于用户看到的最终结果，要让用户知道推荐此内容的原因。比如，“买过这本书的人同时也买过”、”你购买过的xx和此商品类似”。\n- 覆盖率：挖掘长尾内容也是推荐系统很重要的目标。因此，推荐的内容覆盖到的内容越多越好。\n\n基于这些目标，推荐系统包括四种推荐方式：\n\n- 热门推荐：就是热门排行榜的概念。这种推荐方式不仅仅在IT系统，在平常的生活中也是处处存在的。这应该是效果最好的一种推荐方式，毕竟热门推荐的物品都是位于曝光量比较高的位置的。\n- 人工推荐：人工干预的推荐内容。相比于依赖热门和算法来进行推荐。一些热点时事如世界杯、nba总决赛等就需要人工加入推荐列表。另一方面，热点新闻带来的推荐效果也是很高的。\n- 相关推荐：相关推荐有点类似于关联规则的个性化推荐，就是在你阅读一个内容的时候，会提示你阅读与此相关的内容。\n- 个性化推荐：基于用户的历史行为做出的内容推荐。也是本文主要讲述的内容。\n\n其中，前三者是和机器学习没有任何关系的，但却是推荐效果最好的三种方式。一般说来，这部分内容应该占到总的推荐内容的80%左右，另外20%则是对长尾内容的个性化推荐。\n\n## 个性化推荐系统\n\n个性化推荐是机器学习应用的一个典型场景。在本质上和搜索引擎是一样的，同样是为了解决信息过载的问题。搜索引擎某种意义上也是一个个性化推荐系统，但是其输入特征是可以从搜索关键字直接可以得到的。而一般的推荐系统，输入特征则是需要机器学习才能得到。\n\n个性化推荐系统一般由日志系统、推荐算法、内容展示UI三部分组成。\n\n日志系统：这是推荐系统的输入源，是一个推荐系统所有信息的源头。\n\n推荐算法：这是推荐系统的核心，根据输入数据得出最终的推荐结果的具体过程就在这里。\n\n内容展示UI：对于推荐结果如何展示，也是一个值得权衡的地方。以更好地满足推荐系统的目标，并能更好的收集用户的行为信息等。\n\n其中，个性化推荐中最为核心的推荐算法，目前比较流行的有以下几种：\n\n基于内容的推荐：根据内容本身的属性(特征向量)所作的推荐。\n\n基于关联规则的推荐：“啤酒与尿布”的方式，是一种动态的推荐，能够实时对用户的行为作出推荐。是基于物品之间的特征关联性所做的推荐，在某种情况下会退化为物品协同过滤推荐。\n\n协同过滤推荐：与基于关联规则的推荐相比是一种静态方式的推荐，是根据用户已有的历史行为作分析的基础上做的推荐。可分为物品协同过滤、用户协同过滤、基于模型的协同过滤。其中，基于模型的协同又可以分为以下几种类型：基于距离的协同过滤；基于矩阵分解的协同过滤，即Latent Factor Model(SVD)；基于图模型协同，即Graph，也叫社会网络图模型。\n\n个性化推荐系统的典型架构如下图所示:\n\n在线业务系统的日志接入数据高速公路，再由数据高速公路迅速运转到离线数据处理平台和在线流计算平台；离线数据处理平台周期性地以批处理方式加工过去一段时间的数据，得到人群标签和其他模型参数，存放在高速缓存中，供在线业务系统使用，与此同时，在线流计算平台实时对线上的日志数据做处理，对离线计算出的数据进行补充、修正等；在线业务系统综合离线特征和在线特征使用一定的逻辑得到输出供业务使用，产生的日志流入数据高速公路。\n\n基于此框架，个性化推荐系统的典型流程如下所示：\n\n可知，一个推荐系统主要有以下模块组成：\n\n用户行为日志：此部分主要是用户行为日志的存储，属于数据统计的一部分, 存储在hive中。在此不做赘述。\n\n数据ETL-1：将用户日志转换为推荐算法所需要的数据格式。\n\n推荐算法：是个性化推荐最主要的部分，包括通过用户行为计算相关内容以及推荐结果等。\n\n数据ETL-2: 将推荐算法得到的结果进一步加工为存储模块的输入数据。\n\n用户画像存储：存储用户的偏好以及行为数据，如对内容关键字的偏好、点击过哪些内容等。\n\n推荐结果存储：存储各种推荐算法产生的推荐结果，可以分为两部分：{用户 : itemList}推荐结果，为用户推荐的内容列表；{item : itemList}推荐结果，与item相关的内容列表。\n\n服务调用模块：整合推荐结构，对外提供提供推荐的调用接口。\n\n### 数据ETL-1\n\n对原始的用户行为等数据进行清洗、加工，如字段、属性、格式化等，作为下一步推荐算法的输入。\n\n### 推荐算法\n\n对于个性化推荐系统来说，推荐算法应该是其最核心的部分。目前有很多流行的算法，比如：\n\n基于内容和用户画像的推荐：此种算法，可见之前的一篇文章：http://www.rowkey.me/blog/2016/04/07/up-recommend/。\n\n基于矩阵分解的推荐: 基于SVD/ALS算法对用户进行内容推荐。相比起SVD，ALS更加适合解决稀疏矩阵的问题。Spark mlib中已经集成了对als算法的实现，需要做的就是在etl-1中把数据转换为als需要的数据格式以及调整als算法的各种参数。这里有一篇文章比较具体地描述了如何使用spark来做基于ALS的推荐：http://colobu.com/2015/11/30/movie-recommendation-for-douban-users-by-spark-mllib/。\n\n用户&物品协同过滤推荐：包括UserBased CF和ItemBased CF。对于这两者，需要根据业务的不同来选择不同的算法。当用户非常多的时候，考虑到维护用户矩阵的成本，一般是不推荐选择用户协同过滤的，而对于候选item很多的时候，则不推荐使用物品协同过滤。\n\n推荐算法的输出结果一般是一个用户对应一个item列表或者是一个item对应一个item列表。此部分主要考虑的是算法的时间复杂度，不管是哪一种算法，一旦用户或者内容数据上了百万级别，都需要通过分布式计算如MapReduce、Spark等来进行解决。\n\n推荐算法的基本流程如下图所示：\n\n\n### 数据ETL-2\n\n对推荐算法产生的结果进行清洗、格式化等，作为下一步存储模块的输入。\n\n### 用户画像存储\n\n存储用户的偏好以及行为数据等信息。对于偏好，采用标签量化来表示，是一种随着时间衰减的值。对于用户画像，是批量写入、实时读取，所以存储要着重考虑读的性能。可以选择使用Redis集群作为技术方案，能够最大满足读的性能，缺点是Redis的成本昂贵且不支持auto index。也可使用Hbase作为存储，使用ElasricSearch构建二级索引，以应对根据多种维度聚集用户的需求(比如过滤某一个标签下的所有用户)。\n\n### 推荐结果存储\n\n对各种推荐算法计算出的推荐结果的存储。存储空间要求大，格式复杂。对于存储的容量和读写性能要求都比较高。可以选择使用Redis集群作为此部分的存储方案。\n\n### 服务调用\n\n整合用户画像和推荐结果两部分数据，向外提供推荐调用的接口。主要是数据库IO调用开销。\n\n根据用户id，获取推荐的item列表。\n\n根据item，获取相关联的item列表。\n\n根据用户id, 获取用户画像。\n\n该模块需要采取一定的策略聚合多种推荐算法的推荐结果，直接面向业务。策略由于会随着面向的业务不同而不同，需要可配置化。同时也提供对外暴露用户画像的接口，使得业务方可以使用用户画像做针对性的处理。可以采用RPC机制对外暴露服务接口。\n\n### 需要考虑的问题\n\n对于一个推荐系统，结合其实现目标，还有一些需要注重考虑的问题。\n\n#### 实时性问题\n\n由于计算用户、item矩阵或者进行矩阵分解是需要离线进行且比较耗时，因此协同的推荐算法是很难达到实时性的。实时部分的推荐主要依靠基于用户画像的推荐来进行。最终的推荐列表是根据一定的策略对这两部分进行聚合的结果。\n\n#### 时效性内容问题\n\n时效性内容指的是那些与时间强相关的内容，比如新闻、时事等。如果一条10天前xx球员获得冠军的新闻现在被推荐了出来，可想用户肯定是莫名其妙或者是很失望的。因此，对于时效性内容，需要与普通的待推荐的内容区分开，做单独的推荐或者不走个性化推荐。\n\n#### 冷启动问题\n\n不管使用何种推荐算法，都会面临冷启动问题：当用户是新用户，如何给用户推荐item呢？当内容是新内容，如何推荐给用户？\n\n对于新用户，可以采取的一种策略就是采用热门推荐或者人工推荐，把绝大多人关心的内容推荐出来。\n\n对于内容，可以将内容分为新内容池和待推荐内容池。新内容产生时，首先进入新内容池。每次推荐的时候，先从新内容池做候选推荐，并给此内容的传播度+1，直到其传播度大于一个阈值的时候，将其移至待推荐内容池。这样既可以解决新内容的冷启动问题也在一定程度上可以保证新内容的曝光量。\n\n#### 多样性问题\n\n在基于用户画像的推荐算法中，取出用户的多个标签，然后根据相关度从不同的标签中取不同数量的内容，这样既兼顾了用户的多种兴趣也能够在一定程度上解决多样性的问题。\n\n如：用户具有tag:A B C D,相关度为wA wB wC wD，Total推荐为总共需要推荐的条数，那么\n\nRecommendList(u) = A[Total推荐 * wA] + B[Total推荐 * wB] + C[Total推荐 * wC] + D[Total推荐 * wD]\n\n#### 内容质量\n\n不管是热门推荐、人工推荐还是取某一标签下的内容列表都牵扯到的一个问题就是：如何给内容排序？\n\n当用户对内容的喜好不一样，可以按照兴趣度来排序；但当无法区分兴趣度的时候(比如：用户是新用户；内容都是新内容；用户对于某一标签下的内容兴趣度一样)，可以使用内容质量来做排序。click/pv是一种评判内容质量的方式。此外，使用卷积神经网络相关算法也可以构建内容质量模型。\n\n#### 惊喜问题\n\n推荐系统的惊喜目标一直是一个难题，被称作EE(Exploit & Explore)问题，bandit算法是解决这个问题的一个派系，就是估计置信区间的做法，然后按照置信区间的上界来进行推荐，以UCB、LinUCB为代表的。简单点说就是先不考虑你喜不喜欢就把质量高的内容推荐给你，后面根据用户的行为反馈对推荐内容作调整。具体的可以参见此篇文章：推荐系统的苟且和远方。\n\n### 总结\n\n借用推荐系统的那点事一文的几句话做为结语：\n\n实力派的【算法工程师】往往都是ABC[always be coding]，这样的算法工程师才能根据实际问题建立模型或者建立规则库，是真正能解决问题的人。往往是一些有研究背景，经验丰富的研究员，更加重视工程，因为工程架构上一些恰当合理的设计，效果往往就能远远高过于模型算法优化。\n\n学院派的【算法工程师】往往是为了算法而算法，而不是为了解决推荐系统的问题去找最适合算法。这也是为什么大公司经常招了一些博士毕业的算法工程师后，不是研究算法而是让他们整天在那看数据报表？【因为发现算法没啥好研究，只能让他们在那看看报表找找规律了。】\n\n【几乎所有所谓的智能推荐算法都是花拳绣腿】\n\n当一个做推荐系统的部门开始重视【数据清理，数据标柱，效果评测，数据统计，数据分析】这些所谓的脏活累活，这样的推荐系统才会有救。","source":"_posts/test2.md","raw":"title: test2\ntags: []\ncategories: []\ndate: 2017-09-26 10:59:00\n---\n# 推荐系统杂谈\n首先需要明确的就是推荐系统的目标，一般来说不外乎以下几个：\n\n- **用户满意性**：首当其冲的，推荐系统主要就是为了满足用户的需求，因此准确率是评判一个推荐系统好坏的最关键指标。\n- **多样性**：虽然推荐系统最主要还是满足用户的兴趣，但是也要兼顾内容的多样性，对于权重不同的兴趣都要做到兼顾。\n- 新颖性：用户看到的内容是那些他们之前没有听说过的物品。简单的做法就是在推荐列表去掉用户之前有过行为的那些内容。\n- 惊喜度：和新颖性类似，但新颖性只是用户没看到过的但是确实是和他行为是相关的，而惊喜度是用户既没有看过和他之前的行为也不相关，但用户看到后的确是喜欢的。\n- 实时性：推荐系统要根据用户的上下文来实时更新推荐内容，用户的兴趣也是随着时间而改变的，需要实时更新。\n- 推荐透明度：对于用户看到的最终结果，要让用户知道推荐此内容的原因。比如，“买过这本书的人同时也买过”、”你购买过的xx和此商品类似”。\n- 覆盖率：挖掘长尾内容也是推荐系统很重要的目标。因此，推荐的内容覆盖到的内容越多越好。\n\n基于这些目标，推荐系统包括四种推荐方式：\n\n- 热门推荐：就是热门排行榜的概念。这种推荐方式不仅仅在IT系统，在平常的生活中也是处处存在的。这应该是效果最好的一种推荐方式，毕竟热门推荐的物品都是位于曝光量比较高的位置的。\n- 人工推荐：人工干预的推荐内容。相比于依赖热门和算法来进行推荐。一些热点时事如世界杯、nba总决赛等就需要人工加入推荐列表。另一方面，热点新闻带来的推荐效果也是很高的。\n- 相关推荐：相关推荐有点类似于关联规则的个性化推荐，就是在你阅读一个内容的时候，会提示你阅读与此相关的内容。\n- 个性化推荐：基于用户的历史行为做出的内容推荐。也是本文主要讲述的内容。\n\n其中，前三者是和机器学习没有任何关系的，但却是推荐效果最好的三种方式。一般说来，这部分内容应该占到总的推荐内容的80%左右，另外20%则是对长尾内容的个性化推荐。\n\n## 个性化推荐系统\n\n个性化推荐是机器学习应用的一个典型场景。在本质上和搜索引擎是一样的，同样是为了解决信息过载的问题。搜索引擎某种意义上也是一个个性化推荐系统，但是其输入特征是可以从搜索关键字直接可以得到的。而一般的推荐系统，输入特征则是需要机器学习才能得到。\n\n个性化推荐系统一般由日志系统、推荐算法、内容展示UI三部分组成。\n\n日志系统：这是推荐系统的输入源，是一个推荐系统所有信息的源头。\n\n推荐算法：这是推荐系统的核心，根据输入数据得出最终的推荐结果的具体过程就在这里。\n\n内容展示UI：对于推荐结果如何展示，也是一个值得权衡的地方。以更好地满足推荐系统的目标，并能更好的收集用户的行为信息等。\n\n其中，个性化推荐中最为核心的推荐算法，目前比较流行的有以下几种：\n\n基于内容的推荐：根据内容本身的属性(特征向量)所作的推荐。\n\n基于关联规则的推荐：“啤酒与尿布”的方式，是一种动态的推荐，能够实时对用户的行为作出推荐。是基于物品之间的特征关联性所做的推荐，在某种情况下会退化为物品协同过滤推荐。\n\n协同过滤推荐：与基于关联规则的推荐相比是一种静态方式的推荐，是根据用户已有的历史行为作分析的基础上做的推荐。可分为物品协同过滤、用户协同过滤、基于模型的协同过滤。其中，基于模型的协同又可以分为以下几种类型：基于距离的协同过滤；基于矩阵分解的协同过滤，即Latent Factor Model(SVD)；基于图模型协同，即Graph，也叫社会网络图模型。\n\n个性化推荐系统的典型架构如下图所示:\n\n在线业务系统的日志接入数据高速公路，再由数据高速公路迅速运转到离线数据处理平台和在线流计算平台；离线数据处理平台周期性地以批处理方式加工过去一段时间的数据，得到人群标签和其他模型参数，存放在高速缓存中，供在线业务系统使用，与此同时，在线流计算平台实时对线上的日志数据做处理，对离线计算出的数据进行补充、修正等；在线业务系统综合离线特征和在线特征使用一定的逻辑得到输出供业务使用，产生的日志流入数据高速公路。\n\n基于此框架，个性化推荐系统的典型流程如下所示：\n\n可知，一个推荐系统主要有以下模块组成：\n\n用户行为日志：此部分主要是用户行为日志的存储，属于数据统计的一部分, 存储在hive中。在此不做赘述。\n\n数据ETL-1：将用户日志转换为推荐算法所需要的数据格式。\n\n推荐算法：是个性化推荐最主要的部分，包括通过用户行为计算相关内容以及推荐结果等。\n\n数据ETL-2: 将推荐算法得到的结果进一步加工为存储模块的输入数据。\n\n用户画像存储：存储用户的偏好以及行为数据，如对内容关键字的偏好、点击过哪些内容等。\n\n推荐结果存储：存储各种推荐算法产生的推荐结果，可以分为两部分：{用户 : itemList}推荐结果，为用户推荐的内容列表；{item : itemList}推荐结果，与item相关的内容列表。\n\n服务调用模块：整合推荐结构，对外提供提供推荐的调用接口。\n\n### 数据ETL-1\n\n对原始的用户行为等数据进行清洗、加工，如字段、属性、格式化等，作为下一步推荐算法的输入。\n\n### 推荐算法\n\n对于个性化推荐系统来说，推荐算法应该是其最核心的部分。目前有很多流行的算法，比如：\n\n基于内容和用户画像的推荐：此种算法，可见之前的一篇文章：http://www.rowkey.me/blog/2016/04/07/up-recommend/。\n\n基于矩阵分解的推荐: 基于SVD/ALS算法对用户进行内容推荐。相比起SVD，ALS更加适合解决稀疏矩阵的问题。Spark mlib中已经集成了对als算法的实现，需要做的就是在etl-1中把数据转换为als需要的数据格式以及调整als算法的各种参数。这里有一篇文章比较具体地描述了如何使用spark来做基于ALS的推荐：http://colobu.com/2015/11/30/movie-recommendation-for-douban-users-by-spark-mllib/。\n\n用户&物品协同过滤推荐：包括UserBased CF和ItemBased CF。对于这两者，需要根据业务的不同来选择不同的算法。当用户非常多的时候，考虑到维护用户矩阵的成本，一般是不推荐选择用户协同过滤的，而对于候选item很多的时候，则不推荐使用物品协同过滤。\n\n推荐算法的输出结果一般是一个用户对应一个item列表或者是一个item对应一个item列表。此部分主要考虑的是算法的时间复杂度，不管是哪一种算法，一旦用户或者内容数据上了百万级别，都需要通过分布式计算如MapReduce、Spark等来进行解决。\n\n推荐算法的基本流程如下图所示：\n\n\n### 数据ETL-2\n\n对推荐算法产生的结果进行清洗、格式化等，作为下一步存储模块的输入。\n\n### 用户画像存储\n\n存储用户的偏好以及行为数据等信息。对于偏好，采用标签量化来表示，是一种随着时间衰减的值。对于用户画像，是批量写入、实时读取，所以存储要着重考虑读的性能。可以选择使用Redis集群作为技术方案，能够最大满足读的性能，缺点是Redis的成本昂贵且不支持auto index。也可使用Hbase作为存储，使用ElasricSearch构建二级索引，以应对根据多种维度聚集用户的需求(比如过滤某一个标签下的所有用户)。\n\n### 推荐结果存储\n\n对各种推荐算法计算出的推荐结果的存储。存储空间要求大，格式复杂。对于存储的容量和读写性能要求都比较高。可以选择使用Redis集群作为此部分的存储方案。\n\n### 服务调用\n\n整合用户画像和推荐结果两部分数据，向外提供推荐调用的接口。主要是数据库IO调用开销。\n\n根据用户id，获取推荐的item列表。\n\n根据item，获取相关联的item列表。\n\n根据用户id, 获取用户画像。\n\n该模块需要采取一定的策略聚合多种推荐算法的推荐结果，直接面向业务。策略由于会随着面向的业务不同而不同，需要可配置化。同时也提供对外暴露用户画像的接口，使得业务方可以使用用户画像做针对性的处理。可以采用RPC机制对外暴露服务接口。\n\n### 需要考虑的问题\n\n对于一个推荐系统，结合其实现目标，还有一些需要注重考虑的问题。\n\n#### 实时性问题\n\n由于计算用户、item矩阵或者进行矩阵分解是需要离线进行且比较耗时，因此协同的推荐算法是很难达到实时性的。实时部分的推荐主要依靠基于用户画像的推荐来进行。最终的推荐列表是根据一定的策略对这两部分进行聚合的结果。\n\n#### 时效性内容问题\n\n时效性内容指的是那些与时间强相关的内容，比如新闻、时事等。如果一条10天前xx球员获得冠军的新闻现在被推荐了出来，可想用户肯定是莫名其妙或者是很失望的。因此，对于时效性内容，需要与普通的待推荐的内容区分开，做单独的推荐或者不走个性化推荐。\n\n#### 冷启动问题\n\n不管使用何种推荐算法，都会面临冷启动问题：当用户是新用户，如何给用户推荐item呢？当内容是新内容，如何推荐给用户？\n\n对于新用户，可以采取的一种策略就是采用热门推荐或者人工推荐，把绝大多人关心的内容推荐出来。\n\n对于内容，可以将内容分为新内容池和待推荐内容池。新内容产生时，首先进入新内容池。每次推荐的时候，先从新内容池做候选推荐，并给此内容的传播度+1，直到其传播度大于一个阈值的时候，将其移至待推荐内容池。这样既可以解决新内容的冷启动问题也在一定程度上可以保证新内容的曝光量。\n\n#### 多样性问题\n\n在基于用户画像的推荐算法中，取出用户的多个标签，然后根据相关度从不同的标签中取不同数量的内容，这样既兼顾了用户的多种兴趣也能够在一定程度上解决多样性的问题。\n\n如：用户具有tag:A B C D,相关度为wA wB wC wD，Total推荐为总共需要推荐的条数，那么\n\nRecommendList(u) = A[Total推荐 * wA] + B[Total推荐 * wB] + C[Total推荐 * wC] + D[Total推荐 * wD]\n\n#### 内容质量\n\n不管是热门推荐、人工推荐还是取某一标签下的内容列表都牵扯到的一个问题就是：如何给内容排序？\n\n当用户对内容的喜好不一样，可以按照兴趣度来排序；但当无法区分兴趣度的时候(比如：用户是新用户；内容都是新内容；用户对于某一标签下的内容兴趣度一样)，可以使用内容质量来做排序。click/pv是一种评判内容质量的方式。此外，使用卷积神经网络相关算法也可以构建内容质量模型。\n\n#### 惊喜问题\n\n推荐系统的惊喜目标一直是一个难题，被称作EE(Exploit & Explore)问题，bandit算法是解决这个问题的一个派系，就是估计置信区间的做法，然后按照置信区间的上界来进行推荐，以UCB、LinUCB为代表的。简单点说就是先不考虑你喜不喜欢就把质量高的内容推荐给你，后面根据用户的行为反馈对推荐内容作调整。具体的可以参见此篇文章：推荐系统的苟且和远方。\n\n### 总结\n\n借用推荐系统的那点事一文的几句话做为结语：\n\n实力派的【算法工程师】往往都是ABC[always be coding]，这样的算法工程师才能根据实际问题建立模型或者建立规则库，是真正能解决问题的人。往往是一些有研究背景，经验丰富的研究员，更加重视工程，因为工程架构上一些恰当合理的设计，效果往往就能远远高过于模型算法优化。\n\n学院派的【算法工程师】往往是为了算法而算法，而不是为了解决推荐系统的问题去找最适合算法。这也是为什么大公司经常招了一些博士毕业的算法工程师后，不是研究算法而是让他们整天在那看数据报表？【因为发现算法没啥好研究，只能让他们在那看看报表找找规律了。】\n\n【几乎所有所谓的智能推荐算法都是花拳绣腿】\n\n当一个做推荐系统的部门开始重视【数据清理，数据标柱，效果评测，数据统计，数据分析】这些所谓的脏活累活，这样的推荐系统才会有救。","slug":"test2","published":1,"updated":"2017-09-26T03:12:13.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj814lkcr0008pjs6wb7x43q9","content":"<h1 id=\"推荐系统杂谈\"><a href=\"#推荐系统杂谈\" class=\"headerlink\" title=\"推荐系统杂谈\"></a>推荐系统杂谈</h1><p>首先需要明确的就是推荐系统的目标，一般来说不外乎以下几个：</p>\n<ul>\n<li><strong>用户满意性</strong>：首当其冲的，推荐系统主要就是为了满足用户的需求，因此准确率是评判一个推荐系统好坏的最关键指标。</li>\n<li><strong>多样性</strong>：虽然推荐系统最主要还是满足用户的兴趣，但是也要兼顾内容的多样性，对于权重不同的兴趣都要做到兼顾。</li>\n<li>新颖性：用户看到的内容是那些他们之前没有听说过的物品。简单的做法就是在推荐列表去掉用户之前有过行为的那些内容。</li>\n<li>惊喜度：和新颖性类似，但新颖性只是用户没看到过的但是确实是和他行为是相关的，而惊喜度是用户既没有看过和他之前的行为也不相关，但用户看到后的确是喜欢的。</li>\n<li>实时性：推荐系统要根据用户的上下文来实时更新推荐内容，用户的兴趣也是随着时间而改变的，需要实时更新。</li>\n<li>推荐透明度：对于用户看到的最终结果，要让用户知道推荐此内容的原因。比如，“买过这本书的人同时也买过”、”你购买过的xx和此商品类似”。</li>\n<li>覆盖率：挖掘长尾内容也是推荐系统很重要的目标。因此，推荐的内容覆盖到的内容越多越好。</li>\n</ul>\n<p>基于这些目标，推荐系统包括四种推荐方式：</p>\n<ul>\n<li>热门推荐：就是热门排行榜的概念。这种推荐方式不仅仅在IT系统，在平常的生活中也是处处存在的。这应该是效果最好的一种推荐方式，毕竟热门推荐的物品都是位于曝光量比较高的位置的。</li>\n<li>人工推荐：人工干预的推荐内容。相比于依赖热门和算法来进行推荐。一些热点时事如世界杯、nba总决赛等就需要人工加入推荐列表。另一方面，热点新闻带来的推荐效果也是很高的。</li>\n<li>相关推荐：相关推荐有点类似于关联规则的个性化推荐，就是在你阅读一个内容的时候，会提示你阅读与此相关的内容。</li>\n<li>个性化推荐：基于用户的历史行为做出的内容推荐。也是本文主要讲述的内容。</li>\n</ul>\n<p>其中，前三者是和机器学习没有任何关系的，但却是推荐效果最好的三种方式。一般说来，这部分内容应该占到总的推荐内容的80%左右，另外20%则是对长尾内容的个性化推荐。</p>\n<h2 id=\"个性化推荐系统\"><a href=\"#个性化推荐系统\" class=\"headerlink\" title=\"个性化推荐系统\"></a>个性化推荐系统</h2><p>个性化推荐是机器学习应用的一个典型场景。在本质上和搜索引擎是一样的，同样是为了解决信息过载的问题。搜索引擎某种意义上也是一个个性化推荐系统，但是其输入特征是可以从搜索关键字直接可以得到的。而一般的推荐系统，输入特征则是需要机器学习才能得到。</p>\n<p>个性化推荐系统一般由日志系统、推荐算法、内容展示UI三部分组成。</p>\n<p>日志系统：这是推荐系统的输入源，是一个推荐系统所有信息的源头。</p>\n<p>推荐算法：这是推荐系统的核心，根据输入数据得出最终的推荐结果的具体过程就在这里。</p>\n<p>内容展示UI：对于推荐结果如何展示，也是一个值得权衡的地方。以更好地满足推荐系统的目标，并能更好的收集用户的行为信息等。</p>\n<p>其中，个性化推荐中最为核心的推荐算法，目前比较流行的有以下几种：</p>\n<p>基于内容的推荐：根据内容本身的属性(特征向量)所作的推荐。</p>\n<p>基于关联规则的推荐：“啤酒与尿布”的方式，是一种动态的推荐，能够实时对用户的行为作出推荐。是基于物品之间的特征关联性所做的推荐，在某种情况下会退化为物品协同过滤推荐。</p>\n<p>协同过滤推荐：与基于关联规则的推荐相比是一种静态方式的推荐，是根据用户已有的历史行为作分析的基础上做的推荐。可分为物品协同过滤、用户协同过滤、基于模型的协同过滤。其中，基于模型的协同又可以分为以下几种类型：基于距离的协同过滤；基于矩阵分解的协同过滤，即Latent Factor Model(SVD)；基于图模型协同，即Graph，也叫社会网络图模型。</p>\n<p>个性化推荐系统的典型架构如下图所示:</p>\n<p>在线业务系统的日志接入数据高速公路，再由数据高速公路迅速运转到离线数据处理平台和在线流计算平台；离线数据处理平台周期性地以批处理方式加工过去一段时间的数据，得到人群标签和其他模型参数，存放在高速缓存中，供在线业务系统使用，与此同时，在线流计算平台实时对线上的日志数据做处理，对离线计算出的数据进行补充、修正等；在线业务系统综合离线特征和在线特征使用一定的逻辑得到输出供业务使用，产生的日志流入数据高速公路。</p>\n<p>基于此框架，个性化推荐系统的典型流程如下所示：</p>\n<p>可知，一个推荐系统主要有以下模块组成：</p>\n<p>用户行为日志：此部分主要是用户行为日志的存储，属于数据统计的一部分, 存储在hive中。在此不做赘述。</p>\n<p>数据ETL-1：将用户日志转换为推荐算法所需要的数据格式。</p>\n<p>推荐算法：是个性化推荐最主要的部分，包括通过用户行为计算相关内容以及推荐结果等。</p>\n<p>数据ETL-2: 将推荐算法得到的结果进一步加工为存储模块的输入数据。</p>\n<p>用户画像存储：存储用户的偏好以及行为数据，如对内容关键字的偏好、点击过哪些内容等。</p>\n<p>推荐结果存储：存储各种推荐算法产生的推荐结果，可以分为两部分：{用户 : itemList}推荐结果，为用户推荐的内容列表；{item : itemList}推荐结果，与item相关的内容列表。</p>\n<p>服务调用模块：整合推荐结构，对外提供提供推荐的调用接口。</p>\n<h3 id=\"数据ETL-1\"><a href=\"#数据ETL-1\" class=\"headerlink\" title=\"数据ETL-1\"></a>数据ETL-1</h3><p>对原始的用户行为等数据进行清洗、加工，如字段、属性、格式化等，作为下一步推荐算法的输入。</p>\n<h3 id=\"推荐算法\"><a href=\"#推荐算法\" class=\"headerlink\" title=\"推荐算法\"></a>推荐算法</h3><p>对于个性化推荐系统来说，推荐算法应该是其最核心的部分。目前有很多流行的算法，比如：</p>\n<p>基于内容和用户画像的推荐：此种算法，可见之前的一篇文章：<a href=\"http://www.rowkey.me/blog/2016/04/07/up-recommend/。\" target=\"_blank\" rel=\"external\">http://www.rowkey.me/blog/2016/04/07/up-recommend/。</a></p>\n<p>基于矩阵分解的推荐: 基于SVD/ALS算法对用户进行内容推荐。相比起SVD，ALS更加适合解决稀疏矩阵的问题。Spark mlib中已经集成了对als算法的实现，需要做的就是在etl-1中把数据转换为als需要的数据格式以及调整als算法的各种参数。这里有一篇文章比较具体地描述了如何使用spark来做基于ALS的推荐：<a href=\"http://colobu.com/2015/11/30/movie-recommendation-for-douban-users-by-spark-mllib/。\" target=\"_blank\" rel=\"external\">http://colobu.com/2015/11/30/movie-recommendation-for-douban-users-by-spark-mllib/。</a></p>\n<p>用户&amp;物品协同过滤推荐：包括UserBased CF和ItemBased CF。对于这两者，需要根据业务的不同来选择不同的算法。当用户非常多的时候，考虑到维护用户矩阵的成本，一般是不推荐选择用户协同过滤的，而对于候选item很多的时候，则不推荐使用物品协同过滤。</p>\n<p>推荐算法的输出结果一般是一个用户对应一个item列表或者是一个item对应一个item列表。此部分主要考虑的是算法的时间复杂度，不管是哪一种算法，一旦用户或者内容数据上了百万级别，都需要通过分布式计算如MapReduce、Spark等来进行解决。</p>\n<p>推荐算法的基本流程如下图所示：</p>\n<h3 id=\"数据ETL-2\"><a href=\"#数据ETL-2\" class=\"headerlink\" title=\"数据ETL-2\"></a>数据ETL-2</h3><p>对推荐算法产生的结果进行清洗、格式化等，作为下一步存储模块的输入。</p>\n<h3 id=\"用户画像存储\"><a href=\"#用户画像存储\" class=\"headerlink\" title=\"用户画像存储\"></a>用户画像存储</h3><p>存储用户的偏好以及行为数据等信息。对于偏好，采用标签量化来表示，是一种随着时间衰减的值。对于用户画像，是批量写入、实时读取，所以存储要着重考虑读的性能。可以选择使用Redis集群作为技术方案，能够最大满足读的性能，缺点是Redis的成本昂贵且不支持auto index。也可使用Hbase作为存储，使用ElasricSearch构建二级索引，以应对根据多种维度聚集用户的需求(比如过滤某一个标签下的所有用户)。</p>\n<h3 id=\"推荐结果存储\"><a href=\"#推荐结果存储\" class=\"headerlink\" title=\"推荐结果存储\"></a>推荐结果存储</h3><p>对各种推荐算法计算出的推荐结果的存储。存储空间要求大，格式复杂。对于存储的容量和读写性能要求都比较高。可以选择使用Redis集群作为此部分的存储方案。</p>\n<h3 id=\"服务调用\"><a href=\"#服务调用\" class=\"headerlink\" title=\"服务调用\"></a>服务调用</h3><p>整合用户画像和推荐结果两部分数据，向外提供推荐调用的接口。主要是数据库IO调用开销。</p>\n<p>根据用户id，获取推荐的item列表。</p>\n<p>根据item，获取相关联的item列表。</p>\n<p>根据用户id, 获取用户画像。</p>\n<p>该模块需要采取一定的策略聚合多种推荐算法的推荐结果，直接面向业务。策略由于会随着面向的业务不同而不同，需要可配置化。同时也提供对外暴露用户画像的接口，使得业务方可以使用用户画像做针对性的处理。可以采用RPC机制对外暴露服务接口。</p>\n<h3 id=\"需要考虑的问题\"><a href=\"#需要考虑的问题\" class=\"headerlink\" title=\"需要考虑的问题\"></a>需要考虑的问题</h3><p>对于一个推荐系统，结合其实现目标，还有一些需要注重考虑的问题。</p>\n<h4 id=\"实时性问题\"><a href=\"#实时性问题\" class=\"headerlink\" title=\"实时性问题\"></a>实时性问题</h4><p>由于计算用户、item矩阵或者进行矩阵分解是需要离线进行且比较耗时，因此协同的推荐算法是很难达到实时性的。实时部分的推荐主要依靠基于用户画像的推荐来进行。最终的推荐列表是根据一定的策略对这两部分进行聚合的结果。</p>\n<h4 id=\"时效性内容问题\"><a href=\"#时效性内容问题\" class=\"headerlink\" title=\"时效性内容问题\"></a>时效性内容问题</h4><p>时效性内容指的是那些与时间强相关的内容，比如新闻、时事等。如果一条10天前xx球员获得冠军的新闻现在被推荐了出来，可想用户肯定是莫名其妙或者是很失望的。因此，对于时效性内容，需要与普通的待推荐的内容区分开，做单独的推荐或者不走个性化推荐。</p>\n<h4 id=\"冷启动问题\"><a href=\"#冷启动问题\" class=\"headerlink\" title=\"冷启动问题\"></a>冷启动问题</h4><p>不管使用何种推荐算法，都会面临冷启动问题：当用户是新用户，如何给用户推荐item呢？当内容是新内容，如何推荐给用户？</p>\n<p>对于新用户，可以采取的一种策略就是采用热门推荐或者人工推荐，把绝大多人关心的内容推荐出来。</p>\n<p>对于内容，可以将内容分为新内容池和待推荐内容池。新内容产生时，首先进入新内容池。每次推荐的时候，先从新内容池做候选推荐，并给此内容的传播度+1，直到其传播度大于一个阈值的时候，将其移至待推荐内容池。这样既可以解决新内容的冷启动问题也在一定程度上可以保证新内容的曝光量。</p>\n<h4 id=\"多样性问题\"><a href=\"#多样性问题\" class=\"headerlink\" title=\"多样性问题\"></a>多样性问题</h4><p>在基于用户画像的推荐算法中，取出用户的多个标签，然后根据相关度从不同的标签中取不同数量的内容，这样既兼顾了用户的多种兴趣也能够在一定程度上解决多样性的问题。</p>\n<p>如：用户具有tag:A B C D,相关度为wA wB wC wD，Total推荐为总共需要推荐的条数，那么</p>\n<p>RecommendList(u) = A[Total推荐 <em> wA] + B[Total推荐 </em> wB] + C[Total推荐 <em> wC] + D[Total推荐 </em> wD]</p>\n<h4 id=\"内容质量\"><a href=\"#内容质量\" class=\"headerlink\" title=\"内容质量\"></a>内容质量</h4><p>不管是热门推荐、人工推荐还是取某一标签下的内容列表都牵扯到的一个问题就是：如何给内容排序？</p>\n<p>当用户对内容的喜好不一样，可以按照兴趣度来排序；但当无法区分兴趣度的时候(比如：用户是新用户；内容都是新内容；用户对于某一标签下的内容兴趣度一样)，可以使用内容质量来做排序。click/pv是一种评判内容质量的方式。此外，使用卷积神经网络相关算法也可以构建内容质量模型。</p>\n<h4 id=\"惊喜问题\"><a href=\"#惊喜问题\" class=\"headerlink\" title=\"惊喜问题\"></a>惊喜问题</h4><p>推荐系统的惊喜目标一直是一个难题，被称作EE(Exploit &amp; Explore)问题，bandit算法是解决这个问题的一个派系，就是估计置信区间的做法，然后按照置信区间的上界来进行推荐，以UCB、LinUCB为代表的。简单点说就是先不考虑你喜不喜欢就把质量高的内容推荐给你，后面根据用户的行为反馈对推荐内容作调整。具体的可以参见此篇文章：推荐系统的苟且和远方。</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>借用推荐系统的那点事一文的几句话做为结语：</p>\n<p>实力派的【算法工程师】往往都是ABC[always be coding]，这样的算法工程师才能根据实际问题建立模型或者建立规则库，是真正能解决问题的人。往往是一些有研究背景，经验丰富的研究员，更加重视工程，因为工程架构上一些恰当合理的设计，效果往往就能远远高过于模型算法优化。</p>\n<p>学院派的【算法工程师】往往是为了算法而算法，而不是为了解决推荐系统的问题去找最适合算法。这也是为什么大公司经常招了一些博士毕业的算法工程师后，不是研究算法而是让他们整天在那看数据报表？【因为发现算法没啥好研究，只能让他们在那看看报表找找规律了。】</p>\n<p>【几乎所有所谓的智能推荐算法都是花拳绣腿】</p>\n<p>当一个做推荐系统的部门开始重视【数据清理，数据标柱，效果评测，数据统计，数据分析】这些所谓的脏活累活，这样的推荐系统才会有救。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"推荐系统杂谈\"><a href=\"#推荐系统杂谈\" class=\"headerlink\" title=\"推荐系统杂谈\"></a>推荐系统杂谈</h1><p>首先需要明确的就是推荐系统的目标，一般来说不外乎以下几个：</p>\n<ul>\n<li><strong>用户满意性</strong>：首当其冲的，推荐系统主要就是为了满足用户的需求，因此准确率是评判一个推荐系统好坏的最关键指标。</li>\n<li><strong>多样性</strong>：虽然推荐系统最主要还是满足用户的兴趣，但是也要兼顾内容的多样性，对于权重不同的兴趣都要做到兼顾。</li>\n<li>新颖性：用户看到的内容是那些他们之前没有听说过的物品。简单的做法就是在推荐列表去掉用户之前有过行为的那些内容。</li>\n<li>惊喜度：和新颖性类似，但新颖性只是用户没看到过的但是确实是和他行为是相关的，而惊喜度是用户既没有看过和他之前的行为也不相关，但用户看到后的确是喜欢的。</li>\n<li>实时性：推荐系统要根据用户的上下文来实时更新推荐内容，用户的兴趣也是随着时间而改变的，需要实时更新。</li>\n<li>推荐透明度：对于用户看到的最终结果，要让用户知道推荐此内容的原因。比如，“买过这本书的人同时也买过”、”你购买过的xx和此商品类似”。</li>\n<li>覆盖率：挖掘长尾内容也是推荐系统很重要的目标。因此，推荐的内容覆盖到的内容越多越好。</li>\n</ul>\n<p>基于这些目标，推荐系统包括四种推荐方式：</p>\n<ul>\n<li>热门推荐：就是热门排行榜的概念。这种推荐方式不仅仅在IT系统，在平常的生活中也是处处存在的。这应该是效果最好的一种推荐方式，毕竟热门推荐的物品都是位于曝光量比较高的位置的。</li>\n<li>人工推荐：人工干预的推荐内容。相比于依赖热门和算法来进行推荐。一些热点时事如世界杯、nba总决赛等就需要人工加入推荐列表。另一方面，热点新闻带来的推荐效果也是很高的。</li>\n<li>相关推荐：相关推荐有点类似于关联规则的个性化推荐，就是在你阅读一个内容的时候，会提示你阅读与此相关的内容。</li>\n<li>个性化推荐：基于用户的历史行为做出的内容推荐。也是本文主要讲述的内容。</li>\n</ul>\n<p>其中，前三者是和机器学习没有任何关系的，但却是推荐效果最好的三种方式。一般说来，这部分内容应该占到总的推荐内容的80%左右，另外20%则是对长尾内容的个性化推荐。</p>\n<h2 id=\"个性化推荐系统\"><a href=\"#个性化推荐系统\" class=\"headerlink\" title=\"个性化推荐系统\"></a>个性化推荐系统</h2><p>个性化推荐是机器学习应用的一个典型场景。在本质上和搜索引擎是一样的，同样是为了解决信息过载的问题。搜索引擎某种意义上也是一个个性化推荐系统，但是其输入特征是可以从搜索关键字直接可以得到的。而一般的推荐系统，输入特征则是需要机器学习才能得到。</p>\n<p>个性化推荐系统一般由日志系统、推荐算法、内容展示UI三部分组成。</p>\n<p>日志系统：这是推荐系统的输入源，是一个推荐系统所有信息的源头。</p>\n<p>推荐算法：这是推荐系统的核心，根据输入数据得出最终的推荐结果的具体过程就在这里。</p>\n<p>内容展示UI：对于推荐结果如何展示，也是一个值得权衡的地方。以更好地满足推荐系统的目标，并能更好的收集用户的行为信息等。</p>\n<p>其中，个性化推荐中最为核心的推荐算法，目前比较流行的有以下几种：</p>\n<p>基于内容的推荐：根据内容本身的属性(特征向量)所作的推荐。</p>\n<p>基于关联规则的推荐：“啤酒与尿布”的方式，是一种动态的推荐，能够实时对用户的行为作出推荐。是基于物品之间的特征关联性所做的推荐，在某种情况下会退化为物品协同过滤推荐。</p>\n<p>协同过滤推荐：与基于关联规则的推荐相比是一种静态方式的推荐，是根据用户已有的历史行为作分析的基础上做的推荐。可分为物品协同过滤、用户协同过滤、基于模型的协同过滤。其中，基于模型的协同又可以分为以下几种类型：基于距离的协同过滤；基于矩阵分解的协同过滤，即Latent Factor Model(SVD)；基于图模型协同，即Graph，也叫社会网络图模型。</p>\n<p>个性化推荐系统的典型架构如下图所示:</p>\n<p>在线业务系统的日志接入数据高速公路，再由数据高速公路迅速运转到离线数据处理平台和在线流计算平台；离线数据处理平台周期性地以批处理方式加工过去一段时间的数据，得到人群标签和其他模型参数，存放在高速缓存中，供在线业务系统使用，与此同时，在线流计算平台实时对线上的日志数据做处理，对离线计算出的数据进行补充、修正等；在线业务系统综合离线特征和在线特征使用一定的逻辑得到输出供业务使用，产生的日志流入数据高速公路。</p>\n<p>基于此框架，个性化推荐系统的典型流程如下所示：</p>\n<p>可知，一个推荐系统主要有以下模块组成：</p>\n<p>用户行为日志：此部分主要是用户行为日志的存储，属于数据统计的一部分, 存储在hive中。在此不做赘述。</p>\n<p>数据ETL-1：将用户日志转换为推荐算法所需要的数据格式。</p>\n<p>推荐算法：是个性化推荐最主要的部分，包括通过用户行为计算相关内容以及推荐结果等。</p>\n<p>数据ETL-2: 将推荐算法得到的结果进一步加工为存储模块的输入数据。</p>\n<p>用户画像存储：存储用户的偏好以及行为数据，如对内容关键字的偏好、点击过哪些内容等。</p>\n<p>推荐结果存储：存储各种推荐算法产生的推荐结果，可以分为两部分：{用户 : itemList}推荐结果，为用户推荐的内容列表；{item : itemList}推荐结果，与item相关的内容列表。</p>\n<p>服务调用模块：整合推荐结构，对外提供提供推荐的调用接口。</p>\n<h3 id=\"数据ETL-1\"><a href=\"#数据ETL-1\" class=\"headerlink\" title=\"数据ETL-1\"></a>数据ETL-1</h3><p>对原始的用户行为等数据进行清洗、加工，如字段、属性、格式化等，作为下一步推荐算法的输入。</p>\n<h3 id=\"推荐算法\"><a href=\"#推荐算法\" class=\"headerlink\" title=\"推荐算法\"></a>推荐算法</h3><p>对于个性化推荐系统来说，推荐算法应该是其最核心的部分。目前有很多流行的算法，比如：</p>\n<p>基于内容和用户画像的推荐：此种算法，可见之前的一篇文章：<a href=\"http://www.rowkey.me/blog/2016/04/07/up-recommend/。\" target=\"_blank\" rel=\"external\">http://www.rowkey.me/blog/2016/04/07/up-recommend/。</a></p>\n<p>基于矩阵分解的推荐: 基于SVD/ALS算法对用户进行内容推荐。相比起SVD，ALS更加适合解决稀疏矩阵的问题。Spark mlib中已经集成了对als算法的实现，需要做的就是在etl-1中把数据转换为als需要的数据格式以及调整als算法的各种参数。这里有一篇文章比较具体地描述了如何使用spark来做基于ALS的推荐：<a href=\"http://colobu.com/2015/11/30/movie-recommendation-for-douban-users-by-spark-mllib/。\" target=\"_blank\" rel=\"external\">http://colobu.com/2015/11/30/movie-recommendation-for-douban-users-by-spark-mllib/。</a></p>\n<p>用户&amp;物品协同过滤推荐：包括UserBased CF和ItemBased CF。对于这两者，需要根据业务的不同来选择不同的算法。当用户非常多的时候，考虑到维护用户矩阵的成本，一般是不推荐选择用户协同过滤的，而对于候选item很多的时候，则不推荐使用物品协同过滤。</p>\n<p>推荐算法的输出结果一般是一个用户对应一个item列表或者是一个item对应一个item列表。此部分主要考虑的是算法的时间复杂度，不管是哪一种算法，一旦用户或者内容数据上了百万级别，都需要通过分布式计算如MapReduce、Spark等来进行解决。</p>\n<p>推荐算法的基本流程如下图所示：</p>\n<h3 id=\"数据ETL-2\"><a href=\"#数据ETL-2\" class=\"headerlink\" title=\"数据ETL-2\"></a>数据ETL-2</h3><p>对推荐算法产生的结果进行清洗、格式化等，作为下一步存储模块的输入。</p>\n<h3 id=\"用户画像存储\"><a href=\"#用户画像存储\" class=\"headerlink\" title=\"用户画像存储\"></a>用户画像存储</h3><p>存储用户的偏好以及行为数据等信息。对于偏好，采用标签量化来表示，是一种随着时间衰减的值。对于用户画像，是批量写入、实时读取，所以存储要着重考虑读的性能。可以选择使用Redis集群作为技术方案，能够最大满足读的性能，缺点是Redis的成本昂贵且不支持auto index。也可使用Hbase作为存储，使用ElasricSearch构建二级索引，以应对根据多种维度聚集用户的需求(比如过滤某一个标签下的所有用户)。</p>\n<h3 id=\"推荐结果存储\"><a href=\"#推荐结果存储\" class=\"headerlink\" title=\"推荐结果存储\"></a>推荐结果存储</h3><p>对各种推荐算法计算出的推荐结果的存储。存储空间要求大，格式复杂。对于存储的容量和读写性能要求都比较高。可以选择使用Redis集群作为此部分的存储方案。</p>\n<h3 id=\"服务调用\"><a href=\"#服务调用\" class=\"headerlink\" title=\"服务调用\"></a>服务调用</h3><p>整合用户画像和推荐结果两部分数据，向外提供推荐调用的接口。主要是数据库IO调用开销。</p>\n<p>根据用户id，获取推荐的item列表。</p>\n<p>根据item，获取相关联的item列表。</p>\n<p>根据用户id, 获取用户画像。</p>\n<p>该模块需要采取一定的策略聚合多种推荐算法的推荐结果，直接面向业务。策略由于会随着面向的业务不同而不同，需要可配置化。同时也提供对外暴露用户画像的接口，使得业务方可以使用用户画像做针对性的处理。可以采用RPC机制对外暴露服务接口。</p>\n<h3 id=\"需要考虑的问题\"><a href=\"#需要考虑的问题\" class=\"headerlink\" title=\"需要考虑的问题\"></a>需要考虑的问题</h3><p>对于一个推荐系统，结合其实现目标，还有一些需要注重考虑的问题。</p>\n<h4 id=\"实时性问题\"><a href=\"#实时性问题\" class=\"headerlink\" title=\"实时性问题\"></a>实时性问题</h4><p>由于计算用户、item矩阵或者进行矩阵分解是需要离线进行且比较耗时，因此协同的推荐算法是很难达到实时性的。实时部分的推荐主要依靠基于用户画像的推荐来进行。最终的推荐列表是根据一定的策略对这两部分进行聚合的结果。</p>\n<h4 id=\"时效性内容问题\"><a href=\"#时效性内容问题\" class=\"headerlink\" title=\"时效性内容问题\"></a>时效性内容问题</h4><p>时效性内容指的是那些与时间强相关的内容，比如新闻、时事等。如果一条10天前xx球员获得冠军的新闻现在被推荐了出来，可想用户肯定是莫名其妙或者是很失望的。因此，对于时效性内容，需要与普通的待推荐的内容区分开，做单独的推荐或者不走个性化推荐。</p>\n<h4 id=\"冷启动问题\"><a href=\"#冷启动问题\" class=\"headerlink\" title=\"冷启动问题\"></a>冷启动问题</h4><p>不管使用何种推荐算法，都会面临冷启动问题：当用户是新用户，如何给用户推荐item呢？当内容是新内容，如何推荐给用户？</p>\n<p>对于新用户，可以采取的一种策略就是采用热门推荐或者人工推荐，把绝大多人关心的内容推荐出来。</p>\n<p>对于内容，可以将内容分为新内容池和待推荐内容池。新内容产生时，首先进入新内容池。每次推荐的时候，先从新内容池做候选推荐，并给此内容的传播度+1，直到其传播度大于一个阈值的时候，将其移至待推荐内容池。这样既可以解决新内容的冷启动问题也在一定程度上可以保证新内容的曝光量。</p>\n<h4 id=\"多样性问题\"><a href=\"#多样性问题\" class=\"headerlink\" title=\"多样性问题\"></a>多样性问题</h4><p>在基于用户画像的推荐算法中，取出用户的多个标签，然后根据相关度从不同的标签中取不同数量的内容，这样既兼顾了用户的多种兴趣也能够在一定程度上解决多样性的问题。</p>\n<p>如：用户具有tag:A B C D,相关度为wA wB wC wD，Total推荐为总共需要推荐的条数，那么</p>\n<p>RecommendList(u) = A[Total推荐 <em> wA] + B[Total推荐 </em> wB] + C[Total推荐 <em> wC] + D[Total推荐 </em> wD]</p>\n<h4 id=\"内容质量\"><a href=\"#内容质量\" class=\"headerlink\" title=\"内容质量\"></a>内容质量</h4><p>不管是热门推荐、人工推荐还是取某一标签下的内容列表都牵扯到的一个问题就是：如何给内容排序？</p>\n<p>当用户对内容的喜好不一样，可以按照兴趣度来排序；但当无法区分兴趣度的时候(比如：用户是新用户；内容都是新内容；用户对于某一标签下的内容兴趣度一样)，可以使用内容质量来做排序。click/pv是一种评判内容质量的方式。此外，使用卷积神经网络相关算法也可以构建内容质量模型。</p>\n<h4 id=\"惊喜问题\"><a href=\"#惊喜问题\" class=\"headerlink\" title=\"惊喜问题\"></a>惊喜问题</h4><p>推荐系统的惊喜目标一直是一个难题，被称作EE(Exploit &amp; Explore)问题，bandit算法是解决这个问题的一个派系，就是估计置信区间的做法，然后按照置信区间的上界来进行推荐，以UCB、LinUCB为代表的。简单点说就是先不考虑你喜不喜欢就把质量高的内容推荐给你，后面根据用户的行为反馈对推荐内容作调整。具体的可以参见此篇文章：推荐系统的苟且和远方。</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>借用推荐系统的那点事一文的几句话做为结语：</p>\n<p>实力派的【算法工程师】往往都是ABC[always be coding]，这样的算法工程师才能根据实际问题建立模型或者建立规则库，是真正能解决问题的人。往往是一些有研究背景，经验丰富的研究员，更加重视工程，因为工程架构上一些恰当合理的设计，效果往往就能远远高过于模型算法优化。</p>\n<p>学院派的【算法工程师】往往是为了算法而算法，而不是为了解决推荐系统的问题去找最适合算法。这也是为什么大公司经常招了一些博士毕业的算法工程师后，不是研究算法而是让他们整天在那看数据报表？【因为发现算法没啥好研究，只能让他们在那看看报表找找规律了。】</p>\n<p>【几乎所有所谓的智能推荐算法都是花拳绣腿】</p>\n<p>当一个做推荐系统的部门开始重视【数据清理，数据标柱，效果评测，数据统计，数据分析】这些所谓的脏活累活，这样的推荐系统才会有救。</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cj814lkce0000pjs6jwpjkson","category_id":"cj814lkcn0004pjs6j6w32492","_id":"cj814lkcv000epjs6km8jpd9q"},{"post_id":"cj814lkcl0002pjs6ah38leva","category_id":"cj814lkcn0004pjs6j6w32492","_id":"cj814lkcx000ipjs6vbs1fnfd"},{"post_id":"cj814lkcp0006pjs66cch88hm","category_id":"cj814lkcn0004pjs6j6w32492","_id":"cj814lkcy000kpjs63pquas3g"}],"PostTag":[{"post_id":"cj814lkce0000pjs6jwpjkson","tag_id":"cj814lkcp0005pjs6ux3173im","_id":"cj814lkcv000dpjs65pw1p7j2"},{"post_id":"cj814lkcl0002pjs6ah38leva","tag_id":"cj814lkct000bpjs6dw0wk753","_id":"cj814lkcx000hpjs6da49jqrq"},{"post_id":"cj814lkcp0006pjs66cch88hm","tag_id":"cj814lkcp0005pjs6ux3173im","_id":"cj814lkcy000jpjs62xa9rc6i"}],"Tag":[{"name":"geeker","_id":"cj814lkcp0005pjs6ux3173im"},{"name":"rec","_id":"cj814lkct000bpjs6dw0wk753"}]}}
{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/vexo/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/vexo/source/js/script.js","path":"js/script.js","modified":0,"renderable":1},{"_id":"themes/vexo/source/js/qrious.js","path":"js/qrious.js","modified":0,"renderable":1},{"_id":"themes/vexo/source/css/images/menu.png","path":"css/images/menu.png","modified":0,"renderable":1},{"_id":"themes/vexo/source/css/images/escheres.png","path":"css/images/escheres.png","modified":0,"renderable":1},{"_id":"themes/vexo/source/css/images/top.png","path":"css/images/top.png","modified":0,"renderable":1},{"_id":"themes/vexo/source/css/plugins/gitment.css","path":"css/plugins/gitment.css","modified":0,"renderable":1},{"_id":"themes/vexo/source/css/images/alipay.png","path":"css/images/alipay.png","modified":0,"renderable":1},{"_id":"themes/vexo/source/css/images/wechat.png","path":"css/images/wechat.png","modified":0,"renderable":1},{"_id":"themes/vexo/source/js/gitment.js","path":"js/gitment.js","modified":0,"renderable":1},{"_id":"themes/vexo/source/fonts/SourceSansPro.ttf","path":"fonts/SourceSansPro.ttf","modified":0,"renderable":1},{"_id":"themes/vexo/source/css/images/logo.png","path":"css/images/logo.png","modified":0,"renderable":1},{"_id":"source/robots.txt","path":"robots.txt","modified":0,"renderable":0}],"Cache":[{"_id":"source/.DS_Store","hash":"b48c4f7d61a5928be717d4bd654481ff1eab36ee","modified":1506398227000},{"_id":"themes/vexo/.gitignore","hash":"37fb9fd49e7f944716efd3284a6bf55adb6dd0c2","modified":1506395539000},{"_id":"themes/vexo/.travis.yml","hash":"ade5797c6eb124979b4af6f94e86c1431337b5d7","modified":1506395539000},{"_id":"themes/vexo/LICENSE","hash":"3e135cd69c0e02c0a49dd43d571f600223cc61d1","modified":1506395534000},{"_id":"themes/vexo/README.md","hash":"9c72a193211a48689e7c700ed7d7aa54123d862c","modified":1506395543000},{"_id":"themes/vexo/_config.yml","hash":"c8970cf47ce40843c9b5da6d0563501098dd3b2b","modified":1506410715000},{"_id":"themes/vexo/lint.sh","hash":"f580302e4aa9ccfb95a253851da6501d145613fe","modified":1506395539000},{"_id":"themes/vexo/package.json","hash":"4a839847a872079d154a4884182a7bc773e76535","modified":1506395543000},{"_id":"source/_posts/how-to-be-a-geeker.md","hash":"12df737e8a6854f07f2019f2a5c5d6cf61fb95c1","modified":1506395533000},{"_id":"source/_posts/test.md","hash":"9a315c557e64975b91ccb3796ed9f969edc3421c","modified":1506403200000},{"_id":"source/_posts/test3.md","hash":"6dc64d5b0b220361c7a6e8cc80cfd07ddb7bfc2a","modified":1506398223000},{"_id":"source/about/index.md","hash":"68c8af0453deca5f6b03eb18ee6f89fb0c1f1f75","modified":1506395533000},{"_id":"source/_posts/test2.md","hash":"197fa93f9c263e552ce98baedd789e4e196368cd","modified":1506395533000},{"_id":"source/bookshelf/index.md","hash":"a431cd000eb907a570e4d08c1629ff938fd0317b","modified":1506395533000},{"_id":"source/search/index.md","hash":"25f79ca74c25c2fd943e9761aebd1c9b45c92252","modified":1506395532000},{"_id":"source/resys/index.md","hash":"5b9e423d3737bb3852498e860d2c056dacb9ee8c","modified":1506395533000},{"_id":"source/tags/index.md","hash":"80a15f1b5daff22b04849109e976bc91a410b83e","modified":1506395533000},{"_id":"themes/vexo/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1506395538000},{"_id":"themes/vexo/.git/config","hash":"85b0752953f75d6b59eb0ac5f1a1b61a4b48ca00","modified":1506395536000},{"_id":"themes/vexo/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1506395535000},{"_id":"themes/vexo/.git/index","hash":"c369630adb2eda0c04d01816caa8d1fe8d8c88c3","modified":1506399061000},{"_id":"themes/vexo/.git/packed-refs","hash":"104d2c2c94d832902c078ae982aba2c4d34ecd01","modified":1506395534000},{"_id":"themes/vexo/layout/index.ejs","hash":"6c7358c1d6a3fb5ae19dea47cea708c9896809a2","modified":1506395533000},{"_id":"themes/vexo/layout/about.ejs","hash":"9d0f12efdc59859aec21fd7c4acab9ac150a4cd5","modified":1506395533000},{"_id":"themes/vexo/layout/archive.ejs","hash":"cb12abb19cb70e90d410a6233933eedb3f2c033a","modified":1506395534000},{"_id":"themes/vexo/layout/layout.ejs","hash":"a7b8f1debdca12d667ecd1bcc3d4bc6e13a23d7b","modified":1506395533000},{"_id":"themes/vexo/layout/page.ejs","hash":"c953764278ac03794e08cfe6d7cc0d378d5e8406","modified":1506395533000},{"_id":"themes/vexo/layout/tags.ejs","hash":"5b326e2bd3292b3015d0666b796544d7126acfda","modified":1506395533000},{"_id":"themes/vexo/.git/hooks/applypatch-msg.sample","hash":"86b9655a9ebbde13ac8dd5795eb4d5b539edab0f","modified":1506395536000},{"_id":"themes/vexo/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1506395535000},{"_id":"themes/vexo/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1506395536000},{"_id":"themes/vexo/.git/hooks/pre-applypatch.sample","hash":"42fa41564917b44183a50c4d94bb03e1768ddad8","modified":1506395536000},{"_id":"themes/vexo/.git/hooks/pre-push.sample","hash":"503c3d2cd9066c2329ae84309c03a4c274f6d90e","modified":1506395536000},{"_id":"themes/vexo/.git/hooks/pre-commit.sample","hash":"e6c9fe47f7506171be08ed90baaf91d49bc7fe0c","modified":1506395535000},{"_id":"themes/vexo/.git/hooks/pre-rebase.sample","hash":"5885a56ab4fca8075a05a562d005e922cde9853b","modified":1506395536000},{"_id":"themes/vexo/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1506395536000},{"_id":"themes/vexo/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1506395535000},{"_id":"themes/vexo/.git/hooks/update.sample","hash":"39355a075977d05708ef74e1b66d09a36e486df1","modified":1506395536000},{"_id":"themes/vexo/.git/logs/HEAD","hash":"eafb8b087d529997eed94a846d8cc2f64862efe4","modified":1506395535000},{"_id":"themes/vexo/_source/about/index.md","hash":"68c8af0453deca5f6b03eb18ee6f89fb0c1f1f75","modified":1506395539000},{"_id":"themes/vexo/_source/tags/index.md","hash":"80a15f1b5daff22b04849109e976bc91a410b83e","modified":1506395539000},{"_id":"themes/vexo/_source/project/index.md","hash":"b8f5482c157514bd2df4ce8a4e4d01a957497924","modified":1506395539000},{"_id":"themes/vexo/layout/_partial/archive.ejs","hash":"9abbf14034d581569c0b6c992fe22035cb5306b3","modified":1506395534000},{"_id":"themes/vexo/layout/_partial/footer.ejs","hash":"63625ff0335f0c1ebfa3cd1f9a6018321fba82df","modified":1506415204000},{"_id":"themes/vexo/layout/_partial/head.ejs","hash":"9c2cb91d07c78657eb6723a1629fee96dc5b2176","modified":1506414830000},{"_id":"themes/vexo/layout/_partial/header.ejs","hash":"e544f516b23bc609cc6367190f380c879b935c21","modified":1506395534000},{"_id":"themes/vexo/layout/_partial/pager.ejs","hash":"3a1b9680fbfa3baa76933c7c17216996381ad241","modified":1506395534000},{"_id":"themes/vexo/layout/_partial/top.ejs","hash":"f09dea486246a580213005b21d4b38810dd16fb3","modified":1506395534000},{"_id":"themes/vexo/layout/_partial/tag.ejs","hash":"5d2a2c3f8ca7000945ab426a0c6939421974b224","modified":1506395534000},{"_id":"themes/vexo/source/css/_config.styl","hash":"ac69c720d1699d2c93982b81c233c02982fc01be","modified":1506395542000},{"_id":"themes/vexo/source/css/style.styl","hash":"f2a32891e67d53d0414daa3255167296204d7f51","modified":1506395542000},{"_id":"themes/vexo/source/js/script.js","hash":"a19ed5f3c1d9c64855f162bce7ec66b47aada780","modified":1506395540000},{"_id":"themes/vexo/source/js/qrious.js","hash":"a9271e81e2ac6a692b1c133811afa33f0f3d7dc5","modified":1506395539000},{"_id":"themes/vexo/.git/objects/pack/pack-d44dd37d3af2471e8252d8ae7ee49d1d06ae37a5.idx","hash":"2c7f9275cdc6b9c9b8c807b390b28a1c5bdd05b4","modified":1506395538000},{"_id":"themes/vexo/.git/refs/heads/master","hash":"daab59e07919301fe79e877aa08b31b4fdf37fd7","modified":1506395538000},{"_id":"themes/vexo/source/css/_partial/about.styl","hash":"e4a9bffe9c44c3179c021e2d924386ff9f758399","modified":1506395542000},{"_id":"themes/vexo/source/css/_partial/footer.styl","hash":"acc26664e5b3bdb40534496234a66fca2994e905","modified":1506395542000},{"_id":"themes/vexo/source/css/_partial/archive.styl","hash":"e80ddf26f2af3523632afeabd57f81592537985a","modified":1506395542000},{"_id":"themes/vexo/source/css/_partial/header.styl","hash":"def3a6938d925c585a7da6256a6f2e90f3b7d61e","modified":1506395542000},{"_id":"themes/vexo/source/css/_partial/markdown.styl","hash":"c141d008eae51b55eb0ea0526860046974f3be49","modified":1506395542000},{"_id":"themes/vexo/source/css/_partial/project.styl","hash":"e9b6faadf4852bce3a4141cba0a102a7afb81e9f","modified":1506395542000},{"_id":"themes/vexo/source/css/_partial/tags.styl","hash":"5198a7f7c221341138ae5c65185e86b6e13e8e26","modified":1506395542000},{"_id":"themes/vexo/source/css/_partial/pager.styl","hash":"888384c67429c7568aa38b5ebe5acae3cc4de367","modified":1506395542000},{"_id":"themes/vexo/source/css/images/menu.png","hash":"bdaa35eb1ed119caeb934e15a05b9f4a5396d957","modified":1506395541000},{"_id":"themes/vexo/source/css/images/logo.png.bak","hash":"718c6e48956249121cf3cca1a22a99f8372a3f0d","modified":1506395542000},{"_id":"themes/vexo/source/css/images/escheres.png","hash":"55deece3236dcc2fb44c28dec3e8bacbb7b46542","modified":1506395542000},{"_id":"themes/vexo/source/css/images/alipay.jpg.bak","hash":"c49822ea6f06f868c2404fb00a93f913c8fff7b5","modified":1506395541000},{"_id":"themes/vexo/source/css/images/top.png","hash":"611a257907474ca02828319f81b006c1d818bb84","modified":1506395541000},{"_id":"themes/vexo/source/css/plugins/gitment.css","hash":"541ff18d7f3542b5663dc6aad06d43e135332b71","modified":1506395541000},{"_id":"themes/vexo/source/css/images/wechat.jpg.bak","hash":"5bed6d3eb9f71b227b0ea0187c1a7ba8caf5ee64","modified":1506395542000},{"_id":"themes/vexo/source/css/images/alipay.png","hash":"9f6b1c1389daf4d4725e1dd0649882463940687b","modified":1506395541000},{"_id":"themes/vexo/source/css/images/wechat.png","hash":"047933e41de09c3931e5c16fb008038bb55aec8e","modified":1506395542000},{"_id":"themes/vexo/source/js/gitment.js","hash":"376446d9c5930576016f97dd63e5e6616c94d8d4","modified":1506395540000},{"_id":"themes/vexo/source/fonts/SourceSansPro.ttf","hash":"1e9f0372c269da205fdbac8cf27cb9cf59f6ad45","modified":1506395539000},{"_id":"themes/vexo/.git/logs/refs/heads/master","hash":"eafb8b087d529997eed94a846d8cc2f64862efe4","modified":1506395535000},{"_id":"themes/vexo/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1506395539000},{"_id":"themes/vexo/.git/logs/refs/remotes/origin/HEAD","hash":"eafb8b087d529997eed94a846d8cc2f64862efe4","modified":1506395535000},{"_id":"themes/vexo/.git/objects/pack/pack-d44dd37d3af2471e8252d8ae7ee49d1d06ae37a5.pack","hash":"c8d50f49b877fed5ed96d6fb858c8ed4f7445295","modified":1506395538000},{"_id":"public/atom.xml","hash":"346a8db18f57df0950c7eb9249b0f344e61ca366","modified":1506412293696},{"_id":"public/sitemap.xml","hash":"baaf98ba0c5ff789146418503e77e53467132150","modified":1506412293699},{"_id":"public/about/index.html","hash":"56cba9396bf3ba6fd476eae539dd4c6b78304e9f","modified":1506415212906},{"_id":"public/tags/index.html","hash":"cc326820a8b9cf1c0ec107198cad0dd849edf3e0","modified":1506415212907},{"_id":"public/resys/index.html","hash":"8ee9bbcbbd422b2c671f67f177d2b40f1f3124d5","modified":1506415212906},{"_id":"public/2017/09/23/test3/index.html","hash":"2f7d7eb210632d99eb768e6b1aadcc959d6fb129","modified":1506410964107},{"_id":"public/archives/index.html","hash":"d9d337c02a85b80219c112ca51a2160bfc4a68d3","modified":1506415212907},{"_id":"public/2017/06/03/how-to-be-a-geeker/index.html","hash":"9972287d8fe5621e3376e4411209e464fa208e83","modified":1506415212907},{"_id":"public/archives/2017/index.html","hash":"5e7dda501b81610aa90ab3ca42df5593072b098b","modified":1506415212907},{"_id":"public/archives/2017/06/index.html","hash":"fbb8c6b8cea00639b4547752871e3b0dd18efd34","modified":1506415212907},{"_id":"public/archives/2017/09/index.html","hash":"2ffe2755a3f81e8b17563844edc5a8c9f1dcd025","modified":1506415212907},{"_id":"public/index.html","hash":"3d0e8cf93daf3a75b1026a07233ff3aa901d3d5c","modified":1506415212907},{"_id":"public/categories/Thought/index.html","hash":"5cca473e59bd944d83ddf0b954eb4af5eae18da1","modified":1506415212907},{"_id":"public/tags/geeker/index.html","hash":"6d6beb295a88913db8c61a943d2b5fa5b4f83e16","modified":1506415212908},{"_id":"public/search/index.html","hash":"444df09c820443f89246230856935fd78aaa638d","modified":1506415212906},{"_id":"public/bookshelf/index.html","hash":"3548a1690b4fa2e7ae9674b4a22c2864e40d5c8b","modified":1506415212906},{"_id":"public/tags/rec/index.html","hash":"382b359516d0868f6f27b2a94c92344a4c26001b","modified":1506410964108},{"_id":"public/2017/09/26/test2/index.html","hash":"ea13abfea7656575703a1eee537fe4e838c34f79","modified":1506410964108},{"_id":"public/2017/09/26/test/index.html","hash":"7471c36ce3d531e22f2feae5104b688ce5567be3","modified":1506410964108},{"_id":"public/css/images/menu.png","hash":"bdaa35eb1ed119caeb934e15a05b9f4a5396d957","modified":1506401567926},{"_id":"public/css/images/alipay.jpg.bak","hash":"c49822ea6f06f868c2404fb00a93f913c8fff7b5","modified":1506401567926},{"_id":"public/css/images/top.png","hash":"611a257907474ca02828319f81b006c1d818bb84","modified":1506401567927},{"_id":"public/css/images/wechat.jpg.bak","hash":"5bed6d3eb9f71b227b0ea0187c1a7ba8caf5ee64","modified":1506401567927},{"_id":"public/css/images/alipay.png","hash":"9f6b1c1389daf4d4725e1dd0649882463940687b","modified":1506401567927},{"_id":"public/css/images/wechat.png","hash":"047933e41de09c3931e5c16fb008038bb55aec8e","modified":1506401567927},{"_id":"public/css/images/escheres.png","hash":"55deece3236dcc2fb44c28dec3e8bacbb7b46542","modified":1506401567927},{"_id":"public/css/images/logo.png.bak","hash":"718c6e48956249121cf3cca1a22a99f8372a3f0d","modified":1506401567927},{"_id":"public/js/script.js","hash":"a19ed5f3c1d9c64855f162bce7ec66b47aada780","modified":1506401567929},{"_id":"public/css/style.css","hash":"91599cbf54c671afad2ec2c6a23bafc132e54050","modified":1506401567930},{"_id":"public/js/qrious.js","hash":"a9271e81e2ac6a692b1c133811afa33f0f3d7dc5","modified":1506401567932},{"_id":"public/css/plugins/gitment.css","hash":"541ff18d7f3542b5663dc6aad06d43e135332b71","modified":1506401567932},{"_id":"public/js/gitment.js","hash":"376446d9c5930576016f97dd63e5e6616c94d8d4","modified":1506401567932},{"_id":"public/fonts/SourceSansPro.ttf","hash":"1e9f0372c269da205fdbac8cf27cb9cf59f6ad45","modified":1506401567933},{"_id":"themes/vexo/source/css/images/logo.png","hash":"3cc2fc6bda241e89369e1cef5887c31368528663","modified":1506405841000},{"_id":"public/css/images/logo.png","hash":"3cc2fc6bda241e89369e1cef5887c31368528663","modified":1506405866890},{"_id":"source/robots.txt","hash":"9631979ef280b534d113141d3752eb719b56f824","modified":1506408836000},{"_id":"public/baidusitemap.xml","hash":"39704cace626a09f7e0d0cb9e8a201f5225f39cf","modified":1506412293649},{"_id":"public/robots.txt","hash":"9631979ef280b534d113141d3752eb719b56f824","modified":1506408883750},{"_id":"source/_posts/elasticsearch_tec_book_v1.01.md","hash":"56aa77f19d796a99c5c63e5e4b531c0936817feb","modified":1506412276000},{"_id":"public/categories/search/index.html","hash":"12fafba5b1c902c9a58a097f8f2a8f45ac803e7a","modified":1506415212907},{"_id":"public/tags/search/index.html","hash":"9a2f2f78b6776814d765aae24067d6aa30b74c58","modified":1506415212908},{"_id":"public/2017/09/26/elasticsearch_tec_book_v1.01/index.html","hash":"7ecee10d9028a4f3b66985fdfd9c5c2135292000","modified":1506415212908},{"_id":"themes/vexo/node_modules/.staging/uslug-d79edd83/.npmignore","hash":"0a861f1091bff14f09cdcf55bf72d2a7f1b4bd1b","modified":1457473856000},{"_id":"themes/vexo/node_modules/.staging/uslug-d79edd83/LICENSE","hash":"2fe6c1073604f5c099a17a5ec183b9015b6e02f3","modified":1457473856000},{"_id":"themes/vexo/node_modules/.staging/uslug-d79edd83/README.md","hash":"624f19c7ea6bfbf91d3d60be9bd6d28c004b2d76","modified":1457473856000},{"_id":"themes/vexo/node_modules/.staging/uslug-d79edd83/index.js","hash":"adcfa6488fb6ff5ddf31d13b589d22dbc176bf96","modified":1457473856000},{"_id":"themes/vexo/node_modules/.staging/uslug-d79edd83/package.json","hash":"1bd898af40f6c47ed08304b5e94c429a5575b518","modified":1457473937000},{"_id":"themes/vexo/node_modules/.staging/uslug-d79edd83/lib/M.js","hash":"e1cad9515147544f2a3edaf6e999033275ea4f26","modified":1457473856000},{"_id":"themes/vexo/node_modules/.staging/uslug-d79edd83/lib/N.js","hash":"35a5ff6b2274af2ade459d0141cf53275ed81b4c","modified":1457473856000},{"_id":"themes/vexo/node_modules/.staging/uslug-d79edd83/test/test.js","hash":"845d084bde9afb8d49274c1fbee586544e7f81ad","modified":1457473856000},{"_id":"themes/vexo/node_modules/.staging/uslug-d79edd83/lib/Z.js","hash":"794d12289bb4ac77e1b97b3965a69c35813ef289","modified":1457473856000},{"_id":"themes/vexo/node_modules/.staging/uslug-d79edd83/lib/uslug.js","hash":"5ebbff4e7c9f8dd8b629dd674ec50c5790d6cfc7","modified":1457473856000},{"_id":"themes/vexo/node_modules/.staging/uslug-d79edd83/lib/L.js","hash":"c5f59c21644741cd89efa99b86dc13b9e64a4abe","modified":1457473856000}],"Category":[{"name":"Thought","_id":"cj814lkcn0004pjs6j6w32492"},{"name":"search","_id":"cj81aidwr00014ss6ml5lez37"}],"Data":[],"Page":[{"title":"About","layout":"about","_content":"","source":"about/index.md","raw":"---\ntitle: About\nlayout: about\n---","date":"2017-09-26T03:12:13.000Z","updated":"2017-09-26T03:12:13.000Z","path":"about/index.html","comments":1,"_id":"cj814lkck0001pjs6mlclzz9r","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Bookshelf","id":1949,"comment":false,"date":"2017-06-03T06:12:10.000Z","_content":"\n## 那些年度过的时间\n\n## Book\n\n(1) **Tcp/ip 详解（卷1）** – 评分：7.0\n\n读后评：介绍计算机网络的比较基础的一本书，在学校或多或少都学过，这里不展开讲了。如果在互联网公司，还是请看第二卷、三卷吧。\n\n(2)Java编程思想\n\n(3)Python CookBook\n\n(4) 大型网站技术架构 – 核心原理与案例分析\n\n(4) 本色（乐嘉）\n\n读后评：通过各方面的了解，我还是比较喜欢乐嘉这个人的，他写的这本书买来读了一下，很是通透。\n(6) **请给我结果**\n\n读后评：直白的语言，有些地方不适合互联网公司。\n(7)**番茄工作方法图解**\n\n读后评：经典的方法，以番茄钟来高效的利用自己的时间，尝试了一段时间。但是，还是被自己码代码的投入忘了时间。\n(8)**黑客与画家**\n\n读后评：我对这本书印象最深的是关于财富、创业、语言的部分，很深刻，有共鸣。\n\n(9) **三体** – 刘慈欣\n\n读后评：在一开始就深深的吸引了我，花了一个周末看完了，其中各种的问题真的很令人深思！\n\n(10) **趁年轻，折腾吧（袁岳）**\n\n读后评：一句话概括：趁年轻，折腾吧！！ 推荐一读\n\n(11) **看见（柴静）**\n\n读后评：以自己的经历（看见的）讲到的近几年的各种事情，让我看到了当年各个事件的另一个方面（好的或者坏的或者更坏的）。推荐阅读\n\n## Paper\n\n(1) Bigtable:A Distributed Storage System for Structured Data ([download](http://document-save.qiniudn.com/zhangxiaolong.orgbigtable-osdi06.pdf))\n(2) GFS:The Google File System ([download](http://document-save.qiniudn.com/zhangxiaolong.orggfs-sosp2003.pdf))\n(3) MapReduce:MapReduce: Simplied Data Processing on Large Clusters ([download](http://document-save.qiniudn.com/zhangxiaolong.orgmapreduce-osdi04.pdf))\n(4) Spanner:Google’s Globally-Distributed Database ([download](http://document-save.qiniudn.com/zhangxiaolong.orgspanner-osdi2012.pdf))\n(5) Megastore: Providing Scalable, Highly Available Storage for Interactive Services ([download](http://document-save.qiniudn.com/zhangxiaolong.orgmegastore.pdf))\n(6) Pregel:A System for Large-Scale Graph Processing ([download](http://document-save.qiniudn.com/zhangxiaolong.orgPregel.pdf))\n(7) Dremel: Interactive Analysis of Web-Scale Datasets ([download](http://document-save.qiniudn.com/zhangxiaolong.orgDremel.pdf))\n(8) Caffeine: Large-scale Incremental Processing Using Distributed Transactions and Notications ([download](http://document-save.qiniudn.com/zhangxiaolong.orgCaffeine%20-1.pdf))\n(9) Search The Web ([download](http://document-save.qiniudn.com/web%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%A6%82%E8%AE%BA%E2%80%94%E2%80%94searching_the_web.pdf))","source":"bookshelf/index.md","raw":"---\ntitle: Bookshelf\nid: 1949\ncomment: false\ndate: 2017-06-03 14:12:10\n---\n\n## 那些年度过的时间\n\n## Book\n\n(1) **Tcp/ip 详解（卷1）** – 评分：7.0\n\n读后评：介绍计算机网络的比较基础的一本书，在学校或多或少都学过，这里不展开讲了。如果在互联网公司，还是请看第二卷、三卷吧。\n\n(2)Java编程思想\n\n(3)Python CookBook\n\n(4) 大型网站技术架构 – 核心原理与案例分析\n\n(4) 本色（乐嘉）\n\n读后评：通过各方面的了解，我还是比较喜欢乐嘉这个人的，他写的这本书买来读了一下，很是通透。\n(6) **请给我结果**\n\n读后评：直白的语言，有些地方不适合互联网公司。\n(7)**番茄工作方法图解**\n\n读后评：经典的方法，以番茄钟来高效的利用自己的时间，尝试了一段时间。但是，还是被自己码代码的投入忘了时间。\n(8)**黑客与画家**\n\n读后评：我对这本书印象最深的是关于财富、创业、语言的部分，很深刻，有共鸣。\n\n(9) **三体** – 刘慈欣\n\n读后评：在一开始就深深的吸引了我，花了一个周末看完了，其中各种的问题真的很令人深思！\n\n(10) **趁年轻，折腾吧（袁岳）**\n\n读后评：一句话概括：趁年轻，折腾吧！！ 推荐一读\n\n(11) **看见（柴静）**\n\n读后评：以自己的经历（看见的）讲到的近几年的各种事情，让我看到了当年各个事件的另一个方面（好的或者坏的或者更坏的）。推荐阅读\n\n## Paper\n\n(1) Bigtable:A Distributed Storage System for Structured Data ([download](http://document-save.qiniudn.com/zhangxiaolong.orgbigtable-osdi06.pdf))\n(2) GFS:The Google File System ([download](http://document-save.qiniudn.com/zhangxiaolong.orggfs-sosp2003.pdf))\n(3) MapReduce:MapReduce: Simplied Data Processing on Large Clusters ([download](http://document-save.qiniudn.com/zhangxiaolong.orgmapreduce-osdi04.pdf))\n(4) Spanner:Google’s Globally-Distributed Database ([download](http://document-save.qiniudn.com/zhangxiaolong.orgspanner-osdi2012.pdf))\n(5) Megastore: Providing Scalable, Highly Available Storage for Interactive Services ([download](http://document-save.qiniudn.com/zhangxiaolong.orgmegastore.pdf))\n(6) Pregel:A System for Large-Scale Graph Processing ([download](http://document-save.qiniudn.com/zhangxiaolong.orgPregel.pdf))\n(7) Dremel: Interactive Analysis of Web-Scale Datasets ([download](http://document-save.qiniudn.com/zhangxiaolong.orgDremel.pdf))\n(8) Caffeine: Large-scale Incremental Processing Using Distributed Transactions and Notications ([download](http://document-save.qiniudn.com/zhangxiaolong.orgCaffeine%20-1.pdf))\n(9) Search The Web ([download](http://document-save.qiniudn.com/web%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%A6%82%E8%AE%BA%E2%80%94%E2%80%94searching_the_web.pdf))","updated":"2017-09-26T03:12:13.000Z","path":"bookshelf/index.html","comments":1,"layout":"page","_id":"cj814lkcm0003pjs6qxx7z31z","content":"<h2 id=\"那些年度过的时间\"><a href=\"#那些年度过的时间\" class=\"headerlink\" title=\"那些年度过的时间\"></a>那些年度过的时间</h2><h2 id=\"Book\"><a href=\"#Book\" class=\"headerlink\" title=\"Book\"></a>Book</h2><p>(1) <strong>Tcp/ip 详解（卷1）</strong> – 评分：7.0</p>\n<p>读后评：介绍计算机网络的比较基础的一本书，在学校或多或少都学过，这里不展开讲了。如果在互联网公司，还是请看第二卷、三卷吧。</p>\n<p>(2)Java编程思想</p>\n<p>(3)Python CookBook</p>\n<p>(4) 大型网站技术架构 – 核心原理与案例分析</p>\n<p>(4) 本色（乐嘉）</p>\n<p>读后评：通过各方面的了解，我还是比较喜欢乐嘉这个人的，他写的这本书买来读了一下，很是通透。<br>(6) <strong>请给我结果</strong></p>\n<p>读后评：直白的语言，有些地方不适合互联网公司。<br>(7)<strong>番茄工作方法图解</strong></p>\n<p>读后评：经典的方法，以番茄钟来高效的利用自己的时间，尝试了一段时间。但是，还是被自己码代码的投入忘了时间。<br>(8)<strong>黑客与画家</strong></p>\n<p>读后评：我对这本书印象最深的是关于财富、创业、语言的部分，很深刻，有共鸣。</p>\n<p>(9) <strong>三体</strong> – 刘慈欣</p>\n<p>读后评：在一开始就深深的吸引了我，花了一个周末看完了，其中各种的问题真的很令人深思！</p>\n<p>(10) <strong>趁年轻，折腾吧（袁岳）</strong></p>\n<p>读后评：一句话概括：趁年轻，折腾吧！！ 推荐一读</p>\n<p>(11) <strong>看见（柴静）</strong></p>\n<p>读后评：以自己的经历（看见的）讲到的近几年的各种事情，让我看到了当年各个事件的另一个方面（好的或者坏的或者更坏的）。推荐阅读</p>\n<h2 id=\"Paper\"><a href=\"#Paper\" class=\"headerlink\" title=\"Paper\"></a>Paper</h2><p>(1) Bigtable:A Distributed Storage System for Structured Data (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgbigtable-osdi06.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(2) GFS:The Google File System (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orggfs-sosp2003.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(3) MapReduce:MapReduce: Simplied Data Processing on Large Clusters (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgmapreduce-osdi04.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(4) Spanner:Google’s Globally-Distributed Database (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgspanner-osdi2012.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(5) Megastore: Providing Scalable, Highly Available Storage for Interactive Services (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgmegastore.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(6) Pregel:A System for Large-Scale Graph Processing (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgPregel.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(7) Dremel: Interactive Analysis of Web-Scale Datasets (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgDremel.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(8) Caffeine: Large-scale Incremental Processing Using Distributed Transactions and Notications (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgCaffeine%20-1.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(9) Search The Web (<a href=\"http://document-save.qiniudn.com/web%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%A6%82%E8%AE%BA%E2%80%94%E2%80%94searching_the_web.pdf\" target=\"_blank\" rel=\"external\">download</a>)</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"那些年度过的时间\"><a href=\"#那些年度过的时间\" class=\"headerlink\" title=\"那些年度过的时间\"></a>那些年度过的时间</h2><h2 id=\"Book\"><a href=\"#Book\" class=\"headerlink\" title=\"Book\"></a>Book</h2><p>(1) <strong>Tcp/ip 详解（卷1）</strong> – 评分：7.0</p>\n<p>读后评：介绍计算机网络的比较基础的一本书，在学校或多或少都学过，这里不展开讲了。如果在互联网公司，还是请看第二卷、三卷吧。</p>\n<p>(2)Java编程思想</p>\n<p>(3)Python CookBook</p>\n<p>(4) 大型网站技术架构 – 核心原理与案例分析</p>\n<p>(4) 本色（乐嘉）</p>\n<p>读后评：通过各方面的了解，我还是比较喜欢乐嘉这个人的，他写的这本书买来读了一下，很是通透。<br>(6) <strong>请给我结果</strong></p>\n<p>读后评：直白的语言，有些地方不适合互联网公司。<br>(7)<strong>番茄工作方法图解</strong></p>\n<p>读后评：经典的方法，以番茄钟来高效的利用自己的时间，尝试了一段时间。但是，还是被自己码代码的投入忘了时间。<br>(8)<strong>黑客与画家</strong></p>\n<p>读后评：我对这本书印象最深的是关于财富、创业、语言的部分，很深刻，有共鸣。</p>\n<p>(9) <strong>三体</strong> – 刘慈欣</p>\n<p>读后评：在一开始就深深的吸引了我，花了一个周末看完了，其中各种的问题真的很令人深思！</p>\n<p>(10) <strong>趁年轻，折腾吧（袁岳）</strong></p>\n<p>读后评：一句话概括：趁年轻，折腾吧！！ 推荐一读</p>\n<p>(11) <strong>看见（柴静）</strong></p>\n<p>读后评：以自己的经历（看见的）讲到的近几年的各种事情，让我看到了当年各个事件的另一个方面（好的或者坏的或者更坏的）。推荐阅读</p>\n<h2 id=\"Paper\"><a href=\"#Paper\" class=\"headerlink\" title=\"Paper\"></a>Paper</h2><p>(1) Bigtable:A Distributed Storage System for Structured Data (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgbigtable-osdi06.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(2) GFS:The Google File System (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orggfs-sosp2003.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(3) MapReduce:MapReduce: Simplied Data Processing on Large Clusters (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgmapreduce-osdi04.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(4) Spanner:Google’s Globally-Distributed Database (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgspanner-osdi2012.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(5) Megastore: Providing Scalable, Highly Available Storage for Interactive Services (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgmegastore.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(6) Pregel:A System for Large-Scale Graph Processing (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgPregel.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(7) Dremel: Interactive Analysis of Web-Scale Datasets (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgDremel.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(8) Caffeine: Large-scale Incremental Processing Using Distributed Transactions and Notications (<a href=\"http://document-save.qiniudn.com/zhangxiaolong.orgCaffeine%20-1.pdf\" target=\"_blank\" rel=\"external\">download</a>)<br>(9) Search The Web (<a href=\"http://document-save.qiniudn.com/web%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%A6%82%E8%AE%BA%E2%80%94%E2%80%94searching_the_web.pdf\" target=\"_blank\" rel=\"external\">download</a>)</p>\n"},{"title":"Search","id":1842,"comment":false,"date":"2017-05-22T04:05:33.000Z","_content":"","source":"search/index.md","raw":"---\ntitle: Search\nid: 1842\ncomment: false\ndate: 2017-05-22 12:05:33\n---\n","updated":"2017-09-26T03:12:12.000Z","path":"search/index.html","comments":1,"layout":"page","_id":"cj814lkcq0007pjs6igh0afuw","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"resys","date":"2017-09-26T01:52:24.000Z","_content":"### 自己动手打造推荐系统系列\n\n包含论文阅读和代码实现","source":"resys/index.md","raw":"title: resys\ndate: 2017-09-26 09:52:24\n---\n### 自己动手打造推荐系统系列\n\n包含论文阅读和代码实现","updated":"2017-09-26T03:12:13.000Z","path":"resys/index.html","comments":1,"layout":"page","_id":"cj814lkcs0009pjs6sl2utoxy","content":"<h3 id=\"自己动手打造推荐系统系列\"><a href=\"#自己动手打造推荐系统系列\" class=\"headerlink\" title=\"自己动手打造推荐系统系列\"></a>自己动手打造推荐系统系列</h3><p>包含论文阅读和代码实现</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"自己动手打造推荐系统系列\"><a href=\"#自己动手打造推荐系统系列\" class=\"headerlink\" title=\"自己动手打造推荐系统系列\"></a>自己动手打造推荐系统系列</h3><p>包含论文阅读和代码实现</p>\n"},{"title":"Tags","layout":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: Tags\nlayout: tags\n---\n","date":"2017-09-26T03:12:13.000Z","updated":"2017-09-26T03:12:13.000Z","path":"tags/index.html","comments":1,"_id":"cj814lkct000cpjs66u86l7cz","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"How to be a Geeker?","id":"1945","date":"2017-06-03T05:50:17.000Z","_content":"\n看到这篇以前的文章，回忆一下，2014年7月毕业开始了北漂的\"码农\"的生活，有幸被公司邀请写一篇文章，随写之。\n\n非常感谢@内部沟通部发来的约稿邮件，让我聊一聊程序员的那些事儿。作为一名程序猿，有很多有关技术方面的ideas可以拿来和大家进行分享和探讨。我是一个特别爱折腾的人，对于新技术、新产品都会去尝试一下，所以在技术学习、工作、程序开发方面，我有一些想法，和大家交流一下。\n\n1.做自己`喜欢并且擅长`的事情\n这句话是我在一位技术大牛身上学到的，我们每做一个件事情都是有驱动的，如果你做了自己喜欢并且擅长的事情，那很可能取得你想要的成功。在雏鹰培训的时候，吴正老师给我们上的培训叫发现自己的优势，我觉得很有意义，可以找到自己优势和不足，让我们在擅长的方面找到自己喜欢去做的，并且将它做到极致，那也是一种成功，一种geek精神的体现吧。\n\n2.做一个自己的技术博客\n作为一个技术人，搭建一个属于自己的博客是很有意思和意义的事情。在搭建博客的过程中你可以学习到一些技术知识，比如域名解析、博客主机配置、编写博客程序等等，自由度非常大，动手去实现收获也是非常巨大的。当自己对某些技术有独到的见解可以通过博客的形式分享出去和别人交流。在做博客的过程中，我也会去关注圈内大牛的技术博客（酷壳等）、百度，阿里等官方博客，RSS订阅一些博客，随时学习和接触领域中的新知识。\n\n3.怎样迅速加入一个技术圈\n如果在某一领域是技术“小白”，怎么才能够迅速加入呢。你可以从以下两个方面入手。一是是自我学习，二是和该领域中的技术牛人交流。\n自我学习方式我在实践中总结了一下:\n\n*   Wiki，了解其介绍、使用、API、文档等等；\n*   Presentation，学习大牛的技术分享，特别推荐slideshare.net；\n*   Paper，技术领域都有很多的paper可以去深入学习，比如在大数据领域中google的“前三后三”6篇经典论文；\n*   Video，一提这个可能会想到网易公开课等视频网站，但我会更加推荐你去Youtube或者confreaks.com，特别强大和丰富；\n*   Blog，关注该领域大牛的博客。\n\n当自我学习到一定程度时，你可能希望和这些大牛进行“有深度”的交流，但是如何去找到这些大牛呢？首先google一下该领域大牛，在facebook、twitter、Boogle（maybe sina）中找到，由他们可以带你进入一个Group，此时，可以说你加入了这个技术圈（更重要的是去研究、交流，而不是止于形式）。\n\n4.一天可以学会的实用技能\n如果给你一天时间，你能学会哪些实用的计算机相关技能？这是我在Quora看到的一个问题，下面有很多的回复。我曾经尝试去做过一些，比如学会正则表达式、写一个网络爬虫，解析基本数据等等，可能你会觉得某些技术难，不好下手，不妨试试这种带有挑战意义的方式。尝试后你可能就会发现学习技术并不是不难，只要你有兴趣去发现、去尝试、去研究！\n\n5.我们不只是会写代码的程序员\n如果说掌握一门技术是我们的首要任务的话，那么，我认为技术人员要学会一些更重要的东西，不是技术，而是业务、交流与协作。如果立志要成为一名架构师，后面的是我们更需要学习的东西。架构师需要根据业务需求和扩展，能够了解其未来的发展趋势，理解架构系统所涉及的方方面面，才能设计出更可靠安全的的系统架构。所以我们不要把程序员定位为写代码一类人，我们是发现新技术、创造新产品的superman。\n\n不知不觉已经写了好多内容，还有很多想和大家分享的东西没有讲到，限于篇幅我就不展开讨论了，欢迎大家随时和我进行分享交流，共同进步成为大牛！","source":"_posts/how-to-be-a-geeker.md","raw":"---\ntitle: How to be a Geeker?\ntags:\n  - geeker\nid: 1945\ncategories:\n  - Thought\ndate: 2017-06-03 13:50:17\n---\n\n看到这篇以前的文章，回忆一下，2014年7月毕业开始了北漂的\"码农\"的生活，有幸被公司邀请写一篇文章，随写之。\n\n非常感谢@内部沟通部发来的约稿邮件，让我聊一聊程序员的那些事儿。作为一名程序猿，有很多有关技术方面的ideas可以拿来和大家进行分享和探讨。我是一个特别爱折腾的人，对于新技术、新产品都会去尝试一下，所以在技术学习、工作、程序开发方面，我有一些想法，和大家交流一下。\n\n1.做自己`喜欢并且擅长`的事情\n这句话是我在一位技术大牛身上学到的，我们每做一个件事情都是有驱动的，如果你做了自己喜欢并且擅长的事情，那很可能取得你想要的成功。在雏鹰培训的时候，吴正老师给我们上的培训叫发现自己的优势，我觉得很有意义，可以找到自己优势和不足，让我们在擅长的方面找到自己喜欢去做的，并且将它做到极致，那也是一种成功，一种geek精神的体现吧。\n\n2.做一个自己的技术博客\n作为一个技术人，搭建一个属于自己的博客是很有意思和意义的事情。在搭建博客的过程中你可以学习到一些技术知识，比如域名解析、博客主机配置、编写博客程序等等，自由度非常大，动手去实现收获也是非常巨大的。当自己对某些技术有独到的见解可以通过博客的形式分享出去和别人交流。在做博客的过程中，我也会去关注圈内大牛的技术博客（酷壳等）、百度，阿里等官方博客，RSS订阅一些博客，随时学习和接触领域中的新知识。\n\n3.怎样迅速加入一个技术圈\n如果在某一领域是技术“小白”，怎么才能够迅速加入呢。你可以从以下两个方面入手。一是是自我学习，二是和该领域中的技术牛人交流。\n自我学习方式我在实践中总结了一下:\n\n*   Wiki，了解其介绍、使用、API、文档等等；\n*   Presentation，学习大牛的技术分享，特别推荐slideshare.net；\n*   Paper，技术领域都有很多的paper可以去深入学习，比如在大数据领域中google的“前三后三”6篇经典论文；\n*   Video，一提这个可能会想到网易公开课等视频网站，但我会更加推荐你去Youtube或者confreaks.com，特别强大和丰富；\n*   Blog，关注该领域大牛的博客。\n\n当自我学习到一定程度时，你可能希望和这些大牛进行“有深度”的交流，但是如何去找到这些大牛呢？首先google一下该领域大牛，在facebook、twitter、Boogle（maybe sina）中找到，由他们可以带你进入一个Group，此时，可以说你加入了这个技术圈（更重要的是去研究、交流，而不是止于形式）。\n\n4.一天可以学会的实用技能\n如果给你一天时间，你能学会哪些实用的计算机相关技能？这是我在Quora看到的一个问题，下面有很多的回复。我曾经尝试去做过一些，比如学会正则表达式、写一个网络爬虫，解析基本数据等等，可能你会觉得某些技术难，不好下手，不妨试试这种带有挑战意义的方式。尝试后你可能就会发现学习技术并不是不难，只要你有兴趣去发现、去尝试、去研究！\n\n5.我们不只是会写代码的程序员\n如果说掌握一门技术是我们的首要任务的话，那么，我认为技术人员要学会一些更重要的东西，不是技术，而是业务、交流与协作。如果立志要成为一名架构师，后面的是我们更需要学习的东西。架构师需要根据业务需求和扩展，能够了解其未来的发展趋势，理解架构系统所涉及的方方面面，才能设计出更可靠安全的的系统架构。所以我们不要把程序员定位为写代码一类人，我们是发现新技术、创造新产品的superman。\n\n不知不觉已经写了好多内容，还有很多想和大家分享的东西没有讲到，限于篇幅我就不展开讨论了，欢迎大家随时和我进行分享交流，共同进步成为大牛！","slug":"how-to-be-a-geeker","published":1,"updated":"2017-09-26T03:12:13.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj814lkce0000pjs6jwpjkson","content":"<p>看到这篇以前的文章，回忆一下，2014年7月毕业开始了北漂的”码农”的生活，有幸被公司邀请写一篇文章，随写之。</p>\n<p>非常感谢@内部沟通部发来的约稿邮件，让我聊一聊程序员的那些事儿。作为一名程序猿，有很多有关技术方面的ideas可以拿来和大家进行分享和探讨。我是一个特别爱折腾的人，对于新技术、新产品都会去尝试一下，所以在技术学习、工作、程序开发方面，我有一些想法，和大家交流一下。</p>\n<p>1.做自己<code>喜欢并且擅长</code>的事情<br>这句话是我在一位技术大牛身上学到的，我们每做一个件事情都是有驱动的，如果你做了自己喜欢并且擅长的事情，那很可能取得你想要的成功。在雏鹰培训的时候，吴正老师给我们上的培训叫发现自己的优势，我觉得很有意义，可以找到自己优势和不足，让我们在擅长的方面找到自己喜欢去做的，并且将它做到极致，那也是一种成功，一种geek精神的体现吧。</p>\n<p>2.做一个自己的技术博客<br>作为一个技术人，搭建一个属于自己的博客是很有意思和意义的事情。在搭建博客的过程中你可以学习到一些技术知识，比如域名解析、博客主机配置、编写博客程序等等，自由度非常大，动手去实现收获也是非常巨大的。当自己对某些技术有独到的见解可以通过博客的形式分享出去和别人交流。在做博客的过程中，我也会去关注圈内大牛的技术博客（酷壳等）、百度，阿里等官方博客，RSS订阅一些博客，随时学习和接触领域中的新知识。</p>\n<p>3.怎样迅速加入一个技术圈<br>如果在某一领域是技术“小白”，怎么才能够迅速加入呢。你可以从以下两个方面入手。一是是自我学习，二是和该领域中的技术牛人交流。<br>自我学习方式我在实践中总结了一下:</p>\n<ul>\n<li>Wiki，了解其介绍、使用、API、文档等等；</li>\n<li>Presentation，学习大牛的技术分享，特别推荐slideshare.net；</li>\n<li>Paper，技术领域都有很多的paper可以去深入学习，比如在大数据领域中google的“前三后三”6篇经典论文；</li>\n<li>Video，一提这个可能会想到网易公开课等视频网站，但我会更加推荐你去Youtube或者confreaks.com，特别强大和丰富；</li>\n<li>Blog，关注该领域大牛的博客。</li>\n</ul>\n<p>当自我学习到一定程度时，你可能希望和这些大牛进行“有深度”的交流，但是如何去找到这些大牛呢？首先google一下该领域大牛，在facebook、twitter、Boogle（maybe sina）中找到，由他们可以带你进入一个Group，此时，可以说你加入了这个技术圈（更重要的是去研究、交流，而不是止于形式）。</p>\n<p>4.一天可以学会的实用技能<br>如果给你一天时间，你能学会哪些实用的计算机相关技能？这是我在Quora看到的一个问题，下面有很多的回复。我曾经尝试去做过一些，比如学会正则表达式、写一个网络爬虫，解析基本数据等等，可能你会觉得某些技术难，不好下手，不妨试试这种带有挑战意义的方式。尝试后你可能就会发现学习技术并不是不难，只要你有兴趣去发现、去尝试、去研究！</p>\n<p>5.我们不只是会写代码的程序员<br>如果说掌握一门技术是我们的首要任务的话，那么，我认为技术人员要学会一些更重要的东西，不是技术，而是业务、交流与协作。如果立志要成为一名架构师，后面的是我们更需要学习的东西。架构师需要根据业务需求和扩展，能够了解其未来的发展趋势，理解架构系统所涉及的方方面面，才能设计出更可靠安全的的系统架构。所以我们不要把程序员定位为写代码一类人，我们是发现新技术、创造新产品的superman。</p>\n<p>不知不觉已经写了好多内容，还有很多想和大家分享的东西没有讲到，限于篇幅我就不展开讨论了，欢迎大家随时和我进行分享交流，共同进步成为大牛！</p>\n","site":{"data":{}},"excerpt":"","more":"<p>看到这篇以前的文章，回忆一下，2014年7月毕业开始了北漂的”码农”的生活，有幸被公司邀请写一篇文章，随写之。</p>\n<p>非常感谢@内部沟通部发来的约稿邮件，让我聊一聊程序员的那些事儿。作为一名程序猿，有很多有关技术方面的ideas可以拿来和大家进行分享和探讨。我是一个特别爱折腾的人，对于新技术、新产品都会去尝试一下，所以在技术学习、工作、程序开发方面，我有一些想法，和大家交流一下。</p>\n<p>1.做自己<code>喜欢并且擅长</code>的事情<br>这句话是我在一位技术大牛身上学到的，我们每做一个件事情都是有驱动的，如果你做了自己喜欢并且擅长的事情，那很可能取得你想要的成功。在雏鹰培训的时候，吴正老师给我们上的培训叫发现自己的优势，我觉得很有意义，可以找到自己优势和不足，让我们在擅长的方面找到自己喜欢去做的，并且将它做到极致，那也是一种成功，一种geek精神的体现吧。</p>\n<p>2.做一个自己的技术博客<br>作为一个技术人，搭建一个属于自己的博客是很有意思和意义的事情。在搭建博客的过程中你可以学习到一些技术知识，比如域名解析、博客主机配置、编写博客程序等等，自由度非常大，动手去实现收获也是非常巨大的。当自己对某些技术有独到的见解可以通过博客的形式分享出去和别人交流。在做博客的过程中，我也会去关注圈内大牛的技术博客（酷壳等）、百度，阿里等官方博客，RSS订阅一些博客，随时学习和接触领域中的新知识。</p>\n<p>3.怎样迅速加入一个技术圈<br>如果在某一领域是技术“小白”，怎么才能够迅速加入呢。你可以从以下两个方面入手。一是是自我学习，二是和该领域中的技术牛人交流。<br>自我学习方式我在实践中总结了一下:</p>\n<ul>\n<li>Wiki，了解其介绍、使用、API、文档等等；</li>\n<li>Presentation，学习大牛的技术分享，特别推荐slideshare.net；</li>\n<li>Paper，技术领域都有很多的paper可以去深入学习，比如在大数据领域中google的“前三后三”6篇经典论文；</li>\n<li>Video，一提这个可能会想到网易公开课等视频网站，但我会更加推荐你去Youtube或者confreaks.com，特别强大和丰富；</li>\n<li>Blog，关注该领域大牛的博客。</li>\n</ul>\n<p>当自我学习到一定程度时，你可能希望和这些大牛进行“有深度”的交流，但是如何去找到这些大牛呢？首先google一下该领域大牛，在facebook、twitter、Boogle（maybe sina）中找到，由他们可以带你进入一个Group，此时，可以说你加入了这个技术圈（更重要的是去研究、交流，而不是止于形式）。</p>\n<p>4.一天可以学会的实用技能<br>如果给你一天时间，你能学会哪些实用的计算机相关技能？这是我在Quora看到的一个问题，下面有很多的回复。我曾经尝试去做过一些，比如学会正则表达式、写一个网络爬虫，解析基本数据等等，可能你会觉得某些技术难，不好下手，不妨试试这种带有挑战意义的方式。尝试后你可能就会发现学习技术并不是不难，只要你有兴趣去发现、去尝试、去研究！</p>\n<p>5.我们不只是会写代码的程序员<br>如果说掌握一门技术是我们的首要任务的话，那么，我认为技术人员要学会一些更重要的东西，不是技术，而是业务、交流与协作。如果立志要成为一名架构师，后面的是我们更需要学习的东西。架构师需要根据业务需求和扩展，能够了解其未来的发展趋势，理解架构系统所涉及的方方面面，才能设计出更可靠安全的的系统架构。所以我们不要把程序员定位为写代码一类人，我们是发现新技术、创造新产品的superman。</p>\n<p>不知不觉已经写了好多内容，还有很多想和大家分享的东西没有讲到，限于篇幅我就不展开讨论了，欢迎大家随时和我进行分享交流，共同进步成为大牛！</p>\n"},{"title":"elasticsearch_tec_book(update) v1.01","author":"Atlas","author_id":"Atlas","date":"2017-09-26T02:47:00.000Z","language":null,"_content":"\n# elasticsearch技术手册 v1.01\n\n[toc]\n\n## 1. 基础\n本手册内容是基于`elasticsearch5+`版本。准确的说是5.0.1版本。\n### 1.概念\n集群（cluster）、节点（node）、索引（index）、分片（shards）、副本（replicas）；\nterm、tf-idf、boost等\n### 2. Elasticsearch features\n\n1. [Based in lucene, write in java]()\n2. [Realtime analytics]()\n3. [Full Text search engine]()\n4. [Distributed, easy to scale]()\n5. [High availability]()\n6. [Document oriented(json)]()\n7. [Schema free]()\n8. [Restful API, json over http]()\n9. [Open source:Apache License 6.0 (ES:5.x)]()\n10. [Plugins & Community support]()\n\n### 3. elasticsearch do what on lucene?\nElasticsearch 构建在lucene之上，提供json方式的rest api进行交互；\n\n1. Elasticsearch在lucene之上提供一个完整的分布式系统；\n2. Elasticsearch提供了一个分布式的抽象的数据结构；\n3. 提供了一些特性，例如线程池、队列、node/cluster监控api、数据监控api、以及集群管理等等；\n\n## 2. 生产环境\n### 1. 监控（Monitoring）\n对于已经初步部署完成的elasticsearch集群来说，接下来的集群监控就变的更重要了。集群的重要参数，比如集群状态，分片状态等是集群健康的体现。elasticsearch提供了很对的现成api供我们管理和监控cluster。\n其中，(1)marvel是一个很容易监控elasticsearch的工具。它可以整合大量的统计数据通过kibana。\n(2) cluster health\n### 2. 生产环境部署（Production Deploying）\n生产环境的部署有很多考究的地方，接下来我从以下三个方面来说。\n#### 运维部署考虑（硬件以及部署策略）\n（1）memory，elasticsearch是比较吃内存的，尤其像排序、聚合操作，所以保证足够的heap内存是重要的。如果对内存不够的话，会交换到系统的缓存，由于lucene的数据结构是disk-based的格式，这势必会影响搜索的性能；一般建议使用16g-64gRAM的机器。如果大于64g，则会出现[另外的一些问题](https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html)\n（2）cpus,和内存相比，搜索对cpu的要求不是特别高，一般使用多核cpu就行，比如2-8核的；\n（3）disk，硬盘的性能对搜索集群非常重要，磁盘的性能直接影响索引的构建和读写操作，很多时候是搜索的一个瓶颈。ssd硬盘是目前最好的方式，但是由于其价钱看看阿里云，是同样的`喜人`，所以看业务需要，力所能及吧，我们目前使用的是高性能磁盘（high-performance server disks, 15k RPM drives），可以满足业务需求。\n（4）network，一个快速稳定的网络环境对分布式系统非常的重要，低延迟、高带宽有利于节点间的交互以及分片的拷贝和恢复\n（5）其他，尽量避免使用小配置机器组合一个超大的集群，这样管理起来就是一个大坑\n#### 优化配置参数\n(1)Java Virtual Machine\n(2)Transport Client Versus Node Client\nvs:\nTransport Client 可以解耦你的应用和搜索服务，应用可以很快的创建和销毁连接；\nNode Client 可以和搜索服务保持一个持久连接，可以查看搜索的结构信息；\n(3)Important Configuration Changes\nelasticsearch配置文件有非常好的默认设置，都是在实际的工作环境中实践过的。当遇到性能问题的时候，更多的是需要考虑数据存储布局和添加更多的node（elasticsearch文档中特意说明了配置文件的重要性，不让随便更改，大多数情况下是正确的）。\n\n- name\n\n```\n1. Assign Names\ncluster.name: elasticsearch_production\nnode.name: elasticsearch_005_data\n\n2. Paths\npath.data: /path/to/data1,/path/to/data2 \n\n# Path to log files:\npath.logs: /path/to/logs\n\n# Path to where plugins are installed:\npath.plugins: /path/to/plugins\n\n```\n\n- minimum_master_nodes，这个参数是在配置文件中比较重要的一个，如果配置不对的话，会发生split brains（俗称“脑裂”），就是说会存在多个master节点，继而可能发生丢失data现象。这个参数的计算公式：(number of master-eligible nodes / 2) + 1，举例说明：\n\n\t- 假如你有10个node（可存储数据，可成为master），则设置为6；\n\t- 假如你有三个可选为master的节点，100+个数据节点，则设置为2；\n\t- 假如你有2个常规节点，这个值设置为2，但是如果丢失一个则会造成集群不可用，如果设置为1，则不能保证脑裂的不存在，最好的方法是保证最小的节点数为3.\n\n```\ndiscovery.zen.minimum_master_nodes: 2\n```\n因为elasticsearch是自适应的，节点随时添加或者下线，不过还好，有api我们可以实时调整这个参数，\n\n```\nPUT /_cluster/settings\n{\n    \"persistent\" : {\n        \"discovery.zen.minimum_master_nodes\" : 2\n    }\n}\n```\n\n- Recovery Settings\n恢复策略对elasticsearch是必不可少的，举例来说，假如现在集群（10 nodes）集体下线进行维修升级，当重新启动的时候，先启动了5 nodes，此时集群发现有5个node启动了，会执行shard的备份和交换，直到达到分片平衡，此时如果另外5 nodes加入到集群中，会发生什么呢？cluster会继续rebalance，新加入的节点发现数据集群中已经有了，首先删除本地数据，通知集群发动rebalance，平衡各个shards，这整个过程中shard会发生copy、sweap、delete等操作，耗费好多资源和时间，对一个大集群来说，耗费的更多，不可忍受。所以，elasticsearch有三个参数可以配置这些。\n\n```\ngateway.recover_after_nodes: 8   // 集群中恢复的节点数，就是说当改集群启动了8个几点，才尽兴rebalance\n\n// 这两项说明，本集群有10的node，当10个nodes都启动或者启动了8个node且超过5分钟后就会发起rebalance\ngateway.expected_nodes: 10\ngateway.recover_after_time: 5m\n```\n这些策略只和`整个cluster重启`时生效。\n\n- Prefer Unicast over Multicast\nelasticsearch建议使用单播的方式，虽然依然提供了多播的方式，但存在找不到master等尴尬的问题，不建议使用。\n\n```\ndiscovery.zen.ping.unicast.hosts: [\"host1\", \"host2:port\"]\n```\n（4）不要轻易修改的参数\n\n1. Garbage Collector\nelasticsearch中默认采用Concurrent-Mark and Sweep (CMS)的gc回收器；\n\n2. Threadpools\nelasticsearch中设置线程池非常合理的，如果没有特别情况下不要修改这个值\n\n```\nSearch gets a larger threadpool, and is configured to int((# of cores * 3) / 2) + 1\n```\n(5)Heap: Sizing and Swapping\n(6)File Descriptors and MMap\nelasticsearch混合使用nioFS和MMapFS。\n\n### 3. 插件\n1. 使用[head](https://github.com/mobz/elasticsearch-head)插件来查看索引数据\n2. 使用[kopf](https://github.com/lmenezes/elasticsearch-kopf)来备份集群节点\n3. 使用[bigdesk](https://github.com/lukas-vlcek/bigdesk)查看集群性能\n4. [elasticsearch-sql](https://github.com/NLPchina/elasticsearch-sql) 通过sql进行聚合检索, 可以将sql语句翻译成ES的JSON检索语句\n5. 中文分词（ik、pinying）\n6. [Curator](https://www.elastic.co/guide/en/elasticsearch/client/curator/current/about.html)\n\n## 3. 参数配置\n暂空（后补）\n\n### java优化配置\n(1)Heap不要超过系统可用内存的一半，并且不要超过32GB。\n\n(2) cluster集群jvm调优\n当时我们配置ES的JVM(Xms=Xmx=8G)的垃圾回收器主要是CMS,具体配置如下:\n\n```\n# reduce the per-thread stack size\nJAVA_OPTS=\"$JAVA_OPTS -Xss256k\"\n\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UseParNewGC\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UseConcMarkSweepGC\"\n\nJAVA_OPTS=\"$JAVA_OPTS -XX:CMSInitiatingOccupancyFraction=75\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UseCMSInitiatingOccupancyOnly\"\n```\n这块在官方说明中，特意强调了不建议替换java垃圾回收器，[官方并不推荐使用G1](https://www.elastic.co/guide/en/elasticsearch/guide/current/_don_8217_t_touch_these_settings.html#_garbage_collector)。\n\n[其他博文](https://www.geekhub.cn/a/1256.html)中有试过使用其他垃圾回收器。他的G1的具体配置如下:\n\n```\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UseG1GC \"\n#init_globals()末尾打印日志\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintFlagsFinal \"\n#打印gc引用\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintReferenceGC \"\n#输出虚拟机中GC的详细情况.\nJAVA_OPTS=\"$JAVA_OPTS -verbose:gc \"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintGCDetails \"\n#Enables printing of time stamps at every GC. By default, this option is disabled.\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintGCTimeStamps \"\n#Enables printing of information about adaptive generation sizing. By default, this option is disabled.\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintAdaptiveSizePolicy \"\n# unlocks diagnostic JVM options\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UnlockDiagnosticVMOptions \"\n#to measure where the time is spent\nJAVA_OPTS=\"$JAVA_OPTS -XX:+G1SummarizeConcMark \"\n#设置触发标记周期的 Java 堆占用率阈值。默认占用率是整个 Java 堆的 45%。\n#JAVA_OPTS=\"$JAVA_OPTS -XX:InitiatingHeapOccupancyPercent=45 \"\n```\n\n(3) elastic 开启jmx 监控\n有时候监控是必不可少的，所以在有条件的时候可以加上jmx监控\n\n```\n/usr/local/elastic/bin/elasticsearch.in.sh\nJMX_PORT=9305\nJAVA_OPTS=\"$JAVA_OPTS -Dcom.sun.management.jmxremote.port=$JMX_PORT\"\nJAVA_OPTS=\"$JAVA_OPTS -Dcom.sun.management.jmxremote.ssl=false\"\nJAVA_OPTS=\"$JAVA_OPTS -Dcom.sun.management.jmxremote.authenticate=false\"\nJAVA_OPTS=\"$JAVA_OPTS -Djava.rmi.server.hostname=xx.xx.xx..xx\"\n```\n\n### elasticsearch.yml\n这个是最重要的配置，只有在你明白之后在修改，之后我在单独写一篇文章介绍目前elasticsearch默认参数是如何影响系统的。\n\n目前配置包括以下几个部分：\n（1）cluster\n（2）节点node\n（3）log／data路径\n（4）内存\n（5）网络\n（5）发现Discovery\n（6）Gateway\n（7）其他变量\n\n```\n# ======================== Elasticsearch Configuration =========================\n#\n# NOTE: Elasticsearch comes with reasonable defaults for most settings.\n#       Before you set out to tweak and tune the configuration, make sure you\n#       understand what are you trying to accomplish and the consequences.\n#\n# The primary way of configuring a node is via this file. This template lists\n# the most important settings you may want to configure for a production cluster.\n#\n# Please see the documentation for further information on configuration options:\n# <https://www.elastic.co/guide/en/elasticsearch/reference/5.0/settings.html>\n#\n# ---------------------------------- Cluster -----------------------------------\n#\n# Use a descriptive name for your cluster:\n#\ncluster.name: elastic-pro\n#\n# ------------------------------------ Node ------------------------------------\n#\n# Use a descriptive name for the node:\n#\nnode.name: node-0\n#\n# Add custom attributes to the node:\n#\nnode.attr.rack: r1\n#\n# ----------------------------------- Paths ------------------------------------\n#\n# Path to directory where to store the data (separate multiple locations by comma):\n#\npath.data: /apps/home/worker/zhangxiaolong/data/index0\n#\n# Path to log files:\n#\npath.logs: /apps/home/worker/zhangxiaolong/data/log0\n#\n# ----------------------------------- Memory -----------------------------------\n#\n# Lock the memory on startup:\n#\nbootstrap.memory_lock: true\n#\n# Make sure that the heap size is set to about half the memory available\n# on the system and that the owner of the process is allowed to use this\n# limit.\n#\n# Elasticsearch performs poorly when the system is swapping the memory.\n#\n# ---------------------------------- Network -----------------------------------\n#\n# Set the bind address to a specific IP (IPv4 or IPv6):\n#\nnetwork.host: 172.16.7.1\n#\n# Set a custom port for HTTP:\n#\nhttp.port: 9201\n#\n# For more information, see the documentation at:\n# <https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-network.html>\n#\n# --------------------------------- Discovery ----------------------------------\n#\n# Pass an initial list of hosts to perform discovery when new node is started:\n#The default list of hosts is [\"127.0.0.1\", \"[::1]\"]\n#\ndiscovery.zen.ping.unicast.hosts: [\"172.16.7.1:9300\"]\n#\n# Prevent the \"split brain\" by configuring the majority of nodes (total number of nodes / 2 + 1):\n#\ndiscovery.zen.minimum_master_nodes: 2\n#\n# For more information, see the documentation at:\n# <https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-discovery-zen.html>\n#\n# ---------------------------------- Gateway -----------------------------------\n#\n# Block initial recovery after a full cluster restart until N nodes are started:\n#\ngateway.recover_after_nodes: 2\n#\n# For more information, see the documentation at:\n# <https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-gateway.html>\n#\n# ---------------------------------- Various -----------------------------------\n#\n# Require explicit names when deleting indices:\n#\n#action.destructive_requires_name: true\n```\n\n### 其他\n（1）线程池设置成内核数，比如八核机器就设置成8，很多阻塞的操作都是Lucene来操作的，比如硬盘读写。搜索的线程设置可以设置成内核数的三倍\n（2）内存交换\n这个对于性能影响是致命的，可以使用命令sudo swapoff -a来暂时关闭，永久关闭需要编辑文件/etc/fstab，也可以在配置文件中添加配置bootstrap.mlockall: true，这样jvm可以锁定这些内存，避免被交换到物理存储介质\n（3）其他\n\n- 如果你不需要近实时功能，则设置index的刷新时间；\n- 如果在进行一个大bulk导入，可以优先考虑设置副本数为0；\n- 如果在index中的doc你没有一个自然增长的id，可以使用Elasticsearch’s 的自动id做标示，如果有自己的id，尽量设计对lucene友好的id；\n\n## 4. Rolling Restarts & 备份数据 & 备份恢复 \n### Rolling Restarts\n一般下线一个node（升级、维修等），elasticsearch会进行rebalance操作，如果你是真正的下线一个node，这个操作是十分正确的，但是你知道这台node会之后重新加入到cluster中，则rebalance操作不恰当了，当shard比较大或者多的时候会严重耗费系统资源。\n\n那我们正确的操作是什么？\n\n``` shell\n1. 查看集群设置\ncurl -XGET http://10.10.160.129:9200/_cluster/settings\n\n2. 如果可能的话，停止正在索引的数据；\n\n3. 停止分片同步，阻止elasticsearch进行rebalance操作\nPUT /_cluster/settings\n{\n    \"transient\" : {\n        \"cluster.routing.allocation.enable\" : \"none\"\n    }\n}\n\n4.关闭单个node\n\n5.维护或者升级节点node\n\n6.重启node，确认加入cluster\n\n7.重新打开分片同步\nPUT /_cluster/settings\n{\n    \"transient\" : {\n        \"cluster.routing.allocation.enable\" : \"all\"\n    }\n}\n\n8.针对需要的node重复执行3-7操作\n\n9.到这里就重新恢复了cluster；\n```\n\n### 备份数据\n\n``` shell\n1. 先导入一些数据进行备份\ncurl -XPOST 'http://192.168.56.11:9200/bank/account/_bulk?pretty' --data-binary @accounts.json\ncurl -XPOST 'http://192.168.56.11:9200/shakespeare/_bulk?pretty' --data-binary @shakespeare.json\ncurl -XPOST 'http://192.168.56.11:9200/_bulk?pretty' --data-binary @logs.jsonl\n\n2. 使用API创建一个镜像仓库\ncurl -XPOST http://192.168.56.11:9200/_snapshot/my_backup -d '\n{\n    \"type\": \"fs\", \n    \"settings\": { \n        \"location\": \"/data/mount\"\n        \"compress\":  true \n    }\n}'\n## 解释：\n镜像仓库的名称：my_backup\n镜像仓库的类型：fs。还支持curl，hdfs等。\n镜像仓库的位置：/data/mount 。这个位置必须在配置文件中定义。\n是否启用压缩：compres：true 表示启用压缩。\n\n3. 备份前检查配置\n必须确定备份使用的目录在配置文件中声明了，否则会爆如下错误\n{\n  \"error\": {\n    \"root_cause\": [\n      {\n        \"type\": \"repository_exception\",\n        \"reason\": \"[test-bakcup] failed to create repository\"\n      }\n    ],\n    \"type\": \"repository_exception\",\n    \"reason\": \"[test-bakcup] failed to create repository\",\n    \"caused_by\": {\n      \"type\": \"creation_exception\",\n      \"reason\": \"Guice creation errors:\\n\\n1) Error injecting constructor, RepositoryException[[test-bakcup] location [/data/mount] doesn't match any of the locations specified by path.repo because this setting is empty]\\n  at org.elasticsearch.repositories.fs.FsRepository.<init>(Unknown Source)\\n  while locating org.elasticsearch.repositories.fs.FsRepository\\n  while locating org.elasticsearch.repositories.Repository\\n\\n1 error\",\n      \"caused_by\": {\n        \"type\": \"repository_exception\",\n        \"reason\": \"[test-bakcup] location [/data/mount] doesn't match any of the locations specified by path.repo because this setting is empty\"\n      }\n    }\n  },\n  \"status\": 500\n}\n\n4. 开始创建一个快照\n##在后头创建一个快照\ncurl -XPUT  http://192.168.56.20:9200/_snapshot/my_backup/snapshot_1 \n##也可以在前台运行。\ncurl -XPUT  http://192.168.56.11:9200/_snapshot/my_backup/snapshot_1?wait_for_completion=true\n##上面的参数会在my_backup仓库里创建一个snapshot_1 的快照。\n\n5. 可以选择相应的索引进行备份\ncurl -XPUT  http://192.168.56.20:9200/_snapshot/my_backup/snapshot_2 -d '\n{\n    \"indices\": \"bank,logstash-2015.05.18\"\n}'\n## 解释：\n创建一个snapshot_2的快照，只备份bank,logstash-2015.05.18这两个索引。\n\n6. 查看备份状态\n整个备份过程中，可以通过如下命令查看备份进度\n\ncurl -XGET http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_status\n主要由如下几种状态：\na. INITIALIZING 集群状态检查，检查当前集群是否可以做快照，通常这个过程会非常快\nb. STARTED 正在转移数据到仓库\nc. FINALIZING 数据转移完成，正在转移元信息\nd. DONE　完成\ne. FAILED 备份失败\n\n7. 取消备份\ncurl -XDELETE http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812\n\n8. 获取所有快照信息。\ncurl -XGET http://192.168.56.20:9200/_snapshot/my_backup/_all |python -mjson.tool\n##解释\n查看my_backup仓库下的所有快照。\n\n9. 手动删除快照\ncurl -XDELETE http://192.168.56.20:9200/_snapshot/my_backup/snapshot_2\n## 解释\n删除my_backup仓库下的snapshot_2的快照。\n\n```\n\n### 备份恢复\n\n``` json\n1. 恢复备份\ncurl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore\n同备份一样，也可以设置wait_for_completion=true等待恢复结果\n\ncurl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore?wait_for_completion=true\n默认情况下，是恢复所有的索引，我们也可以设置一些参数来指定恢复的索引，以及重命令恢复的索引，这样可以避免覆盖原有的数据.\n\ncurl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore\n{\n    \"indices\": \"index_1\",\n    \"rename_pattern\": \"index_(.+)\",\n    \"rename_replacement\": \"restored_index_$1\"\n}\n上面的indices, 表示只恢复索引’index_1’\nrename_pattern: 表示重命名索引以’index_’开头的索引.\nrename_replacement: 表示将所有的索引重命名为’restored_index_xxx’.如index_1会被重命名为restored_index_1.\n\n2. 查看所有索引的恢复进度\ncurl -XGET http://192.168.0.1:9200/_recovery/\n\n3. 查看索引restored_index_1的恢复进度\ncurl -XGET http://192.168.0.1:9200/_recovery/restored_index_1\n\n4. 取消恢复\n只需要删除索引，即可取消恢复\ncurl -XDELETE http://192.168.0.1:9200/restored_index_1\n```\n\n## 5. 性能优化\n在讲性能优化之前，首先要知道：\n\n\t过早的优化是万恶之源 Premature optimization is the root of all evil.\n\t\t\t\t\t\t\t\t\t\t                —— Donald Knuth\n\n`优化总是发生在目前的情况下不能满足当前的需求，其他我想不出什么理由去优化它。`\n\n`优化很多时候和业务是紧密关联的，优化业务可能比优化程序效率更高、成本更低！`\n\n### 索引性能优化\n索引性能（Index Performance），我们这样定义它，索引的速度是否提高，可以无缝的提供近实时的功能。\n什么时候会发生索引慢呢？\n（1）你读的慢（doc from db，file，inputstream等等）\n（2）你处理的慢（中文下的分词等）\n（3）你写的慢（还是老式的机械盘？！ 高性能的盘或者ssd）\n\n还有就是针对不同场景选择的判断，如果你索引的文件非常大，数量多，那应该选择elasticsearch提供的bulk接口，在create doc速度能跟上的时候，bulk 是可以提高速度的。\n\n### 查询性能优化\n查询性能（Query Perofrmance），说起来比索引更麻烦一些，面对的场景也更多一些；\n\n面对海量数据以及不同的集群，针对业务需求去查询往往会很慢，有什么策略可以搞定这种情况？有，那就是`routing`[Routing a Document to a Shard](https://www.elastic.co/guide/en/elasticsearch/guide/current/routing-value.html)、[_routing field](https://www.elastic.co/guide/en/elasticsearch/reference/5.1/mapping-routing-field.html).\n\n查询策略，分别查询vs合并查询？索引越来越大，单个 shard 也很巨大，查询速度也越来越慢。这时候，是选择分索引还是更多的shards？在实践过程中，更多的 shards 会带来额外的索引压力，即 IO 压力。我们选择了分索引。比如按照每个大分类一个索引，或者主要的大城市一个索引。然后将他们进行合并查询。\n\n索引越来越大，资源使用也越来越多。若是要进行更细的集群分配，大索引使用的资源成倍增加。有什么办法能减小索引？\n根据具体业务需求，减少某些大的索引，这是一个很好的办法，这样这个集群各方面占用的资源会有一定程度的下降，当让你要说这些少的索引怎么办，这些索引可以放在单独的集群中。\n\n## 应用性能优化 - [from youzan](http://tech.youzan.com/search-engine1/)\n一、使用应用级队列防止雪崩\nES一个问题是在高峰期时候极容易发生雪崩. ES有健全的线程池系统来保证并发与稳定性问题. 但是在流量突变的情况下(比如双十一秒杀)还是很容易发生瘫痪的现象, 主要的原因如下:\n\nES几乎为每类操作配置一个线程池; 只能保证每个线程池的资源使用时合理的, 当2个以上的线程池竞争资源时容易造成资源响应不过来.\n\nES没有考虑网络负载导致稳定的问题.\n\n在AS里我们实现了面向请求的全局队列来保证稳定性. 它主要做了3件事情.\n![](http://ww1.sinaimg.cn/mw690/b7ba225dly1fjx0kmbrr6j20fu0le3zi.jpg)\n\n1. 根据业务把请求分成一个个slide, 每个slide对应一个队列. 默认一个应用就是一个slide, 一个应用也可以区分不同的slide, 这样可以保护一个应用内重要的查询.\n2. 每个队列配置一个队列长度, 默认为50.\n3. 每个队列计算这个队列的平均响应时间. 当队列平均响应时间超过200ms, 停止工作1s, 如果请求溢出就写入溢出日志留数据恢复使用. 如果连续10次队列平均响应时间超过500ms就报警, 以便工程师第一时间处理.\n\n二、自动降级\n应用级队列解决雪崩问题有点粗暴, 如果一个应用本身查询就非常慢, 很容易让一个应用持续超时很久. 我们根据搜索引擎的特点编写了自动降级功能.\n\n比如商品搜索的例子, 商品搜索最基本的功能是布尔查询, 但是还需要按照相关性分数和质量度排序等功能, 甚至还有个性化需求. 完成简单的布尔查询, ES使用bitsets操作就可以做到, 但是如果如果需要相关性分, 就必须使用倒排索引, 并有大量CPU消耗来计算分数. ES的bitsets比倒排索引快50倍左右.\n\n对于有降级方案的slide, AS在队列响应过慢时候直接使用降级query代替正常query. 这种方法让我们在不扩容的情况下成功度过了双十一的流量陡增.\n\n三、善用filtered query\n理解lucence filter工作原理对于写出高性能查询语句至关重要. 许多搜索性能优化都和filter的使用有关. filter使用bitsets进行布尔运算, quey使用倒排索引进行计算, 这是filter比query快的原因. bitsets的优势主要体现在: \n\n1. bitsetcache在内存里面, 永不消失(除非被LRU). \n2. bitsets利用CPU原生支持的位运算操作, 比倒排索引快个数量级 \n3. 多个bitsets的与运算也是非常的快(一个64位CPU可以同时计算64个DOC的与运算) \n4. bitsets 在内存的存储是独立于query的, 有很强的复用性 \n5. 如果一个bitset片段全是0, 计算会自动跳过这些片段, 让bitsets在数据稀疏情况下同样表现优于倒排索引.\n\n举个例子:\n``` java \nquery:bool:  \n    tag:'mac'\n    region:'beijing'\n    title: \"apple\"\n```\n\nlucence处理这个query的方式是在倒排索引中寻找这三个term的倒排链 ,并使用跳指针技术求交, 在运算过程中需要对每个doc进行算分. 实际上tag和region对于算分并没有作用, 他们充当是过滤器的作用.\n\n这就是过滤器使用场景, 它只存储存在和不存在两种状态. 如果我们把tag和region使用bitsets进行存储, 这样这两个过滤器可以一直都被缓存在内存里面, 这样会快很多. 另外tag和region之间的求交非常迅速, 因为64位机器可以时间一个CPU周期同时处理64个doc的位运算.\n\n一个lucence金科玉律是: 能用filter就用filter, 除非必须使用query(当且仅当你需要算分的时候).\n正确的写法为:\n\n``` java\nquery:  \n    filtered: \n        query:  \n             title: \"apple\" \n         filter:\n            tag:\"mac\"\n             region:\"beijing\"\n```\n四、其他\n\n1. 线上集群关闭分片自动均衡. 分片的自动均衡主要目的防止更新造成各个分片数据分布不均匀. 但是如果线上一个节点挂掉后, 很容易触发自动均衡, 一时间集群内部的数据移动占用所有带宽. 建议采用闲时定时均衡策略来保证数据的均匀.\n\n2. 尽可能延长refresh时间间隔. 为了确保实时索引es索引刷新时间间隔默认为1秒, 索引刷新会导致查询性能受影响, 在确保业务时效性保证的基础上可以适当延长refresh时间间隔保证查询的性能.\n\n3. 除非有必要把all字段去掉. 索引默认除了索引每个字段外, 还有额外创建一个all的字段, 保存所有文本, 去掉这个字段可以把索引大小降低50%.\n\n4. 创建索引时候, 尽可能把查询比较慢的索引和快的索引物理分离.\n\n##6. 参考（Reference）\n1. [elastic调优参考](http://www.cnblogs.com/guguli/p/5218297.html)\n2. [elastic监控](https://github.com/Wprosdocimo/Elasticsearch-zabbix)\n3. [Mastering Elasticsearch(中文版)](http://udn.yyuap.com/doc/mastering-elasticsearch/chapter-4/41_README.html)\n4. [ELK-权威指南](http://kibana.logstash.es/content/logstash/plugins/input/file.html)\n5. [Elasticsearch 权威指南](http://www.learnes.net/index.html)\n6. [elasticsearch 生产环境配置](http://www.biglittleant.cn/2016/12/01/elastic-study1/)\n7. [有赞搜索引擎实践(工程篇)](http://tech.youzan.com/search-engine1/)\n\n\n**[更新于2017-05-22 - v1.0 ]\n[更新于2017-09-26 - v1.01]**\n\n(完)\n\n","source":"_posts/elasticsearch_tec_book_v1.01.md","raw":"---\ntitle: elasticsearch_tec_book(update) v1.01\nauthor: Atlas\nauthor_id: Atlas\ntags:\n  - search\ncategories:\n  - search\ndate: 2017-09-26 10:47:00\nlanguage:\n---\n\n# elasticsearch技术手册 v1.01\n\n[toc]\n\n## 1. 基础\n本手册内容是基于`elasticsearch5+`版本。准确的说是5.0.1版本。\n### 1.概念\n集群（cluster）、节点（node）、索引（index）、分片（shards）、副本（replicas）；\nterm、tf-idf、boost等\n### 2. Elasticsearch features\n\n1. [Based in lucene, write in java]()\n2. [Realtime analytics]()\n3. [Full Text search engine]()\n4. [Distributed, easy to scale]()\n5. [High availability]()\n6. [Document oriented(json)]()\n7. [Schema free]()\n8. [Restful API, json over http]()\n9. [Open source:Apache License 6.0 (ES:5.x)]()\n10. [Plugins & Community support]()\n\n### 3. elasticsearch do what on lucene?\nElasticsearch 构建在lucene之上，提供json方式的rest api进行交互；\n\n1. Elasticsearch在lucene之上提供一个完整的分布式系统；\n2. Elasticsearch提供了一个分布式的抽象的数据结构；\n3. 提供了一些特性，例如线程池、队列、node/cluster监控api、数据监控api、以及集群管理等等；\n\n## 2. 生产环境\n### 1. 监控（Monitoring）\n对于已经初步部署完成的elasticsearch集群来说，接下来的集群监控就变的更重要了。集群的重要参数，比如集群状态，分片状态等是集群健康的体现。elasticsearch提供了很对的现成api供我们管理和监控cluster。\n其中，(1)marvel是一个很容易监控elasticsearch的工具。它可以整合大量的统计数据通过kibana。\n(2) cluster health\n### 2. 生产环境部署（Production Deploying）\n生产环境的部署有很多考究的地方，接下来我从以下三个方面来说。\n#### 运维部署考虑（硬件以及部署策略）\n（1）memory，elasticsearch是比较吃内存的，尤其像排序、聚合操作，所以保证足够的heap内存是重要的。如果对内存不够的话，会交换到系统的缓存，由于lucene的数据结构是disk-based的格式，这势必会影响搜索的性能；一般建议使用16g-64gRAM的机器。如果大于64g，则会出现[另外的一些问题](https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html)\n（2）cpus,和内存相比，搜索对cpu的要求不是特别高，一般使用多核cpu就行，比如2-8核的；\n（3）disk，硬盘的性能对搜索集群非常重要，磁盘的性能直接影响索引的构建和读写操作，很多时候是搜索的一个瓶颈。ssd硬盘是目前最好的方式，但是由于其价钱看看阿里云，是同样的`喜人`，所以看业务需要，力所能及吧，我们目前使用的是高性能磁盘（high-performance server disks, 15k RPM drives），可以满足业务需求。\n（4）network，一个快速稳定的网络环境对分布式系统非常的重要，低延迟、高带宽有利于节点间的交互以及分片的拷贝和恢复\n（5）其他，尽量避免使用小配置机器组合一个超大的集群，这样管理起来就是一个大坑\n#### 优化配置参数\n(1)Java Virtual Machine\n(2)Transport Client Versus Node Client\nvs:\nTransport Client 可以解耦你的应用和搜索服务，应用可以很快的创建和销毁连接；\nNode Client 可以和搜索服务保持一个持久连接，可以查看搜索的结构信息；\n(3)Important Configuration Changes\nelasticsearch配置文件有非常好的默认设置，都是在实际的工作环境中实践过的。当遇到性能问题的时候，更多的是需要考虑数据存储布局和添加更多的node（elasticsearch文档中特意说明了配置文件的重要性，不让随便更改，大多数情况下是正确的）。\n\n- name\n\n```\n1. Assign Names\ncluster.name: elasticsearch_production\nnode.name: elasticsearch_005_data\n\n2. Paths\npath.data: /path/to/data1,/path/to/data2 \n\n# Path to log files:\npath.logs: /path/to/logs\n\n# Path to where plugins are installed:\npath.plugins: /path/to/plugins\n\n```\n\n- minimum_master_nodes，这个参数是在配置文件中比较重要的一个，如果配置不对的话，会发生split brains（俗称“脑裂”），就是说会存在多个master节点，继而可能发生丢失data现象。这个参数的计算公式：(number of master-eligible nodes / 2) + 1，举例说明：\n\n\t- 假如你有10个node（可存储数据，可成为master），则设置为6；\n\t- 假如你有三个可选为master的节点，100+个数据节点，则设置为2；\n\t- 假如你有2个常规节点，这个值设置为2，但是如果丢失一个则会造成集群不可用，如果设置为1，则不能保证脑裂的不存在，最好的方法是保证最小的节点数为3.\n\n```\ndiscovery.zen.minimum_master_nodes: 2\n```\n因为elasticsearch是自适应的，节点随时添加或者下线，不过还好，有api我们可以实时调整这个参数，\n\n```\nPUT /_cluster/settings\n{\n    \"persistent\" : {\n        \"discovery.zen.minimum_master_nodes\" : 2\n    }\n}\n```\n\n- Recovery Settings\n恢复策略对elasticsearch是必不可少的，举例来说，假如现在集群（10 nodes）集体下线进行维修升级，当重新启动的时候，先启动了5 nodes，此时集群发现有5个node启动了，会执行shard的备份和交换，直到达到分片平衡，此时如果另外5 nodes加入到集群中，会发生什么呢？cluster会继续rebalance，新加入的节点发现数据集群中已经有了，首先删除本地数据，通知集群发动rebalance，平衡各个shards，这整个过程中shard会发生copy、sweap、delete等操作，耗费好多资源和时间，对一个大集群来说，耗费的更多，不可忍受。所以，elasticsearch有三个参数可以配置这些。\n\n```\ngateway.recover_after_nodes: 8   // 集群中恢复的节点数，就是说当改集群启动了8个几点，才尽兴rebalance\n\n// 这两项说明，本集群有10的node，当10个nodes都启动或者启动了8个node且超过5分钟后就会发起rebalance\ngateway.expected_nodes: 10\ngateway.recover_after_time: 5m\n```\n这些策略只和`整个cluster重启`时生效。\n\n- Prefer Unicast over Multicast\nelasticsearch建议使用单播的方式，虽然依然提供了多播的方式，但存在找不到master等尴尬的问题，不建议使用。\n\n```\ndiscovery.zen.ping.unicast.hosts: [\"host1\", \"host2:port\"]\n```\n（4）不要轻易修改的参数\n\n1. Garbage Collector\nelasticsearch中默认采用Concurrent-Mark and Sweep (CMS)的gc回收器；\n\n2. Threadpools\nelasticsearch中设置线程池非常合理的，如果没有特别情况下不要修改这个值\n\n```\nSearch gets a larger threadpool, and is configured to int((# of cores * 3) / 2) + 1\n```\n(5)Heap: Sizing and Swapping\n(6)File Descriptors and MMap\nelasticsearch混合使用nioFS和MMapFS。\n\n### 3. 插件\n1. 使用[head](https://github.com/mobz/elasticsearch-head)插件来查看索引数据\n2. 使用[kopf](https://github.com/lmenezes/elasticsearch-kopf)来备份集群节点\n3. 使用[bigdesk](https://github.com/lukas-vlcek/bigdesk)查看集群性能\n4. [elasticsearch-sql](https://github.com/NLPchina/elasticsearch-sql) 通过sql进行聚合检索, 可以将sql语句翻译成ES的JSON检索语句\n5. 中文分词（ik、pinying）\n6. [Curator](https://www.elastic.co/guide/en/elasticsearch/client/curator/current/about.html)\n\n## 3. 参数配置\n暂空（后补）\n\n### java优化配置\n(1)Heap不要超过系统可用内存的一半，并且不要超过32GB。\n\n(2) cluster集群jvm调优\n当时我们配置ES的JVM(Xms=Xmx=8G)的垃圾回收器主要是CMS,具体配置如下:\n\n```\n# reduce the per-thread stack size\nJAVA_OPTS=\"$JAVA_OPTS -Xss256k\"\n\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UseParNewGC\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UseConcMarkSweepGC\"\n\nJAVA_OPTS=\"$JAVA_OPTS -XX:CMSInitiatingOccupancyFraction=75\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UseCMSInitiatingOccupancyOnly\"\n```\n这块在官方说明中，特意强调了不建议替换java垃圾回收器，[官方并不推荐使用G1](https://www.elastic.co/guide/en/elasticsearch/guide/current/_don_8217_t_touch_these_settings.html#_garbage_collector)。\n\n[其他博文](https://www.geekhub.cn/a/1256.html)中有试过使用其他垃圾回收器。他的G1的具体配置如下:\n\n```\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UseG1GC \"\n#init_globals()末尾打印日志\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintFlagsFinal \"\n#打印gc引用\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintReferenceGC \"\n#输出虚拟机中GC的详细情况.\nJAVA_OPTS=\"$JAVA_OPTS -verbose:gc \"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintGCDetails \"\n#Enables printing of time stamps at every GC. By default, this option is disabled.\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintGCTimeStamps \"\n#Enables printing of information about adaptive generation sizing. By default, this option is disabled.\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintAdaptiveSizePolicy \"\n# unlocks diagnostic JVM options\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UnlockDiagnosticVMOptions \"\n#to measure where the time is spent\nJAVA_OPTS=\"$JAVA_OPTS -XX:+G1SummarizeConcMark \"\n#设置触发标记周期的 Java 堆占用率阈值。默认占用率是整个 Java 堆的 45%。\n#JAVA_OPTS=\"$JAVA_OPTS -XX:InitiatingHeapOccupancyPercent=45 \"\n```\n\n(3) elastic 开启jmx 监控\n有时候监控是必不可少的，所以在有条件的时候可以加上jmx监控\n\n```\n/usr/local/elastic/bin/elasticsearch.in.sh\nJMX_PORT=9305\nJAVA_OPTS=\"$JAVA_OPTS -Dcom.sun.management.jmxremote.port=$JMX_PORT\"\nJAVA_OPTS=\"$JAVA_OPTS -Dcom.sun.management.jmxremote.ssl=false\"\nJAVA_OPTS=\"$JAVA_OPTS -Dcom.sun.management.jmxremote.authenticate=false\"\nJAVA_OPTS=\"$JAVA_OPTS -Djava.rmi.server.hostname=xx.xx.xx..xx\"\n```\n\n### elasticsearch.yml\n这个是最重要的配置，只有在你明白之后在修改，之后我在单独写一篇文章介绍目前elasticsearch默认参数是如何影响系统的。\n\n目前配置包括以下几个部分：\n（1）cluster\n（2）节点node\n（3）log／data路径\n（4）内存\n（5）网络\n（5）发现Discovery\n（6）Gateway\n（7）其他变量\n\n```\n# ======================== Elasticsearch Configuration =========================\n#\n# NOTE: Elasticsearch comes with reasonable defaults for most settings.\n#       Before you set out to tweak and tune the configuration, make sure you\n#       understand what are you trying to accomplish and the consequences.\n#\n# The primary way of configuring a node is via this file. This template lists\n# the most important settings you may want to configure for a production cluster.\n#\n# Please see the documentation for further information on configuration options:\n# <https://www.elastic.co/guide/en/elasticsearch/reference/5.0/settings.html>\n#\n# ---------------------------------- Cluster -----------------------------------\n#\n# Use a descriptive name for your cluster:\n#\ncluster.name: elastic-pro\n#\n# ------------------------------------ Node ------------------------------------\n#\n# Use a descriptive name for the node:\n#\nnode.name: node-0\n#\n# Add custom attributes to the node:\n#\nnode.attr.rack: r1\n#\n# ----------------------------------- Paths ------------------------------------\n#\n# Path to directory where to store the data (separate multiple locations by comma):\n#\npath.data: /apps/home/worker/zhangxiaolong/data/index0\n#\n# Path to log files:\n#\npath.logs: /apps/home/worker/zhangxiaolong/data/log0\n#\n# ----------------------------------- Memory -----------------------------------\n#\n# Lock the memory on startup:\n#\nbootstrap.memory_lock: true\n#\n# Make sure that the heap size is set to about half the memory available\n# on the system and that the owner of the process is allowed to use this\n# limit.\n#\n# Elasticsearch performs poorly when the system is swapping the memory.\n#\n# ---------------------------------- Network -----------------------------------\n#\n# Set the bind address to a specific IP (IPv4 or IPv6):\n#\nnetwork.host: 172.16.7.1\n#\n# Set a custom port for HTTP:\n#\nhttp.port: 9201\n#\n# For more information, see the documentation at:\n# <https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-network.html>\n#\n# --------------------------------- Discovery ----------------------------------\n#\n# Pass an initial list of hosts to perform discovery when new node is started:\n#The default list of hosts is [\"127.0.0.1\", \"[::1]\"]\n#\ndiscovery.zen.ping.unicast.hosts: [\"172.16.7.1:9300\"]\n#\n# Prevent the \"split brain\" by configuring the majority of nodes (total number of nodes / 2 + 1):\n#\ndiscovery.zen.minimum_master_nodes: 2\n#\n# For more information, see the documentation at:\n# <https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-discovery-zen.html>\n#\n# ---------------------------------- Gateway -----------------------------------\n#\n# Block initial recovery after a full cluster restart until N nodes are started:\n#\ngateway.recover_after_nodes: 2\n#\n# For more information, see the documentation at:\n# <https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-gateway.html>\n#\n# ---------------------------------- Various -----------------------------------\n#\n# Require explicit names when deleting indices:\n#\n#action.destructive_requires_name: true\n```\n\n### 其他\n（1）线程池设置成内核数，比如八核机器就设置成8，很多阻塞的操作都是Lucene来操作的，比如硬盘读写。搜索的线程设置可以设置成内核数的三倍\n（2）内存交换\n这个对于性能影响是致命的，可以使用命令sudo swapoff -a来暂时关闭，永久关闭需要编辑文件/etc/fstab，也可以在配置文件中添加配置bootstrap.mlockall: true，这样jvm可以锁定这些内存，避免被交换到物理存储介质\n（3）其他\n\n- 如果你不需要近实时功能，则设置index的刷新时间；\n- 如果在进行一个大bulk导入，可以优先考虑设置副本数为0；\n- 如果在index中的doc你没有一个自然增长的id，可以使用Elasticsearch’s 的自动id做标示，如果有自己的id，尽量设计对lucene友好的id；\n\n## 4. Rolling Restarts & 备份数据 & 备份恢复 \n### Rolling Restarts\n一般下线一个node（升级、维修等），elasticsearch会进行rebalance操作，如果你是真正的下线一个node，这个操作是十分正确的，但是你知道这台node会之后重新加入到cluster中，则rebalance操作不恰当了，当shard比较大或者多的时候会严重耗费系统资源。\n\n那我们正确的操作是什么？\n\n``` shell\n1. 查看集群设置\ncurl -XGET http://10.10.160.129:9200/_cluster/settings\n\n2. 如果可能的话，停止正在索引的数据；\n\n3. 停止分片同步，阻止elasticsearch进行rebalance操作\nPUT /_cluster/settings\n{\n    \"transient\" : {\n        \"cluster.routing.allocation.enable\" : \"none\"\n    }\n}\n\n4.关闭单个node\n\n5.维护或者升级节点node\n\n6.重启node，确认加入cluster\n\n7.重新打开分片同步\nPUT /_cluster/settings\n{\n    \"transient\" : {\n        \"cluster.routing.allocation.enable\" : \"all\"\n    }\n}\n\n8.针对需要的node重复执行3-7操作\n\n9.到这里就重新恢复了cluster；\n```\n\n### 备份数据\n\n``` shell\n1. 先导入一些数据进行备份\ncurl -XPOST 'http://192.168.56.11:9200/bank/account/_bulk?pretty' --data-binary @accounts.json\ncurl -XPOST 'http://192.168.56.11:9200/shakespeare/_bulk?pretty' --data-binary @shakespeare.json\ncurl -XPOST 'http://192.168.56.11:9200/_bulk?pretty' --data-binary @logs.jsonl\n\n2. 使用API创建一个镜像仓库\ncurl -XPOST http://192.168.56.11:9200/_snapshot/my_backup -d '\n{\n    \"type\": \"fs\", \n    \"settings\": { \n        \"location\": \"/data/mount\"\n        \"compress\":  true \n    }\n}'\n## 解释：\n镜像仓库的名称：my_backup\n镜像仓库的类型：fs。还支持curl，hdfs等。\n镜像仓库的位置：/data/mount 。这个位置必须在配置文件中定义。\n是否启用压缩：compres：true 表示启用压缩。\n\n3. 备份前检查配置\n必须确定备份使用的目录在配置文件中声明了，否则会爆如下错误\n{\n  \"error\": {\n    \"root_cause\": [\n      {\n        \"type\": \"repository_exception\",\n        \"reason\": \"[test-bakcup] failed to create repository\"\n      }\n    ],\n    \"type\": \"repository_exception\",\n    \"reason\": \"[test-bakcup] failed to create repository\",\n    \"caused_by\": {\n      \"type\": \"creation_exception\",\n      \"reason\": \"Guice creation errors:\\n\\n1) Error injecting constructor, RepositoryException[[test-bakcup] location [/data/mount] doesn't match any of the locations specified by path.repo because this setting is empty]\\n  at org.elasticsearch.repositories.fs.FsRepository.<init>(Unknown Source)\\n  while locating org.elasticsearch.repositories.fs.FsRepository\\n  while locating org.elasticsearch.repositories.Repository\\n\\n1 error\",\n      \"caused_by\": {\n        \"type\": \"repository_exception\",\n        \"reason\": \"[test-bakcup] location [/data/mount] doesn't match any of the locations specified by path.repo because this setting is empty\"\n      }\n    }\n  },\n  \"status\": 500\n}\n\n4. 开始创建一个快照\n##在后头创建一个快照\ncurl -XPUT  http://192.168.56.20:9200/_snapshot/my_backup/snapshot_1 \n##也可以在前台运行。\ncurl -XPUT  http://192.168.56.11:9200/_snapshot/my_backup/snapshot_1?wait_for_completion=true\n##上面的参数会在my_backup仓库里创建一个snapshot_1 的快照。\n\n5. 可以选择相应的索引进行备份\ncurl -XPUT  http://192.168.56.20:9200/_snapshot/my_backup/snapshot_2 -d '\n{\n    \"indices\": \"bank,logstash-2015.05.18\"\n}'\n## 解释：\n创建一个snapshot_2的快照，只备份bank,logstash-2015.05.18这两个索引。\n\n6. 查看备份状态\n整个备份过程中，可以通过如下命令查看备份进度\n\ncurl -XGET http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_status\n主要由如下几种状态：\na. INITIALIZING 集群状态检查，检查当前集群是否可以做快照，通常这个过程会非常快\nb. STARTED 正在转移数据到仓库\nc. FINALIZING 数据转移完成，正在转移元信息\nd. DONE　完成\ne. FAILED 备份失败\n\n7. 取消备份\ncurl -XDELETE http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812\n\n8. 获取所有快照信息。\ncurl -XGET http://192.168.56.20:9200/_snapshot/my_backup/_all |python -mjson.tool\n##解释\n查看my_backup仓库下的所有快照。\n\n9. 手动删除快照\ncurl -XDELETE http://192.168.56.20:9200/_snapshot/my_backup/snapshot_2\n## 解释\n删除my_backup仓库下的snapshot_2的快照。\n\n```\n\n### 备份恢复\n\n``` json\n1. 恢复备份\ncurl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore\n同备份一样，也可以设置wait_for_completion=true等待恢复结果\n\ncurl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore?wait_for_completion=true\n默认情况下，是恢复所有的索引，我们也可以设置一些参数来指定恢复的索引，以及重命令恢复的索引，这样可以避免覆盖原有的数据.\n\ncurl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore\n{\n    \"indices\": \"index_1\",\n    \"rename_pattern\": \"index_(.+)\",\n    \"rename_replacement\": \"restored_index_$1\"\n}\n上面的indices, 表示只恢复索引’index_1’\nrename_pattern: 表示重命名索引以’index_’开头的索引.\nrename_replacement: 表示将所有的索引重命名为’restored_index_xxx’.如index_1会被重命名为restored_index_1.\n\n2. 查看所有索引的恢复进度\ncurl -XGET http://192.168.0.1:9200/_recovery/\n\n3. 查看索引restored_index_1的恢复进度\ncurl -XGET http://192.168.0.1:9200/_recovery/restored_index_1\n\n4. 取消恢复\n只需要删除索引，即可取消恢复\ncurl -XDELETE http://192.168.0.1:9200/restored_index_1\n```\n\n## 5. 性能优化\n在讲性能优化之前，首先要知道：\n\n\t过早的优化是万恶之源 Premature optimization is the root of all evil.\n\t\t\t\t\t\t\t\t\t\t                —— Donald Knuth\n\n`优化总是发生在目前的情况下不能满足当前的需求，其他我想不出什么理由去优化它。`\n\n`优化很多时候和业务是紧密关联的，优化业务可能比优化程序效率更高、成本更低！`\n\n### 索引性能优化\n索引性能（Index Performance），我们这样定义它，索引的速度是否提高，可以无缝的提供近实时的功能。\n什么时候会发生索引慢呢？\n（1）你读的慢（doc from db，file，inputstream等等）\n（2）你处理的慢（中文下的分词等）\n（3）你写的慢（还是老式的机械盘？！ 高性能的盘或者ssd）\n\n还有就是针对不同场景选择的判断，如果你索引的文件非常大，数量多，那应该选择elasticsearch提供的bulk接口，在create doc速度能跟上的时候，bulk 是可以提高速度的。\n\n### 查询性能优化\n查询性能（Query Perofrmance），说起来比索引更麻烦一些，面对的场景也更多一些；\n\n面对海量数据以及不同的集群，针对业务需求去查询往往会很慢，有什么策略可以搞定这种情况？有，那就是`routing`[Routing a Document to a Shard](https://www.elastic.co/guide/en/elasticsearch/guide/current/routing-value.html)、[_routing field](https://www.elastic.co/guide/en/elasticsearch/reference/5.1/mapping-routing-field.html).\n\n查询策略，分别查询vs合并查询？索引越来越大，单个 shard 也很巨大，查询速度也越来越慢。这时候，是选择分索引还是更多的shards？在实践过程中，更多的 shards 会带来额外的索引压力，即 IO 压力。我们选择了分索引。比如按照每个大分类一个索引，或者主要的大城市一个索引。然后将他们进行合并查询。\n\n索引越来越大，资源使用也越来越多。若是要进行更细的集群分配，大索引使用的资源成倍增加。有什么办法能减小索引？\n根据具体业务需求，减少某些大的索引，这是一个很好的办法，这样这个集群各方面占用的资源会有一定程度的下降，当让你要说这些少的索引怎么办，这些索引可以放在单独的集群中。\n\n## 应用性能优化 - [from youzan](http://tech.youzan.com/search-engine1/)\n一、使用应用级队列防止雪崩\nES一个问题是在高峰期时候极容易发生雪崩. ES有健全的线程池系统来保证并发与稳定性问题. 但是在流量突变的情况下(比如双十一秒杀)还是很容易发生瘫痪的现象, 主要的原因如下:\n\nES几乎为每类操作配置一个线程池; 只能保证每个线程池的资源使用时合理的, 当2个以上的线程池竞争资源时容易造成资源响应不过来.\n\nES没有考虑网络负载导致稳定的问题.\n\n在AS里我们实现了面向请求的全局队列来保证稳定性. 它主要做了3件事情.\n![](http://ww1.sinaimg.cn/mw690/b7ba225dly1fjx0kmbrr6j20fu0le3zi.jpg)\n\n1. 根据业务把请求分成一个个slide, 每个slide对应一个队列. 默认一个应用就是一个slide, 一个应用也可以区分不同的slide, 这样可以保护一个应用内重要的查询.\n2. 每个队列配置一个队列长度, 默认为50.\n3. 每个队列计算这个队列的平均响应时间. 当队列平均响应时间超过200ms, 停止工作1s, 如果请求溢出就写入溢出日志留数据恢复使用. 如果连续10次队列平均响应时间超过500ms就报警, 以便工程师第一时间处理.\n\n二、自动降级\n应用级队列解决雪崩问题有点粗暴, 如果一个应用本身查询就非常慢, 很容易让一个应用持续超时很久. 我们根据搜索引擎的特点编写了自动降级功能.\n\n比如商品搜索的例子, 商品搜索最基本的功能是布尔查询, 但是还需要按照相关性分数和质量度排序等功能, 甚至还有个性化需求. 完成简单的布尔查询, ES使用bitsets操作就可以做到, 但是如果如果需要相关性分, 就必须使用倒排索引, 并有大量CPU消耗来计算分数. ES的bitsets比倒排索引快50倍左右.\n\n对于有降级方案的slide, AS在队列响应过慢时候直接使用降级query代替正常query. 这种方法让我们在不扩容的情况下成功度过了双十一的流量陡增.\n\n三、善用filtered query\n理解lucence filter工作原理对于写出高性能查询语句至关重要. 许多搜索性能优化都和filter的使用有关. filter使用bitsets进行布尔运算, quey使用倒排索引进行计算, 这是filter比query快的原因. bitsets的优势主要体现在: \n\n1. bitsetcache在内存里面, 永不消失(除非被LRU). \n2. bitsets利用CPU原生支持的位运算操作, 比倒排索引快个数量级 \n3. 多个bitsets的与运算也是非常的快(一个64位CPU可以同时计算64个DOC的与运算) \n4. bitsets 在内存的存储是独立于query的, 有很强的复用性 \n5. 如果一个bitset片段全是0, 计算会自动跳过这些片段, 让bitsets在数据稀疏情况下同样表现优于倒排索引.\n\n举个例子:\n``` java \nquery:bool:  \n    tag:'mac'\n    region:'beijing'\n    title: \"apple\"\n```\n\nlucence处理这个query的方式是在倒排索引中寻找这三个term的倒排链 ,并使用跳指针技术求交, 在运算过程中需要对每个doc进行算分. 实际上tag和region对于算分并没有作用, 他们充当是过滤器的作用.\n\n这就是过滤器使用场景, 它只存储存在和不存在两种状态. 如果我们把tag和region使用bitsets进行存储, 这样这两个过滤器可以一直都被缓存在内存里面, 这样会快很多. 另外tag和region之间的求交非常迅速, 因为64位机器可以时间一个CPU周期同时处理64个doc的位运算.\n\n一个lucence金科玉律是: 能用filter就用filter, 除非必须使用query(当且仅当你需要算分的时候).\n正确的写法为:\n\n``` java\nquery:  \n    filtered: \n        query:  \n             title: \"apple\" \n         filter:\n            tag:\"mac\"\n             region:\"beijing\"\n```\n四、其他\n\n1. 线上集群关闭分片自动均衡. 分片的自动均衡主要目的防止更新造成各个分片数据分布不均匀. 但是如果线上一个节点挂掉后, 很容易触发自动均衡, 一时间集群内部的数据移动占用所有带宽. 建议采用闲时定时均衡策略来保证数据的均匀.\n\n2. 尽可能延长refresh时间间隔. 为了确保实时索引es索引刷新时间间隔默认为1秒, 索引刷新会导致查询性能受影响, 在确保业务时效性保证的基础上可以适当延长refresh时间间隔保证查询的性能.\n\n3. 除非有必要把all字段去掉. 索引默认除了索引每个字段外, 还有额外创建一个all的字段, 保存所有文本, 去掉这个字段可以把索引大小降低50%.\n\n4. 创建索引时候, 尽可能把查询比较慢的索引和快的索引物理分离.\n\n##6. 参考（Reference）\n1. [elastic调优参考](http://www.cnblogs.com/guguli/p/5218297.html)\n2. [elastic监控](https://github.com/Wprosdocimo/Elasticsearch-zabbix)\n3. [Mastering Elasticsearch(中文版)](http://udn.yyuap.com/doc/mastering-elasticsearch/chapter-4/41_README.html)\n4. [ELK-权威指南](http://kibana.logstash.es/content/logstash/plugins/input/file.html)\n5. [Elasticsearch 权威指南](http://www.learnes.net/index.html)\n6. [elasticsearch 生产环境配置](http://www.biglittleant.cn/2016/12/01/elastic-study1/)\n7. [有赞搜索引擎实践(工程篇)](http://tech.youzan.com/search-engine1/)\n\n\n**[更新于2017-05-22 - v1.0 ]\n[更新于2017-09-26 - v1.01]**\n\n(完)\n\n","slug":"elasticsearch_tec_book_v1.01","published":1,"updated":"2017-09-26T07:51:16.000Z","_id":"cj81aidwm00004ss6a95dg9pg","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"elasticsearch技术手册-v1-01\"><a href=\"#elasticsearch技术手册-v1-01\" class=\"headerlink\" title=\"elasticsearch技术手册 v1.01\"></a>elasticsearch技术手册 v1.01</h1><p>[toc]</p>\n<h2 id=\"1-基础\"><a href=\"#1-基础\" class=\"headerlink\" title=\"1. 基础\"></a>1. 基础</h2><p>本手册内容是基于<code>elasticsearch5+</code>版本。准确的说是5.0.1版本。</p>\n<h3 id=\"1-概念\"><a href=\"#1-概念\" class=\"headerlink\" title=\"1.概念\"></a>1.概念</h3><p>集群（cluster）、节点（node）、索引（index）、分片（shards）、副本（replicas）；<br>term、tf-idf、boost等</p>\n<h3 id=\"2-Elasticsearch-features\"><a href=\"#2-Elasticsearch-features\" class=\"headerlink\" title=\"2. Elasticsearch features\"></a>2. Elasticsearch features</h3><ol>\n<li><a href=\"\">Based in lucene, write in java</a></li>\n<li><a href=\"\">Realtime analytics</a></li>\n<li><a href=\"\">Full Text search engine</a></li>\n<li><a href=\"\">Distributed, easy to scale</a></li>\n<li><a href=\"\">High availability</a></li>\n<li><a href=\"\">Document oriented(json)</a></li>\n<li><a href=\"\">Schema free</a></li>\n<li><a href=\"\">Restful API, json over http</a></li>\n<li><a href=\"\">Open source:Apache License 6.0 (ES:5.x)</a></li>\n<li><a href=\"\">Plugins &amp; Community support</a></li>\n</ol>\n<h3 id=\"3-elasticsearch-do-what-on-lucene\"><a href=\"#3-elasticsearch-do-what-on-lucene\" class=\"headerlink\" title=\"3. elasticsearch do what on lucene?\"></a>3. elasticsearch do what on lucene?</h3><p>Elasticsearch 构建在lucene之上，提供json方式的rest api进行交互；</p>\n<ol>\n<li>Elasticsearch在lucene之上提供一个完整的分布式系统；</li>\n<li>Elasticsearch提供了一个分布式的抽象的数据结构；</li>\n<li>提供了一些特性，例如线程池、队列、node/cluster监控api、数据监控api、以及集群管理等等；</li>\n</ol>\n<h2 id=\"2-生产环境\"><a href=\"#2-生产环境\" class=\"headerlink\" title=\"2. 生产环境\"></a>2. 生产环境</h2><h3 id=\"1-监控（Monitoring）\"><a href=\"#1-监控（Monitoring）\" class=\"headerlink\" title=\"1. 监控（Monitoring）\"></a>1. 监控（Monitoring）</h3><p>对于已经初步部署完成的elasticsearch集群来说，接下来的集群监控就变的更重要了。集群的重要参数，比如集群状态，分片状态等是集群健康的体现。elasticsearch提供了很对的现成api供我们管理和监控cluster。<br>其中，(1)marvel是一个很容易监控elasticsearch的工具。它可以整合大量的统计数据通过kibana。<br>(2) cluster health</p>\n<h3 id=\"2-生产环境部署（Production-Deploying）\"><a href=\"#2-生产环境部署（Production-Deploying）\" class=\"headerlink\" title=\"2. 生产环境部署（Production Deploying）\"></a>2. 生产环境部署（Production Deploying）</h3><p>生产环境的部署有很多考究的地方，接下来我从以下三个方面来说。</p>\n<h4 id=\"运维部署考虑（硬件以及部署策略）\"><a href=\"#运维部署考虑（硬件以及部署策略）\" class=\"headerlink\" title=\"运维部署考虑（硬件以及部署策略）\"></a>运维部署考虑（硬件以及部署策略）</h4><p>（1）memory，elasticsearch是比较吃内存的，尤其像排序、聚合操作，所以保证足够的heap内存是重要的。如果对内存不够的话，会交换到系统的缓存，由于lucene的数据结构是disk-based的格式，这势必会影响搜索的性能；一般建议使用16g-64gRAM的机器。如果大于64g，则会出现<a href=\"https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html\" target=\"_blank\" rel=\"external\">另外的一些问题</a><br>（2）cpus,和内存相比，搜索对cpu的要求不是特别高，一般使用多核cpu就行，比如2-8核的；<br>（3）disk，硬盘的性能对搜索集群非常重要，磁盘的性能直接影响索引的构建和读写操作，很多时候是搜索的一个瓶颈。ssd硬盘是目前最好的方式，但是由于其价钱看看阿里云，是同样的<code>喜人</code>，所以看业务需要，力所能及吧，我们目前使用的是高性能磁盘（high-performance server disks, 15k RPM drives），可以满足业务需求。<br>（4）network，一个快速稳定的网络环境对分布式系统非常的重要，低延迟、高带宽有利于节点间的交互以及分片的拷贝和恢复<br>（5）其他，尽量避免使用小配置机器组合一个超大的集群，这样管理起来就是一个大坑</p>\n<h4 id=\"优化配置参数\"><a href=\"#优化配置参数\" class=\"headerlink\" title=\"优化配置参数\"></a>优化配置参数</h4><p>(1)Java Virtual Machine<br>(2)Transport Client Versus Node Client<br>vs:<br>Transport Client 可以解耦你的应用和搜索服务，应用可以很快的创建和销毁连接；<br>Node Client 可以和搜索服务保持一个持久连接，可以查看搜索的结构信息；<br>(3)Important Configuration Changes<br>elasticsearch配置文件有非常好的默认设置，都是在实际的工作环境中实践过的。当遇到性能问题的时候，更多的是需要考虑数据存储布局和添加更多的node（elasticsearch文档中特意说明了配置文件的重要性，不让随便更改，大多数情况下是正确的）。</p>\n<ul>\n<li>name</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">1. Assign Names</div><div class=\"line\">cluster.name: elasticsearch_production</div><div class=\"line\">node.name: elasticsearch_005_data</div><div class=\"line\"></div><div class=\"line\">2. Paths</div><div class=\"line\">path.data: /path/to/data1,/path/to/data2 </div><div class=\"line\"></div><div class=\"line\"># Path to log files:</div><div class=\"line\">path.logs: /path/to/logs</div><div class=\"line\"></div><div class=\"line\"># Path to where plugins are installed:</div><div class=\"line\">path.plugins: /path/to/plugins</div></pre></td></tr></table></figure>\n<ul>\n<li><p>minimum_master_nodes，这个参数是在配置文件中比较重要的一个，如果配置不对的话，会发生split brains（俗称“脑裂”），就是说会存在多个master节点，继而可能发生丢失data现象。这个参数的计算公式：(number of master-eligible nodes / 2) + 1，举例说明：</p>\n<ul>\n<li>假如你有10个node（可存储数据，可成为master），则设置为6；</li>\n<li>假如你有三个可选为master的节点，100+个数据节点，则设置为2；</li>\n<li>假如你有2个常规节点，这个值设置为2，但是如果丢失一个则会造成集群不可用，如果设置为1，则不能保证脑裂的不存在，最好的方法是保证最小的节点数为3.</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">discovery.zen.minimum_master_nodes: 2</div></pre></td></tr></table></figure>\n<p>因为elasticsearch是自适应的，节点随时添加或者下线，不过还好，有api我们可以实时调整这个参数，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">PUT /_cluster/settings</div><div class=\"line\">&#123;</div><div class=\"line\">    &quot;persistent&quot; : &#123;</div><div class=\"line\">        &quot;discovery.zen.minimum_master_nodes&quot; : 2</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<ul>\n<li>Recovery Settings<br>恢复策略对elasticsearch是必不可少的，举例来说，假如现在集群（10 nodes）集体下线进行维修升级，当重新启动的时候，先启动了5 nodes，此时集群发现有5个node启动了，会执行shard的备份和交换，直到达到分片平衡，此时如果另外5 nodes加入到集群中，会发生什么呢？cluster会继续rebalance，新加入的节点发现数据集群中已经有了，首先删除本地数据，通知集群发动rebalance，平衡各个shards，这整个过程中shard会发生copy、sweap、delete等操作，耗费好多资源和时间，对一个大集群来说，耗费的更多，不可忍受。所以，elasticsearch有三个参数可以配置这些。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">gateway.recover_after_nodes: 8   // 集群中恢复的节点数，就是说当改集群启动了8个几点，才尽兴rebalance</div><div class=\"line\"></div><div class=\"line\">// 这两项说明，本集群有10的node，当10个nodes都启动或者启动了8个node且超过5分钟后就会发起rebalance</div><div class=\"line\">gateway.expected_nodes: 10</div><div class=\"line\">gateway.recover_after_time: 5m</div></pre></td></tr></table></figure>\n<p>这些策略只和<code>整个cluster重启</code>时生效。</p>\n<ul>\n<li>Prefer Unicast over Multicast<br>elasticsearch建议使用单播的方式，虽然依然提供了多播的方式，但存在找不到master等尴尬的问题，不建议使用。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">discovery.zen.ping.unicast.hosts: [&quot;host1&quot;, &quot;host2:port&quot;]</div></pre></td></tr></table></figure>\n<p>（4）不要轻易修改的参数</p>\n<ol>\n<li><p>Garbage Collector<br>elasticsearch中默认采用Concurrent-Mark and Sweep (CMS)的gc回收器；</p>\n</li>\n<li><p>Threadpools<br>elasticsearch中设置线程池非常合理的，如果没有特别情况下不要修改这个值</p>\n</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">Search gets a larger threadpool, and is configured to int((# of cores * 3) / 2) + 1</div></pre></td></tr></table></figure>\n<p>(5)Heap: Sizing and Swapping<br>(6)File Descriptors and MMap<br>elasticsearch混合使用nioFS和MMapFS。</p>\n<h3 id=\"3-插件\"><a href=\"#3-插件\" class=\"headerlink\" title=\"3. 插件\"></a>3. 插件</h3><ol>\n<li>使用<a href=\"https://github.com/mobz/elasticsearch-head\" target=\"_blank\" rel=\"external\">head</a>插件来查看索引数据</li>\n<li>使用<a href=\"https://github.com/lmenezes/elasticsearch-kopf\" target=\"_blank\" rel=\"external\">kopf</a>来备份集群节点</li>\n<li>使用<a href=\"https://github.com/lukas-vlcek/bigdesk\" target=\"_blank\" rel=\"external\">bigdesk</a>查看集群性能</li>\n<li><a href=\"https://github.com/NLPchina/elasticsearch-sql\" target=\"_blank\" rel=\"external\">elasticsearch-sql</a> 通过sql进行聚合检索, 可以将sql语句翻译成ES的JSON检索语句</li>\n<li>中文分词（ik、pinying）</li>\n<li><a href=\"https://www.elastic.co/guide/en/elasticsearch/client/curator/current/about.html\" target=\"_blank\" rel=\"external\">Curator</a></li>\n</ol>\n<h2 id=\"3-参数配置\"><a href=\"#3-参数配置\" class=\"headerlink\" title=\"3. 参数配置\"></a>3. 参数配置</h2><p>暂空（后补）</p>\n<h3 id=\"java优化配置\"><a href=\"#java优化配置\" class=\"headerlink\" title=\"java优化配置\"></a>java优化配置</h3><p>(1)Heap不要超过系统可用内存的一半，并且不要超过32GB。</p>\n<p>(2) cluster集群jvm调优<br>当时我们配置ES的JVM(Xms=Xmx=8G)的垃圾回收器主要是CMS,具体配置如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"># reduce the per-thread stack size</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -Xss256k&quot;</div><div class=\"line\"></div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UseParNewGC&quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UseConcMarkSweepGC&quot;</div><div class=\"line\"></div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:CMSInitiatingOccupancyFraction=75&quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UseCMSInitiatingOccupancyOnly&quot;</div></pre></td></tr></table></figure>\n<p>这块在官方说明中，特意强调了不建议替换java垃圾回收器，<a href=\"https://www.elastic.co/guide/en/elasticsearch/guide/current/_don_8217_t_touch_these_settings.html#_garbage_collector\" target=\"_blank\" rel=\"external\">官方并不推荐使用G1</a>。</p>\n<p><a href=\"https://www.geekhub.cn/a/1256.html\" target=\"_blank\" rel=\"external\">其他博文</a>中有试过使用其他垃圾回收器。他的G1的具体配置如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UseG1GC &quot;</div><div class=\"line\">#init_globals()末尾打印日志</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintFlagsFinal &quot;</div><div class=\"line\">#打印gc引用</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintReferenceGC &quot;</div><div class=\"line\">#输出虚拟机中GC的详细情况.</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -verbose:gc &quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintGCDetails &quot;</div><div class=\"line\">#Enables printing of time stamps at every GC. By default, this option is disabled.</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintGCTimeStamps &quot;</div><div class=\"line\">#Enables printing of information about adaptive generation sizing. By default, this option is disabled.</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintAdaptiveSizePolicy &quot;</div><div class=\"line\"># unlocks diagnostic JVM options</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UnlockDiagnosticVMOptions &quot;</div><div class=\"line\">#to measure where the time is spent</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+G1SummarizeConcMark &quot;</div><div class=\"line\">#设置触发标记周期的 Java 堆占用率阈值。默认占用率是整个 Java 堆的 45%。</div><div class=\"line\">#JAVA_OPTS=&quot;$JAVA_OPTS -XX:InitiatingHeapOccupancyPercent=45 &quot;</div></pre></td></tr></table></figure>\n<p>(3) elastic 开启jmx 监控<br>有时候监控是必不可少的，所以在有条件的时候可以加上jmx监控</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">/usr/local/elastic/bin/elasticsearch.in.sh</div><div class=\"line\">JMX_PORT=9305</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -Dcom.sun.management.jmxremote.port=$JMX_PORT&quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -Dcom.sun.management.jmxremote.ssl=false&quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -Dcom.sun.management.jmxremote.authenticate=false&quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -Djava.rmi.server.hostname=xx.xx.xx..xx&quot;</div></pre></td></tr></table></figure>\n<h3 id=\"elasticsearch-yml\"><a href=\"#elasticsearch-yml\" class=\"headerlink\" title=\"elasticsearch.yml\"></a>elasticsearch.yml</h3><p>这个是最重要的配置，只有在你明白之后在修改，之后我在单独写一篇文章介绍目前elasticsearch默认参数是如何影响系统的。</p>\n<p>目前配置包括以下几个部分：<br>（1）cluster<br>（2）节点node<br>（3）log／data路径<br>（4）内存<br>（5）网络<br>（5）发现Discovery<br>（6）Gateway<br>（7）其他变量</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div></pre></td><td class=\"code\"><pre><div class=\"line\"># ======================== Elasticsearch Configuration =========================</div><div class=\"line\">#</div><div class=\"line\"># NOTE: Elasticsearch comes with reasonable defaults for most settings.</div><div class=\"line\">#       Before you set out to tweak and tune the configuration, make sure you</div><div class=\"line\">#       understand what are you trying to accomplish and the consequences.</div><div class=\"line\">#</div><div class=\"line\"># The primary way of configuring a node is via this file. This template lists</div><div class=\"line\"># the most important settings you may want to configure for a production cluster.</div><div class=\"line\">#</div><div class=\"line\"># Please see the documentation for further information on configuration options:</div><div class=\"line\"># &lt;https://www.elastic.co/guide/en/elasticsearch/reference/5.0/settings.html&gt;</div><div class=\"line\">#</div><div class=\"line\"># ---------------------------------- Cluster -----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Use a descriptive name for your cluster:</div><div class=\"line\">#</div><div class=\"line\">cluster.name: elastic-pro</div><div class=\"line\">#</div><div class=\"line\"># ------------------------------------ Node ------------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Use a descriptive name for the node:</div><div class=\"line\">#</div><div class=\"line\">node.name: node-0</div><div class=\"line\">#</div><div class=\"line\"># Add custom attributes to the node:</div><div class=\"line\">#</div><div class=\"line\">node.attr.rack: r1</div><div class=\"line\">#</div><div class=\"line\"># ----------------------------------- Paths ------------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Path to directory where to store the data (separate multiple locations by comma):</div><div class=\"line\">#</div><div class=\"line\">path.data: /apps/home/worker/zhangxiaolong/data/index0</div><div class=\"line\">#</div><div class=\"line\"># Path to log files:</div><div class=\"line\">#</div><div class=\"line\">path.logs: /apps/home/worker/zhangxiaolong/data/log0</div><div class=\"line\">#</div><div class=\"line\"># ----------------------------------- Memory -----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Lock the memory on startup:</div><div class=\"line\">#</div><div class=\"line\">bootstrap.memory_lock: true</div><div class=\"line\">#</div><div class=\"line\"># Make sure that the heap size is set to about half the memory available</div><div class=\"line\"># on the system and that the owner of the process is allowed to use this</div><div class=\"line\"># limit.</div><div class=\"line\">#</div><div class=\"line\"># Elasticsearch performs poorly when the system is swapping the memory.</div><div class=\"line\">#</div><div class=\"line\"># ---------------------------------- Network -----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Set the bind address to a specific IP (IPv4 or IPv6):</div><div class=\"line\">#</div><div class=\"line\">network.host: 172.16.7.1</div><div class=\"line\">#</div><div class=\"line\"># Set a custom port for HTTP:</div><div class=\"line\">#</div><div class=\"line\">http.port: 9201</div><div class=\"line\">#</div><div class=\"line\"># For more information, see the documentation at:</div><div class=\"line\"># &lt;https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-network.html&gt;</div><div class=\"line\">#</div><div class=\"line\"># --------------------------------- Discovery ----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Pass an initial list of hosts to perform discovery when new node is started:</div><div class=\"line\">#The default list of hosts is [&quot;127.0.0.1&quot;, &quot;[::1]&quot;]</div><div class=\"line\">#</div><div class=\"line\">discovery.zen.ping.unicast.hosts: [&quot;172.16.7.1:9300&quot;]</div><div class=\"line\">#</div><div class=\"line\"># Prevent the &quot;split brain&quot; by configuring the majority of nodes (total number of nodes / 2 + 1):</div><div class=\"line\">#</div><div class=\"line\">discovery.zen.minimum_master_nodes: 2</div><div class=\"line\">#</div><div class=\"line\"># For more information, see the documentation at:</div><div class=\"line\"># &lt;https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-discovery-zen.html&gt;</div><div class=\"line\">#</div><div class=\"line\"># ---------------------------------- Gateway -----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Block initial recovery after a full cluster restart until N nodes are started:</div><div class=\"line\">#</div><div class=\"line\">gateway.recover_after_nodes: 2</div><div class=\"line\">#</div><div class=\"line\"># For more information, see the documentation at:</div><div class=\"line\"># &lt;https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-gateway.html&gt;</div><div class=\"line\">#</div><div class=\"line\"># ---------------------------------- Various -----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Require explicit names when deleting indices:</div><div class=\"line\">#</div><div class=\"line\">#action.destructive_requires_name: true</div></pre></td></tr></table></figure>\n<h3 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h3><p>（1）线程池设置成内核数，比如八核机器就设置成8，很多阻塞的操作都是Lucene来操作的，比如硬盘读写。搜索的线程设置可以设置成内核数的三倍<br>（2）内存交换<br>这个对于性能影响是致命的，可以使用命令sudo swapoff -a来暂时关闭，永久关闭需要编辑文件/etc/fstab，也可以在配置文件中添加配置bootstrap.mlockall: true，这样jvm可以锁定这些内存，避免被交换到物理存储介质<br>（3）其他</p>\n<ul>\n<li>如果你不需要近实时功能，则设置index的刷新时间；</li>\n<li>如果在进行一个大bulk导入，可以优先考虑设置副本数为0；</li>\n<li>如果在index中的doc你没有一个自然增长的id，可以使用Elasticsearch’s 的自动id做标示，如果有自己的id，尽量设计对lucene友好的id；</li>\n</ul>\n<h2 id=\"4-Rolling-Restarts-amp-备份数据-amp-备份恢复\"><a href=\"#4-Rolling-Restarts-amp-备份数据-amp-备份恢复\" class=\"headerlink\" title=\"4. Rolling Restarts &amp; 备份数据 &amp; 备份恢复\"></a>4. Rolling Restarts &amp; 备份数据 &amp; 备份恢复</h2><h3 id=\"Rolling-Restarts\"><a href=\"#Rolling-Restarts\" class=\"headerlink\" title=\"Rolling Restarts\"></a>Rolling Restarts</h3><p>一般下线一个node（升级、维修等），elasticsearch会进行rebalance操作，如果你是真正的下线一个node，这个操作是十分正确的，但是你知道这台node会之后重新加入到cluster中，则rebalance操作不恰当了，当shard比较大或者多的时候会严重耗费系统资源。</p>\n<p>那我们正确的操作是什么？</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div></pre></td><td class=\"code\"><pre><div class=\"line\">1. 查看集群设置</div><div class=\"line\">curl -XGET http://10.10.160.129:9200/_cluster/settings</div><div class=\"line\"></div><div class=\"line\">2. 如果可能的话，停止正在索引的数据；</div><div class=\"line\"></div><div class=\"line\">3. 停止分片同步，阻止elasticsearch进行rebalance操作</div><div class=\"line\">PUT /_cluster/settings</div><div class=\"line\">&#123;</div><div class=\"line\">    \"transient\" : &#123;</div><div class=\"line\">        \"cluster.routing.allocation.enable\" : \"none\"</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">4.关闭单个node</div><div class=\"line\"></div><div class=\"line\">5.维护或者升级节点node</div><div class=\"line\"></div><div class=\"line\">6.重启node，确认加入cluster</div><div class=\"line\"></div><div class=\"line\">7.重新打开分片同步</div><div class=\"line\">PUT /_cluster/settings</div><div class=\"line\">&#123;</div><div class=\"line\">    \"transient\" : &#123;</div><div class=\"line\">        \"cluster.routing.allocation.enable\" : \"all\"</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">8.针对需要的node重复执行3-7操作</div><div class=\"line\"></div><div class=\"line\">9.到这里就重新恢复了cluster；</div></pre></td></tr></table></figure>\n<h3 id=\"备份数据\"><a href=\"#备份数据\" class=\"headerlink\" title=\"备份数据\"></a>备份数据</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div></pre></td><td class=\"code\"><pre><div class=\"line\">1. 先导入一些数据进行备份</div><div class=\"line\">curl -XPOST 'http://192.168.56.11:9200/bank/account/_bulk?pretty' --data-binary @accounts.json</div><div class=\"line\">curl -XPOST 'http://192.168.56.11:9200/shakespeare/_bulk?pretty' --data-binary @shakespeare.json</div><div class=\"line\">curl -XPOST 'http://192.168.56.11:9200/_bulk?pretty' --data-binary @logs.jsonl</div><div class=\"line\"></div><div class=\"line\">2. 使用API创建一个镜像仓库</div><div class=\"line\">curl -XPOST http://192.168.56.11:9200/_snapshot/my_backup -d '</div><div class=\"line\">&#123;</div><div class=\"line\">    \"type\": \"fs\", </div><div class=\"line\">    \"settings\": &#123; </div><div class=\"line\">        \"location\": \"/data/mount\"</div><div class=\"line\">        \"compress\":  true </div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;'</div><div class=\"line\"><span class=\"meta\">#</span># 解释：</div><div class=\"line\">镜像仓库的名称：my_backup</div><div class=\"line\">镜像仓库的类型：fs。还支持curl，hdfs等。</div><div class=\"line\">镜像仓库的位置：/data/mount 。这个位置必须在配置文件中定义。</div><div class=\"line\">是否启用压缩：compres：true 表示启用压缩。</div><div class=\"line\"></div><div class=\"line\">3. 备份前检查配置</div><div class=\"line\">必须确定备份使用的目录在配置文件中声明了，否则会爆如下错误</div><div class=\"line\">&#123;</div><div class=\"line\">  \"error\": &#123;</div><div class=\"line\">    \"root_cause\": [</div><div class=\"line\">      &#123;</div><div class=\"line\">        \"type\": \"repository_exception\",</div><div class=\"line\">        \"reason\": \"[test-bakcup] failed to create repository\"</div><div class=\"line\">      &#125;</div><div class=\"line\">    ],</div><div class=\"line\">    \"type\": \"repository_exception\",</div><div class=\"line\">    \"reason\": \"[test-bakcup] failed to create repository\",</div><div class=\"line\">    \"caused_by\": &#123;</div><div class=\"line\">      \"type\": \"creation_exception\",</div><div class=\"line\">      \"reason\": \"Guice creation errors:\\n\\n1) Error injecting constructor, RepositoryException[[test-bakcup] location [/data/mount] doesn't match any of the locations specified by path.repo because this setting is empty]\\n  at org.elasticsearch.repositories.fs.FsRepository.&lt;init&gt;(Unknown Source)\\n  while locating org.elasticsearch.repositories.fs.FsRepository\\n  while locating org.elasticsearch.repositories.Repository\\n\\n1 error\",</div><div class=\"line\">      \"caused_by\": &#123;</div><div class=\"line\">        \"type\": \"repository_exception\",</div><div class=\"line\">        \"reason\": \"[test-bakcup] location [/data/mount] doesn't match any of the locations specified by path.repo because this setting is empty\"</div><div class=\"line\">      &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;,</div><div class=\"line\">  \"status\": 500</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">4. 开始创建一个快照</div><div class=\"line\"><span class=\"meta\">#</span>#在后头创建一个快照</div><div class=\"line\">curl -XPUT  http://192.168.56.20:9200/_snapshot/my_backup/snapshot_1 </div><div class=\"line\"><span class=\"meta\">#</span>#也可以在前台运行。</div><div class=\"line\">curl -XPUT  http://192.168.56.11:9200/_snapshot/my_backup/snapshot_1?wait_for_completion=true</div><div class=\"line\"><span class=\"meta\">#</span>#上面的参数会在my_backup仓库里创建一个snapshot_1 的快照。</div><div class=\"line\"></div><div class=\"line\">5. 可以选择相应的索引进行备份</div><div class=\"line\">curl -XPUT  http://192.168.56.20:9200/_snapshot/my_backup/snapshot_2 -d '</div><div class=\"line\">&#123;</div><div class=\"line\">    \"indices\": \"bank,logstash-2015.05.18\"</div><div class=\"line\">&#125;'</div><div class=\"line\"><span class=\"meta\">#</span># 解释：</div><div class=\"line\">创建一个snapshot_2的快照，只备份bank,logstash-2015.05.18这两个索引。</div><div class=\"line\"></div><div class=\"line\">6. 查看备份状态</div><div class=\"line\">整个备份过程中，可以通过如下命令查看备份进度</div><div class=\"line\"></div><div class=\"line\">curl -XGET http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_status</div><div class=\"line\">主要由如下几种状态：</div><div class=\"line\">a. INITIALIZING 集群状态检查，检查当前集群是否可以做快照，通常这个过程会非常快</div><div class=\"line\">b. STARTED 正在转移数据到仓库</div><div class=\"line\">c. FINALIZING 数据转移完成，正在转移元信息</div><div class=\"line\">d. DONE　完成</div><div class=\"line\">e. FAILED 备份失败</div><div class=\"line\"></div><div class=\"line\">7. 取消备份</div><div class=\"line\">curl -XDELETE http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812</div><div class=\"line\"></div><div class=\"line\">8. 获取所有快照信息。</div><div class=\"line\">curl -XGET http://192.168.56.20:9200/_snapshot/my_backup/_all |python -mjson.tool</div><div class=\"line\"><span class=\"meta\">#</span>#解释</div><div class=\"line\">查看my_backup仓库下的所有快照。</div><div class=\"line\"></div><div class=\"line\">9. 手动删除快照</div><div class=\"line\">curl -XDELETE http://192.168.56.20:9200/_snapshot/my_backup/snapshot_2</div><div class=\"line\"><span class=\"meta\">#</span># 解释</div><div class=\"line\">删除my_backup仓库下的snapshot_2的快照。</div></pre></td></tr></table></figure>\n<h3 id=\"备份恢复\"><a href=\"#备份恢复\" class=\"headerlink\" title=\"备份恢复\"></a>备份恢复</h3><figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div></pre></td><td class=\"code\"><pre><div class=\"line\">1. 恢复备份</div><div class=\"line\">curl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore</div><div class=\"line\">同备份一样，也可以设置wait_for_completion=true等待恢复结果</div><div class=\"line\"></div><div class=\"line\">curl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore?wait_for_completion=true</div><div class=\"line\">默认情况下，是恢复所有的索引，我们也可以设置一些参数来指定恢复的索引，以及重命令恢复的索引，这样可以避免覆盖原有的数据.</div><div class=\"line\"></div><div class=\"line\">curl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore</div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"attr\">\"indices\"</span>: <span class=\"string\">\"index_1\"</span>,</div><div class=\"line\">    <span class=\"attr\">\"rename_pattern\"</span>: <span class=\"string\">\"index_(.+)\"</span>,</div><div class=\"line\">    <span class=\"attr\">\"rename_replacement\"</span>: <span class=\"string\">\"restored_index_$1\"</span></div><div class=\"line\">&#125;</div><div class=\"line\">上面的indices, 表示只恢复索引’index_1’</div><div class=\"line\">rename_pattern: 表示重命名索引以’index_’开头的索引.</div><div class=\"line\">rename_replacement: 表示将所有的索引重命名为’restored_index_xxx’.如index_1会被重命名为restored_index_1.</div><div class=\"line\"></div><div class=\"line\">2. 查看所有索引的恢复进度</div><div class=\"line\">curl -XGET http://192.168.0.1:9200/_recovery/</div><div class=\"line\"></div><div class=\"line\">3. 查看索引restored_index_1的恢复进度</div><div class=\"line\">curl -XGET http://192.168.0.1:9200/_recovery/restored_index_1</div><div class=\"line\"></div><div class=\"line\">4. 取消恢复</div><div class=\"line\">只需要删除索引，即可取消恢复</div><div class=\"line\">curl -XDELETE http://192.168.0.1:9200/restored_index_1</div></pre></td></tr></table></figure>\n<h2 id=\"5-性能优化\"><a href=\"#5-性能优化\" class=\"headerlink\" title=\"5. 性能优化\"></a>5. 性能优化</h2><p>在讲性能优化之前，首先要知道：</p>\n<pre><code>过早的优化是万恶之源 Premature optimization is the root of all evil.\n                                                    —— Donald Knuth\n</code></pre><p><code>优化总是发生在目前的情况下不能满足当前的需求，其他我想不出什么理由去优化它。</code></p>\n<p><code>优化很多时候和业务是紧密关联的，优化业务可能比优化程序效率更高、成本更低！</code></p>\n<h3 id=\"索引性能优化\"><a href=\"#索引性能优化\" class=\"headerlink\" title=\"索引性能优化\"></a>索引性能优化</h3><p>索引性能（Index Performance），我们这样定义它，索引的速度是否提高，可以无缝的提供近实时的功能。<br>什么时候会发生索引慢呢？<br>（1）你读的慢（doc from db，file，inputstream等等）<br>（2）你处理的慢（中文下的分词等）<br>（3）你写的慢（还是老式的机械盘？！ 高性能的盘或者ssd）</p>\n<p>还有就是针对不同场景选择的判断，如果你索引的文件非常大，数量多，那应该选择elasticsearch提供的bulk接口，在create doc速度能跟上的时候，bulk 是可以提高速度的。</p>\n<h3 id=\"查询性能优化\"><a href=\"#查询性能优化\" class=\"headerlink\" title=\"查询性能优化\"></a>查询性能优化</h3><p>查询性能（Query Perofrmance），说起来比索引更麻烦一些，面对的场景也更多一些；</p>\n<p>面对海量数据以及不同的集群，针对业务需求去查询往往会很慢，有什么策略可以搞定这种情况？有，那就是<code>routing</code><a href=\"https://www.elastic.co/guide/en/elasticsearch/guide/current/routing-value.html\" target=\"_blank\" rel=\"external\">Routing a Document to a Shard</a>、<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/5.1/mapping-routing-field.html\" target=\"_blank\" rel=\"external\">_routing field</a>.</p>\n<p>查询策略，分别查询vs合并查询？索引越来越大，单个 shard 也很巨大，查询速度也越来越慢。这时候，是选择分索引还是更多的shards？在实践过程中，更多的 shards 会带来额外的索引压力，即 IO 压力。我们选择了分索引。比如按照每个大分类一个索引，或者主要的大城市一个索引。然后将他们进行合并查询。</p>\n<p>索引越来越大，资源使用也越来越多。若是要进行更细的集群分配，大索引使用的资源成倍增加。有什么办法能减小索引？<br>根据具体业务需求，减少某些大的索引，这是一个很好的办法，这样这个集群各方面占用的资源会有一定程度的下降，当让你要说这些少的索引怎么办，这些索引可以放在单独的集群中。</p>\n<h2 id=\"应用性能优化-from-youzan\"><a href=\"#应用性能优化-from-youzan\" class=\"headerlink\" title=\"应用性能优化 - from youzan\"></a>应用性能优化 - <a href=\"http://tech.youzan.com/search-engine1/\" target=\"_blank\" rel=\"external\">from youzan</a></h2><p>一、使用应用级队列防止雪崩<br>ES一个问题是在高峰期时候极容易发生雪崩. ES有健全的线程池系统来保证并发与稳定性问题. 但是在流量突变的情况下(比如双十一秒杀)还是很容易发生瘫痪的现象, 主要的原因如下:</p>\n<p>ES几乎为每类操作配置一个线程池; 只能保证每个线程池的资源使用时合理的, 当2个以上的线程池竞争资源时容易造成资源响应不过来.</p>\n<p>ES没有考虑网络负载导致稳定的问题.</p>\n<p>在AS里我们实现了面向请求的全局队列来保证稳定性. 它主要做了3件事情.<br><img src=\"http://ww1.sinaimg.cn/mw690/b7ba225dly1fjx0kmbrr6j20fu0le3zi.jpg\" alt=\"\"></p>\n<ol>\n<li>根据业务把请求分成一个个slide, 每个slide对应一个队列. 默认一个应用就是一个slide, 一个应用也可以区分不同的slide, 这样可以保护一个应用内重要的查询.</li>\n<li>每个队列配置一个队列长度, 默认为50.</li>\n<li>每个队列计算这个队列的平均响应时间. 当队列平均响应时间超过200ms, 停止工作1s, 如果请求溢出就写入溢出日志留数据恢复使用. 如果连续10次队列平均响应时间超过500ms就报警, 以便工程师第一时间处理.</li>\n</ol>\n<p>二、自动降级<br>应用级队列解决雪崩问题有点粗暴, 如果一个应用本身查询就非常慢, 很容易让一个应用持续超时很久. 我们根据搜索引擎的特点编写了自动降级功能.</p>\n<p>比如商品搜索的例子, 商品搜索最基本的功能是布尔查询, 但是还需要按照相关性分数和质量度排序等功能, 甚至还有个性化需求. 完成简单的布尔查询, ES使用bitsets操作就可以做到, 但是如果如果需要相关性分, 就必须使用倒排索引, 并有大量CPU消耗来计算分数. ES的bitsets比倒排索引快50倍左右.</p>\n<p>对于有降级方案的slide, AS在队列响应过慢时候直接使用降级query代替正常query. 这种方法让我们在不扩容的情况下成功度过了双十一的流量陡增.</p>\n<p>三、善用filtered query<br>理解lucence filter工作原理对于写出高性能查询语句至关重要. 许多搜索性能优化都和filter的使用有关. filter使用bitsets进行布尔运算, quey使用倒排索引进行计算, 这是filter比query快的原因. bitsets的优势主要体现在: </p>\n<ol>\n<li>bitsetcache在内存里面, 永不消失(除非被LRU). </li>\n<li>bitsets利用CPU原生支持的位运算操作, 比倒排索引快个数量级 </li>\n<li>多个bitsets的与运算也是非常的快(一个64位CPU可以同时计算64个DOC的与运算) </li>\n<li>bitsets 在内存的存储是独立于query的, 有很强的复用性 </li>\n<li>如果一个bitset片段全是0, 计算会自动跳过这些片段, 让bitsets在数据稀疏情况下同样表现优于倒排索引.</li>\n</ol>\n<p>举个例子:<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">query:bool:  </div><div class=\"line\">    tag:<span class=\"string\">'mac'</span></div><div class=\"line\">    region:<span class=\"string\">'beijing'</span></div><div class=\"line\">    title: <span class=\"string\">\"apple\"</span></div></pre></td></tr></table></figure></p>\n<p>lucence处理这个query的方式是在倒排索引中寻找这三个term的倒排链 ,并使用跳指针技术求交, 在运算过程中需要对每个doc进行算分. 实际上tag和region对于算分并没有作用, 他们充当是过滤器的作用.</p>\n<p>这就是过滤器使用场景, 它只存储存在和不存在两种状态. 如果我们把tag和region使用bitsets进行存储, 这样这两个过滤器可以一直都被缓存在内存里面, 这样会快很多. 另外tag和region之间的求交非常迅速, 因为64位机器可以时间一个CPU周期同时处理64个doc的位运算.</p>\n<p>一个lucence金科玉律是: 能用filter就用filter, 除非必须使用query(当且仅当你需要算分的时候).<br>正确的写法为:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">query:  </div><div class=\"line\">    filtered: </div><div class=\"line\">        query:  </div><div class=\"line\">             title: <span class=\"string\">\"apple\"</span> </div><div class=\"line\">         filter:</div><div class=\"line\">            tag:<span class=\"string\">\"mac\"</span></div><div class=\"line\">             region:<span class=\"string\">\"beijing\"</span></div></pre></td></tr></table></figure>\n<p>四、其他</p>\n<ol>\n<li><p>线上集群关闭分片自动均衡. 分片的自动均衡主要目的防止更新造成各个分片数据分布不均匀. 但是如果线上一个节点挂掉后, 很容易触发自动均衡, 一时间集群内部的数据移动占用所有带宽. 建议采用闲时定时均衡策略来保证数据的均匀.</p>\n</li>\n<li><p>尽可能延长refresh时间间隔. 为了确保实时索引es索引刷新时间间隔默认为1秒, 索引刷新会导致查询性能受影响, 在确保业务时效性保证的基础上可以适当延长refresh时间间隔保证查询的性能.</p>\n</li>\n<li><p>除非有必要把all字段去掉. 索引默认除了索引每个字段外, 还有额外创建一个all的字段, 保存所有文本, 去掉这个字段可以把索引大小降低50%.</p>\n</li>\n<li><p>创建索引时候, 尽可能把查询比较慢的索引和快的索引物理分离.</p>\n</li>\n</ol>\n<p>##6. 参考（Reference）</p>\n<ol>\n<li><a href=\"http://www.cnblogs.com/guguli/p/5218297.html\" target=\"_blank\" rel=\"external\">elastic调优参考</a></li>\n<li><a href=\"https://github.com/Wprosdocimo/Elasticsearch-zabbix\" target=\"_blank\" rel=\"external\">elastic监控</a></li>\n<li><a href=\"http://udn.yyuap.com/doc/mastering-elasticsearch/chapter-4/41_README.html\" target=\"_blank\" rel=\"external\">Mastering Elasticsearch(中文版)</a></li>\n<li><a href=\"http://kibana.logstash.es/content/logstash/plugins/input/file.html\" target=\"_blank\" rel=\"external\">ELK-权威指南</a></li>\n<li><a href=\"http://www.learnes.net/index.html\" target=\"_blank\" rel=\"external\">Elasticsearch 权威指南</a></li>\n<li><a href=\"http://www.biglittleant.cn/2016/12/01/elastic-study1/\" target=\"_blank\" rel=\"external\">elasticsearch 生产环境配置</a></li>\n<li><a href=\"http://tech.youzan.com/search-engine1/\" target=\"_blank\" rel=\"external\">有赞搜索引擎实践(工程篇)</a></li>\n</ol>\n<p><strong>[更新于2017-05-22 - v1.0 ]<br>[更新于2017-09-26 - v1.01]</strong></p>\n<p>(完)</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"elasticsearch技术手册-v1-01\"><a href=\"#elasticsearch技术手册-v1-01\" class=\"headerlink\" title=\"elasticsearch技术手册 v1.01\"></a>elasticsearch技术手册 v1.01</h1><p>[toc]</p>\n<h2 id=\"1-基础\"><a href=\"#1-基础\" class=\"headerlink\" title=\"1. 基础\"></a>1. 基础</h2><p>本手册内容是基于<code>elasticsearch5+</code>版本。准确的说是5.0.1版本。</p>\n<h3 id=\"1-概念\"><a href=\"#1-概念\" class=\"headerlink\" title=\"1.概念\"></a>1.概念</h3><p>集群（cluster）、节点（node）、索引（index）、分片（shards）、副本（replicas）；<br>term、tf-idf、boost等</p>\n<h3 id=\"2-Elasticsearch-features\"><a href=\"#2-Elasticsearch-features\" class=\"headerlink\" title=\"2. Elasticsearch features\"></a>2. Elasticsearch features</h3><ol>\n<li><a href=\"\">Based in lucene, write in java</a></li>\n<li><a href=\"\">Realtime analytics</a></li>\n<li><a href=\"\">Full Text search engine</a></li>\n<li><a href=\"\">Distributed, easy to scale</a></li>\n<li><a href=\"\">High availability</a></li>\n<li><a href=\"\">Document oriented(json)</a></li>\n<li><a href=\"\">Schema free</a></li>\n<li><a href=\"\">Restful API, json over http</a></li>\n<li><a href=\"\">Open source:Apache License 6.0 (ES:5.x)</a></li>\n<li><a href=\"\">Plugins &amp; Community support</a></li>\n</ol>\n<h3 id=\"3-elasticsearch-do-what-on-lucene\"><a href=\"#3-elasticsearch-do-what-on-lucene\" class=\"headerlink\" title=\"3. elasticsearch do what on lucene?\"></a>3. elasticsearch do what on lucene?</h3><p>Elasticsearch 构建在lucene之上，提供json方式的rest api进行交互；</p>\n<ol>\n<li>Elasticsearch在lucene之上提供一个完整的分布式系统；</li>\n<li>Elasticsearch提供了一个分布式的抽象的数据结构；</li>\n<li>提供了一些特性，例如线程池、队列、node/cluster监控api、数据监控api、以及集群管理等等；</li>\n</ol>\n<h2 id=\"2-生产环境\"><a href=\"#2-生产环境\" class=\"headerlink\" title=\"2. 生产环境\"></a>2. 生产环境</h2><h3 id=\"1-监控（Monitoring）\"><a href=\"#1-监控（Monitoring）\" class=\"headerlink\" title=\"1. 监控（Monitoring）\"></a>1. 监控（Monitoring）</h3><p>对于已经初步部署完成的elasticsearch集群来说，接下来的集群监控就变的更重要了。集群的重要参数，比如集群状态，分片状态等是集群健康的体现。elasticsearch提供了很对的现成api供我们管理和监控cluster。<br>其中，(1)marvel是一个很容易监控elasticsearch的工具。它可以整合大量的统计数据通过kibana。<br>(2) cluster health</p>\n<h3 id=\"2-生产环境部署（Production-Deploying）\"><a href=\"#2-生产环境部署（Production-Deploying）\" class=\"headerlink\" title=\"2. 生产环境部署（Production Deploying）\"></a>2. 生产环境部署（Production Deploying）</h3><p>生产环境的部署有很多考究的地方，接下来我从以下三个方面来说。</p>\n<h4 id=\"运维部署考虑（硬件以及部署策略）\"><a href=\"#运维部署考虑（硬件以及部署策略）\" class=\"headerlink\" title=\"运维部署考虑（硬件以及部署策略）\"></a>运维部署考虑（硬件以及部署策略）</h4><p>（1）memory，elasticsearch是比较吃内存的，尤其像排序、聚合操作，所以保证足够的heap内存是重要的。如果对内存不够的话，会交换到系统的缓存，由于lucene的数据结构是disk-based的格式，这势必会影响搜索的性能；一般建议使用16g-64gRAM的机器。如果大于64g，则会出现<a href=\"https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html\" target=\"_blank\" rel=\"external\">另外的一些问题</a><br>（2）cpus,和内存相比，搜索对cpu的要求不是特别高，一般使用多核cpu就行，比如2-8核的；<br>（3）disk，硬盘的性能对搜索集群非常重要，磁盘的性能直接影响索引的构建和读写操作，很多时候是搜索的一个瓶颈。ssd硬盘是目前最好的方式，但是由于其价钱看看阿里云，是同样的<code>喜人</code>，所以看业务需要，力所能及吧，我们目前使用的是高性能磁盘（high-performance server disks, 15k RPM drives），可以满足业务需求。<br>（4）network，一个快速稳定的网络环境对分布式系统非常的重要，低延迟、高带宽有利于节点间的交互以及分片的拷贝和恢复<br>（5）其他，尽量避免使用小配置机器组合一个超大的集群，这样管理起来就是一个大坑</p>\n<h4 id=\"优化配置参数\"><a href=\"#优化配置参数\" class=\"headerlink\" title=\"优化配置参数\"></a>优化配置参数</h4><p>(1)Java Virtual Machine<br>(2)Transport Client Versus Node Client<br>vs:<br>Transport Client 可以解耦你的应用和搜索服务，应用可以很快的创建和销毁连接；<br>Node Client 可以和搜索服务保持一个持久连接，可以查看搜索的结构信息；<br>(3)Important Configuration Changes<br>elasticsearch配置文件有非常好的默认设置，都是在实际的工作环境中实践过的。当遇到性能问题的时候，更多的是需要考虑数据存储布局和添加更多的node（elasticsearch文档中特意说明了配置文件的重要性，不让随便更改，大多数情况下是正确的）。</p>\n<ul>\n<li>name</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">1. Assign Names</div><div class=\"line\">cluster.name: elasticsearch_production</div><div class=\"line\">node.name: elasticsearch_005_data</div><div class=\"line\"></div><div class=\"line\">2. Paths</div><div class=\"line\">path.data: /path/to/data1,/path/to/data2 </div><div class=\"line\"></div><div class=\"line\"># Path to log files:</div><div class=\"line\">path.logs: /path/to/logs</div><div class=\"line\"></div><div class=\"line\"># Path to where plugins are installed:</div><div class=\"line\">path.plugins: /path/to/plugins</div></pre></td></tr></table></figure>\n<ul>\n<li><p>minimum_master_nodes，这个参数是在配置文件中比较重要的一个，如果配置不对的话，会发生split brains（俗称“脑裂”），就是说会存在多个master节点，继而可能发生丢失data现象。这个参数的计算公式：(number of master-eligible nodes / 2) + 1，举例说明：</p>\n<ul>\n<li>假如你有10个node（可存储数据，可成为master），则设置为6；</li>\n<li>假如你有三个可选为master的节点，100+个数据节点，则设置为2；</li>\n<li>假如你有2个常规节点，这个值设置为2，但是如果丢失一个则会造成集群不可用，如果设置为1，则不能保证脑裂的不存在，最好的方法是保证最小的节点数为3.</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">discovery.zen.minimum_master_nodes: 2</div></pre></td></tr></table></figure>\n<p>因为elasticsearch是自适应的，节点随时添加或者下线，不过还好，有api我们可以实时调整这个参数，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">PUT /_cluster/settings</div><div class=\"line\">&#123;</div><div class=\"line\">    &quot;persistent&quot; : &#123;</div><div class=\"line\">        &quot;discovery.zen.minimum_master_nodes&quot; : 2</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<ul>\n<li>Recovery Settings<br>恢复策略对elasticsearch是必不可少的，举例来说，假如现在集群（10 nodes）集体下线进行维修升级，当重新启动的时候，先启动了5 nodes，此时集群发现有5个node启动了，会执行shard的备份和交换，直到达到分片平衡，此时如果另外5 nodes加入到集群中，会发生什么呢？cluster会继续rebalance，新加入的节点发现数据集群中已经有了，首先删除本地数据，通知集群发动rebalance，平衡各个shards，这整个过程中shard会发生copy、sweap、delete等操作，耗费好多资源和时间，对一个大集群来说，耗费的更多，不可忍受。所以，elasticsearch有三个参数可以配置这些。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">gateway.recover_after_nodes: 8   // 集群中恢复的节点数，就是说当改集群启动了8个几点，才尽兴rebalance</div><div class=\"line\"></div><div class=\"line\">// 这两项说明，本集群有10的node，当10个nodes都启动或者启动了8个node且超过5分钟后就会发起rebalance</div><div class=\"line\">gateway.expected_nodes: 10</div><div class=\"line\">gateway.recover_after_time: 5m</div></pre></td></tr></table></figure>\n<p>这些策略只和<code>整个cluster重启</code>时生效。</p>\n<ul>\n<li>Prefer Unicast over Multicast<br>elasticsearch建议使用单播的方式，虽然依然提供了多播的方式，但存在找不到master等尴尬的问题，不建议使用。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">discovery.zen.ping.unicast.hosts: [&quot;host1&quot;, &quot;host2:port&quot;]</div></pre></td></tr></table></figure>\n<p>（4）不要轻易修改的参数</p>\n<ol>\n<li><p>Garbage Collector<br>elasticsearch中默认采用Concurrent-Mark and Sweep (CMS)的gc回收器；</p>\n</li>\n<li><p>Threadpools<br>elasticsearch中设置线程池非常合理的，如果没有特别情况下不要修改这个值</p>\n</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">Search gets a larger threadpool, and is configured to int((# of cores * 3) / 2) + 1</div></pre></td></tr></table></figure>\n<p>(5)Heap: Sizing and Swapping<br>(6)File Descriptors and MMap<br>elasticsearch混合使用nioFS和MMapFS。</p>\n<h3 id=\"3-插件\"><a href=\"#3-插件\" class=\"headerlink\" title=\"3. 插件\"></a>3. 插件</h3><ol>\n<li>使用<a href=\"https://github.com/mobz/elasticsearch-head\" target=\"_blank\" rel=\"external\">head</a>插件来查看索引数据</li>\n<li>使用<a href=\"https://github.com/lmenezes/elasticsearch-kopf\" target=\"_blank\" rel=\"external\">kopf</a>来备份集群节点</li>\n<li>使用<a href=\"https://github.com/lukas-vlcek/bigdesk\" target=\"_blank\" rel=\"external\">bigdesk</a>查看集群性能</li>\n<li><a href=\"https://github.com/NLPchina/elasticsearch-sql\" target=\"_blank\" rel=\"external\">elasticsearch-sql</a> 通过sql进行聚合检索, 可以将sql语句翻译成ES的JSON检索语句</li>\n<li>中文分词（ik、pinying）</li>\n<li><a href=\"https://www.elastic.co/guide/en/elasticsearch/client/curator/current/about.html\" target=\"_blank\" rel=\"external\">Curator</a></li>\n</ol>\n<h2 id=\"3-参数配置\"><a href=\"#3-参数配置\" class=\"headerlink\" title=\"3. 参数配置\"></a>3. 参数配置</h2><p>暂空（后补）</p>\n<h3 id=\"java优化配置\"><a href=\"#java优化配置\" class=\"headerlink\" title=\"java优化配置\"></a>java优化配置</h3><p>(1)Heap不要超过系统可用内存的一半，并且不要超过32GB。</p>\n<p>(2) cluster集群jvm调优<br>当时我们配置ES的JVM(Xms=Xmx=8G)的垃圾回收器主要是CMS,具体配置如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"># reduce the per-thread stack size</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -Xss256k&quot;</div><div class=\"line\"></div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UseParNewGC&quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UseConcMarkSweepGC&quot;</div><div class=\"line\"></div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:CMSInitiatingOccupancyFraction=75&quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UseCMSInitiatingOccupancyOnly&quot;</div></pre></td></tr></table></figure>\n<p>这块在官方说明中，特意强调了不建议替换java垃圾回收器，<a href=\"https://www.elastic.co/guide/en/elasticsearch/guide/current/_don_8217_t_touch_these_settings.html#_garbage_collector\" target=\"_blank\" rel=\"external\">官方并不推荐使用G1</a>。</p>\n<p><a href=\"https://www.geekhub.cn/a/1256.html\" target=\"_blank\" rel=\"external\">其他博文</a>中有试过使用其他垃圾回收器。他的G1的具体配置如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UseG1GC &quot;</div><div class=\"line\">#init_globals()末尾打印日志</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintFlagsFinal &quot;</div><div class=\"line\">#打印gc引用</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintReferenceGC &quot;</div><div class=\"line\">#输出虚拟机中GC的详细情况.</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -verbose:gc &quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintGCDetails &quot;</div><div class=\"line\">#Enables printing of time stamps at every GC. By default, this option is disabled.</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintGCTimeStamps &quot;</div><div class=\"line\">#Enables printing of information about adaptive generation sizing. By default, this option is disabled.</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintAdaptiveSizePolicy &quot;</div><div class=\"line\"># unlocks diagnostic JVM options</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UnlockDiagnosticVMOptions &quot;</div><div class=\"line\">#to measure where the time is spent</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+G1SummarizeConcMark &quot;</div><div class=\"line\">#设置触发标记周期的 Java 堆占用率阈值。默认占用率是整个 Java 堆的 45%。</div><div class=\"line\">#JAVA_OPTS=&quot;$JAVA_OPTS -XX:InitiatingHeapOccupancyPercent=45 &quot;</div></pre></td></tr></table></figure>\n<p>(3) elastic 开启jmx 监控<br>有时候监控是必不可少的，所以在有条件的时候可以加上jmx监控</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">/usr/local/elastic/bin/elasticsearch.in.sh</div><div class=\"line\">JMX_PORT=9305</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -Dcom.sun.management.jmxremote.port=$JMX_PORT&quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -Dcom.sun.management.jmxremote.ssl=false&quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -Dcom.sun.management.jmxremote.authenticate=false&quot;</div><div class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -Djava.rmi.server.hostname=xx.xx.xx..xx&quot;</div></pre></td></tr></table></figure>\n<h3 id=\"elasticsearch-yml\"><a href=\"#elasticsearch-yml\" class=\"headerlink\" title=\"elasticsearch.yml\"></a>elasticsearch.yml</h3><p>这个是最重要的配置，只有在你明白之后在修改，之后我在单独写一篇文章介绍目前elasticsearch默认参数是如何影响系统的。</p>\n<p>目前配置包括以下几个部分：<br>（1）cluster<br>（2）节点node<br>（3）log／data路径<br>（4）内存<br>（5）网络<br>（5）发现Discovery<br>（6）Gateway<br>（7）其他变量</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div></pre></td><td class=\"code\"><pre><div class=\"line\"># ======================== Elasticsearch Configuration =========================</div><div class=\"line\">#</div><div class=\"line\"># NOTE: Elasticsearch comes with reasonable defaults for most settings.</div><div class=\"line\">#       Before you set out to tweak and tune the configuration, make sure you</div><div class=\"line\">#       understand what are you trying to accomplish and the consequences.</div><div class=\"line\">#</div><div class=\"line\"># The primary way of configuring a node is via this file. This template lists</div><div class=\"line\"># the most important settings you may want to configure for a production cluster.</div><div class=\"line\">#</div><div class=\"line\"># Please see the documentation for further information on configuration options:</div><div class=\"line\"># &lt;https://www.elastic.co/guide/en/elasticsearch/reference/5.0/settings.html&gt;</div><div class=\"line\">#</div><div class=\"line\"># ---------------------------------- Cluster -----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Use a descriptive name for your cluster:</div><div class=\"line\">#</div><div class=\"line\">cluster.name: elastic-pro</div><div class=\"line\">#</div><div class=\"line\"># ------------------------------------ Node ------------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Use a descriptive name for the node:</div><div class=\"line\">#</div><div class=\"line\">node.name: node-0</div><div class=\"line\">#</div><div class=\"line\"># Add custom attributes to the node:</div><div class=\"line\">#</div><div class=\"line\">node.attr.rack: r1</div><div class=\"line\">#</div><div class=\"line\"># ----------------------------------- Paths ------------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Path to directory where to store the data (separate multiple locations by comma):</div><div class=\"line\">#</div><div class=\"line\">path.data: /apps/home/worker/zhangxiaolong/data/index0</div><div class=\"line\">#</div><div class=\"line\"># Path to log files:</div><div class=\"line\">#</div><div class=\"line\">path.logs: /apps/home/worker/zhangxiaolong/data/log0</div><div class=\"line\">#</div><div class=\"line\"># ----------------------------------- Memory -----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Lock the memory on startup:</div><div class=\"line\">#</div><div class=\"line\">bootstrap.memory_lock: true</div><div class=\"line\">#</div><div class=\"line\"># Make sure that the heap size is set to about half the memory available</div><div class=\"line\"># on the system and that the owner of the process is allowed to use this</div><div class=\"line\"># limit.</div><div class=\"line\">#</div><div class=\"line\"># Elasticsearch performs poorly when the system is swapping the memory.</div><div class=\"line\">#</div><div class=\"line\"># ---------------------------------- Network -----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Set the bind address to a specific IP (IPv4 or IPv6):</div><div class=\"line\">#</div><div class=\"line\">network.host: 172.16.7.1</div><div class=\"line\">#</div><div class=\"line\"># Set a custom port for HTTP:</div><div class=\"line\">#</div><div class=\"line\">http.port: 9201</div><div class=\"line\">#</div><div class=\"line\"># For more information, see the documentation at:</div><div class=\"line\"># &lt;https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-network.html&gt;</div><div class=\"line\">#</div><div class=\"line\"># --------------------------------- Discovery ----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Pass an initial list of hosts to perform discovery when new node is started:</div><div class=\"line\">#The default list of hosts is [&quot;127.0.0.1&quot;, &quot;[::1]&quot;]</div><div class=\"line\">#</div><div class=\"line\">discovery.zen.ping.unicast.hosts: [&quot;172.16.7.1:9300&quot;]</div><div class=\"line\">#</div><div class=\"line\"># Prevent the &quot;split brain&quot; by configuring the majority of nodes (total number of nodes / 2 + 1):</div><div class=\"line\">#</div><div class=\"line\">discovery.zen.minimum_master_nodes: 2</div><div class=\"line\">#</div><div class=\"line\"># For more information, see the documentation at:</div><div class=\"line\"># &lt;https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-discovery-zen.html&gt;</div><div class=\"line\">#</div><div class=\"line\"># ---------------------------------- Gateway -----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Block initial recovery after a full cluster restart until N nodes are started:</div><div class=\"line\">#</div><div class=\"line\">gateway.recover_after_nodes: 2</div><div class=\"line\">#</div><div class=\"line\"># For more information, see the documentation at:</div><div class=\"line\"># &lt;https://www.elastic.co/guide/en/elasticsearch/reference/5.0/modules-gateway.html&gt;</div><div class=\"line\">#</div><div class=\"line\"># ---------------------------------- Various -----------------------------------</div><div class=\"line\">#</div><div class=\"line\"># Require explicit names when deleting indices:</div><div class=\"line\">#</div><div class=\"line\">#action.destructive_requires_name: true</div></pre></td></tr></table></figure>\n<h3 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h3><p>（1）线程池设置成内核数，比如八核机器就设置成8，很多阻塞的操作都是Lucene来操作的，比如硬盘读写。搜索的线程设置可以设置成内核数的三倍<br>（2）内存交换<br>这个对于性能影响是致命的，可以使用命令sudo swapoff -a来暂时关闭，永久关闭需要编辑文件/etc/fstab，也可以在配置文件中添加配置bootstrap.mlockall: true，这样jvm可以锁定这些内存，避免被交换到物理存储介质<br>（3）其他</p>\n<ul>\n<li>如果你不需要近实时功能，则设置index的刷新时间；</li>\n<li>如果在进行一个大bulk导入，可以优先考虑设置副本数为0；</li>\n<li>如果在index中的doc你没有一个自然增长的id，可以使用Elasticsearch’s 的自动id做标示，如果有自己的id，尽量设计对lucene友好的id；</li>\n</ul>\n<h2 id=\"4-Rolling-Restarts-amp-备份数据-amp-备份恢复\"><a href=\"#4-Rolling-Restarts-amp-备份数据-amp-备份恢复\" class=\"headerlink\" title=\"4. Rolling Restarts &amp; 备份数据 &amp; 备份恢复\"></a>4. Rolling Restarts &amp; 备份数据 &amp; 备份恢复</h2><h3 id=\"Rolling-Restarts\"><a href=\"#Rolling-Restarts\" class=\"headerlink\" title=\"Rolling Restarts\"></a>Rolling Restarts</h3><p>一般下线一个node（升级、维修等），elasticsearch会进行rebalance操作，如果你是真正的下线一个node，这个操作是十分正确的，但是你知道这台node会之后重新加入到cluster中，则rebalance操作不恰当了，当shard比较大或者多的时候会严重耗费系统资源。</p>\n<p>那我们正确的操作是什么？</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div></pre></td><td class=\"code\"><pre><div class=\"line\">1. 查看集群设置</div><div class=\"line\">curl -XGET http://10.10.160.129:9200/_cluster/settings</div><div class=\"line\"></div><div class=\"line\">2. 如果可能的话，停止正在索引的数据；</div><div class=\"line\"></div><div class=\"line\">3. 停止分片同步，阻止elasticsearch进行rebalance操作</div><div class=\"line\">PUT /_cluster/settings</div><div class=\"line\">&#123;</div><div class=\"line\">    \"transient\" : &#123;</div><div class=\"line\">        \"cluster.routing.allocation.enable\" : \"none\"</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">4.关闭单个node</div><div class=\"line\"></div><div class=\"line\">5.维护或者升级节点node</div><div class=\"line\"></div><div class=\"line\">6.重启node，确认加入cluster</div><div class=\"line\"></div><div class=\"line\">7.重新打开分片同步</div><div class=\"line\">PUT /_cluster/settings</div><div class=\"line\">&#123;</div><div class=\"line\">    \"transient\" : &#123;</div><div class=\"line\">        \"cluster.routing.allocation.enable\" : \"all\"</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">8.针对需要的node重复执行3-7操作</div><div class=\"line\"></div><div class=\"line\">9.到这里就重新恢复了cluster；</div></pre></td></tr></table></figure>\n<h3 id=\"备份数据\"><a href=\"#备份数据\" class=\"headerlink\" title=\"备份数据\"></a>备份数据</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div></pre></td><td class=\"code\"><pre><div class=\"line\">1. 先导入一些数据进行备份</div><div class=\"line\">curl -XPOST 'http://192.168.56.11:9200/bank/account/_bulk?pretty' --data-binary @accounts.json</div><div class=\"line\">curl -XPOST 'http://192.168.56.11:9200/shakespeare/_bulk?pretty' --data-binary @shakespeare.json</div><div class=\"line\">curl -XPOST 'http://192.168.56.11:9200/_bulk?pretty' --data-binary @logs.jsonl</div><div class=\"line\"></div><div class=\"line\">2. 使用API创建一个镜像仓库</div><div class=\"line\">curl -XPOST http://192.168.56.11:9200/_snapshot/my_backup -d '</div><div class=\"line\">&#123;</div><div class=\"line\">    \"type\": \"fs\", </div><div class=\"line\">    \"settings\": &#123; </div><div class=\"line\">        \"location\": \"/data/mount\"</div><div class=\"line\">        \"compress\":  true </div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;'</div><div class=\"line\"><span class=\"meta\">#</span># 解释：</div><div class=\"line\">镜像仓库的名称：my_backup</div><div class=\"line\">镜像仓库的类型：fs。还支持curl，hdfs等。</div><div class=\"line\">镜像仓库的位置：/data/mount 。这个位置必须在配置文件中定义。</div><div class=\"line\">是否启用压缩：compres：true 表示启用压缩。</div><div class=\"line\"></div><div class=\"line\">3. 备份前检查配置</div><div class=\"line\">必须确定备份使用的目录在配置文件中声明了，否则会爆如下错误</div><div class=\"line\">&#123;</div><div class=\"line\">  \"error\": &#123;</div><div class=\"line\">    \"root_cause\": [</div><div class=\"line\">      &#123;</div><div class=\"line\">        \"type\": \"repository_exception\",</div><div class=\"line\">        \"reason\": \"[test-bakcup] failed to create repository\"</div><div class=\"line\">      &#125;</div><div class=\"line\">    ],</div><div class=\"line\">    \"type\": \"repository_exception\",</div><div class=\"line\">    \"reason\": \"[test-bakcup] failed to create repository\",</div><div class=\"line\">    \"caused_by\": &#123;</div><div class=\"line\">      \"type\": \"creation_exception\",</div><div class=\"line\">      \"reason\": \"Guice creation errors:\\n\\n1) Error injecting constructor, RepositoryException[[test-bakcup] location [/data/mount] doesn't match any of the locations specified by path.repo because this setting is empty]\\n  at org.elasticsearch.repositories.fs.FsRepository.&lt;init&gt;(Unknown Source)\\n  while locating org.elasticsearch.repositories.fs.FsRepository\\n  while locating org.elasticsearch.repositories.Repository\\n\\n1 error\",</div><div class=\"line\">      \"caused_by\": &#123;</div><div class=\"line\">        \"type\": \"repository_exception\",</div><div class=\"line\">        \"reason\": \"[test-bakcup] location [/data/mount] doesn't match any of the locations specified by path.repo because this setting is empty\"</div><div class=\"line\">      &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;,</div><div class=\"line\">  \"status\": 500</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">4. 开始创建一个快照</div><div class=\"line\"><span class=\"meta\">#</span>#在后头创建一个快照</div><div class=\"line\">curl -XPUT  http://192.168.56.20:9200/_snapshot/my_backup/snapshot_1 </div><div class=\"line\"><span class=\"meta\">#</span>#也可以在前台运行。</div><div class=\"line\">curl -XPUT  http://192.168.56.11:9200/_snapshot/my_backup/snapshot_1?wait_for_completion=true</div><div class=\"line\"><span class=\"meta\">#</span>#上面的参数会在my_backup仓库里创建一个snapshot_1 的快照。</div><div class=\"line\"></div><div class=\"line\">5. 可以选择相应的索引进行备份</div><div class=\"line\">curl -XPUT  http://192.168.56.20:9200/_snapshot/my_backup/snapshot_2 -d '</div><div class=\"line\">&#123;</div><div class=\"line\">    \"indices\": \"bank,logstash-2015.05.18\"</div><div class=\"line\">&#125;'</div><div class=\"line\"><span class=\"meta\">#</span># 解释：</div><div class=\"line\">创建一个snapshot_2的快照，只备份bank,logstash-2015.05.18这两个索引。</div><div class=\"line\"></div><div class=\"line\">6. 查看备份状态</div><div class=\"line\">整个备份过程中，可以通过如下命令查看备份进度</div><div class=\"line\"></div><div class=\"line\">curl -XGET http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_status</div><div class=\"line\">主要由如下几种状态：</div><div class=\"line\">a. INITIALIZING 集群状态检查，检查当前集群是否可以做快照，通常这个过程会非常快</div><div class=\"line\">b. STARTED 正在转移数据到仓库</div><div class=\"line\">c. FINALIZING 数据转移完成，正在转移元信息</div><div class=\"line\">d. DONE　完成</div><div class=\"line\">e. FAILED 备份失败</div><div class=\"line\"></div><div class=\"line\">7. 取消备份</div><div class=\"line\">curl -XDELETE http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812</div><div class=\"line\"></div><div class=\"line\">8. 获取所有快照信息。</div><div class=\"line\">curl -XGET http://192.168.56.20:9200/_snapshot/my_backup/_all |python -mjson.tool</div><div class=\"line\"><span class=\"meta\">#</span>#解释</div><div class=\"line\">查看my_backup仓库下的所有快照。</div><div class=\"line\"></div><div class=\"line\">9. 手动删除快照</div><div class=\"line\">curl -XDELETE http://192.168.56.20:9200/_snapshot/my_backup/snapshot_2</div><div class=\"line\"><span class=\"meta\">#</span># 解释</div><div class=\"line\">删除my_backup仓库下的snapshot_2的快照。</div></pre></td></tr></table></figure>\n<h3 id=\"备份恢复\"><a href=\"#备份恢复\" class=\"headerlink\" title=\"备份恢复\"></a>备份恢复</h3><figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div></pre></td><td class=\"code\"><pre><div class=\"line\">1. 恢复备份</div><div class=\"line\">curl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore</div><div class=\"line\">同备份一样，也可以设置wait_for_completion=true等待恢复结果</div><div class=\"line\"></div><div class=\"line\">curl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore?wait_for_completion=true</div><div class=\"line\">默认情况下，是恢复所有的索引，我们也可以设置一些参数来指定恢复的索引，以及重命令恢复的索引，这样可以避免覆盖原有的数据.</div><div class=\"line\"></div><div class=\"line\">curl -XPOST http://192.168.0.1:9200/_snapshot/my_backup/snapshot_20150812/_restore</div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"attr\">\"indices\"</span>: <span class=\"string\">\"index_1\"</span>,</div><div class=\"line\">    <span class=\"attr\">\"rename_pattern\"</span>: <span class=\"string\">\"index_(.+)\"</span>,</div><div class=\"line\">    <span class=\"attr\">\"rename_replacement\"</span>: <span class=\"string\">\"restored_index_$1\"</span></div><div class=\"line\">&#125;</div><div class=\"line\">上面的indices, 表示只恢复索引’index_1’</div><div class=\"line\">rename_pattern: 表示重命名索引以’index_’开头的索引.</div><div class=\"line\">rename_replacement: 表示将所有的索引重命名为’restored_index_xxx’.如index_1会被重命名为restored_index_1.</div><div class=\"line\"></div><div class=\"line\">2. 查看所有索引的恢复进度</div><div class=\"line\">curl -XGET http://192.168.0.1:9200/_recovery/</div><div class=\"line\"></div><div class=\"line\">3. 查看索引restored_index_1的恢复进度</div><div class=\"line\">curl -XGET http://192.168.0.1:9200/_recovery/restored_index_1</div><div class=\"line\"></div><div class=\"line\">4. 取消恢复</div><div class=\"line\">只需要删除索引，即可取消恢复</div><div class=\"line\">curl -XDELETE http://192.168.0.1:9200/restored_index_1</div></pre></td></tr></table></figure>\n<h2 id=\"5-性能优化\"><a href=\"#5-性能优化\" class=\"headerlink\" title=\"5. 性能优化\"></a>5. 性能优化</h2><p>在讲性能优化之前，首先要知道：</p>\n<pre><code>过早的优化是万恶之源 Premature optimization is the root of all evil.\n                                                    —— Donald Knuth\n</code></pre><p><code>优化总是发生在目前的情况下不能满足当前的需求，其他我想不出什么理由去优化它。</code></p>\n<p><code>优化很多时候和业务是紧密关联的，优化业务可能比优化程序效率更高、成本更低！</code></p>\n<h3 id=\"索引性能优化\"><a href=\"#索引性能优化\" class=\"headerlink\" title=\"索引性能优化\"></a>索引性能优化</h3><p>索引性能（Index Performance），我们这样定义它，索引的速度是否提高，可以无缝的提供近实时的功能。<br>什么时候会发生索引慢呢？<br>（1）你读的慢（doc from db，file，inputstream等等）<br>（2）你处理的慢（中文下的分词等）<br>（3）你写的慢（还是老式的机械盘？！ 高性能的盘或者ssd）</p>\n<p>还有就是针对不同场景选择的判断，如果你索引的文件非常大，数量多，那应该选择elasticsearch提供的bulk接口，在create doc速度能跟上的时候，bulk 是可以提高速度的。</p>\n<h3 id=\"查询性能优化\"><a href=\"#查询性能优化\" class=\"headerlink\" title=\"查询性能优化\"></a>查询性能优化</h3><p>查询性能（Query Perofrmance），说起来比索引更麻烦一些，面对的场景也更多一些；</p>\n<p>面对海量数据以及不同的集群，针对业务需求去查询往往会很慢，有什么策略可以搞定这种情况？有，那就是<code>routing</code><a href=\"https://www.elastic.co/guide/en/elasticsearch/guide/current/routing-value.html\" target=\"_blank\" rel=\"external\">Routing a Document to a Shard</a>、<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/5.1/mapping-routing-field.html\" target=\"_blank\" rel=\"external\">_routing field</a>.</p>\n<p>查询策略，分别查询vs合并查询？索引越来越大，单个 shard 也很巨大，查询速度也越来越慢。这时候，是选择分索引还是更多的shards？在实践过程中，更多的 shards 会带来额外的索引压力，即 IO 压力。我们选择了分索引。比如按照每个大分类一个索引，或者主要的大城市一个索引。然后将他们进行合并查询。</p>\n<p>索引越来越大，资源使用也越来越多。若是要进行更细的集群分配，大索引使用的资源成倍增加。有什么办法能减小索引？<br>根据具体业务需求，减少某些大的索引，这是一个很好的办法，这样这个集群各方面占用的资源会有一定程度的下降，当让你要说这些少的索引怎么办，这些索引可以放在单独的集群中。</p>\n<h2 id=\"应用性能优化-from-youzan\"><a href=\"#应用性能优化-from-youzan\" class=\"headerlink\" title=\"应用性能优化 - from youzan\"></a>应用性能优化 - <a href=\"http://tech.youzan.com/search-engine1/\" target=\"_blank\" rel=\"external\">from youzan</a></h2><p>一、使用应用级队列防止雪崩<br>ES一个问题是在高峰期时候极容易发生雪崩. ES有健全的线程池系统来保证并发与稳定性问题. 但是在流量突变的情况下(比如双十一秒杀)还是很容易发生瘫痪的现象, 主要的原因如下:</p>\n<p>ES几乎为每类操作配置一个线程池; 只能保证每个线程池的资源使用时合理的, 当2个以上的线程池竞争资源时容易造成资源响应不过来.</p>\n<p>ES没有考虑网络负载导致稳定的问题.</p>\n<p>在AS里我们实现了面向请求的全局队列来保证稳定性. 它主要做了3件事情.<br><img src=\"http://ww1.sinaimg.cn/mw690/b7ba225dly1fjx0kmbrr6j20fu0le3zi.jpg\" alt=\"\"></p>\n<ol>\n<li>根据业务把请求分成一个个slide, 每个slide对应一个队列. 默认一个应用就是一个slide, 一个应用也可以区分不同的slide, 这样可以保护一个应用内重要的查询.</li>\n<li>每个队列配置一个队列长度, 默认为50.</li>\n<li>每个队列计算这个队列的平均响应时间. 当队列平均响应时间超过200ms, 停止工作1s, 如果请求溢出就写入溢出日志留数据恢复使用. 如果连续10次队列平均响应时间超过500ms就报警, 以便工程师第一时间处理.</li>\n</ol>\n<p>二、自动降级<br>应用级队列解决雪崩问题有点粗暴, 如果一个应用本身查询就非常慢, 很容易让一个应用持续超时很久. 我们根据搜索引擎的特点编写了自动降级功能.</p>\n<p>比如商品搜索的例子, 商品搜索最基本的功能是布尔查询, 但是还需要按照相关性分数和质量度排序等功能, 甚至还有个性化需求. 完成简单的布尔查询, ES使用bitsets操作就可以做到, 但是如果如果需要相关性分, 就必须使用倒排索引, 并有大量CPU消耗来计算分数. ES的bitsets比倒排索引快50倍左右.</p>\n<p>对于有降级方案的slide, AS在队列响应过慢时候直接使用降级query代替正常query. 这种方法让我们在不扩容的情况下成功度过了双十一的流量陡增.</p>\n<p>三、善用filtered query<br>理解lucence filter工作原理对于写出高性能查询语句至关重要. 许多搜索性能优化都和filter的使用有关. filter使用bitsets进行布尔运算, quey使用倒排索引进行计算, 这是filter比query快的原因. bitsets的优势主要体现在: </p>\n<ol>\n<li>bitsetcache在内存里面, 永不消失(除非被LRU). </li>\n<li>bitsets利用CPU原生支持的位运算操作, 比倒排索引快个数量级 </li>\n<li>多个bitsets的与运算也是非常的快(一个64位CPU可以同时计算64个DOC的与运算) </li>\n<li>bitsets 在内存的存储是独立于query的, 有很强的复用性 </li>\n<li>如果一个bitset片段全是0, 计算会自动跳过这些片段, 让bitsets在数据稀疏情况下同样表现优于倒排索引.</li>\n</ol>\n<p>举个例子:<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">query:bool:  </div><div class=\"line\">    tag:<span class=\"string\">'mac'</span></div><div class=\"line\">    region:<span class=\"string\">'beijing'</span></div><div class=\"line\">    title: <span class=\"string\">\"apple\"</span></div></pre></td></tr></table></figure></p>\n<p>lucence处理这个query的方式是在倒排索引中寻找这三个term的倒排链 ,并使用跳指针技术求交, 在运算过程中需要对每个doc进行算分. 实际上tag和region对于算分并没有作用, 他们充当是过滤器的作用.</p>\n<p>这就是过滤器使用场景, 它只存储存在和不存在两种状态. 如果我们把tag和region使用bitsets进行存储, 这样这两个过滤器可以一直都被缓存在内存里面, 这样会快很多. 另外tag和region之间的求交非常迅速, 因为64位机器可以时间一个CPU周期同时处理64个doc的位运算.</p>\n<p>一个lucence金科玉律是: 能用filter就用filter, 除非必须使用query(当且仅当你需要算分的时候).<br>正确的写法为:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">query:  </div><div class=\"line\">    filtered: </div><div class=\"line\">        query:  </div><div class=\"line\">             title: <span class=\"string\">\"apple\"</span> </div><div class=\"line\">         filter:</div><div class=\"line\">            tag:<span class=\"string\">\"mac\"</span></div><div class=\"line\">             region:<span class=\"string\">\"beijing\"</span></div></pre></td></tr></table></figure>\n<p>四、其他</p>\n<ol>\n<li><p>线上集群关闭分片自动均衡. 分片的自动均衡主要目的防止更新造成各个分片数据分布不均匀. 但是如果线上一个节点挂掉后, 很容易触发自动均衡, 一时间集群内部的数据移动占用所有带宽. 建议采用闲时定时均衡策略来保证数据的均匀.</p>\n</li>\n<li><p>尽可能延长refresh时间间隔. 为了确保实时索引es索引刷新时间间隔默认为1秒, 索引刷新会导致查询性能受影响, 在确保业务时效性保证的基础上可以适当延长refresh时间间隔保证查询的性能.</p>\n</li>\n<li><p>除非有必要把all字段去掉. 索引默认除了索引每个字段外, 还有额外创建一个all的字段, 保存所有文本, 去掉这个字段可以把索引大小降低50%.</p>\n</li>\n<li><p>创建索引时候, 尽可能把查询比较慢的索引和快的索引物理分离.</p>\n</li>\n</ol>\n<p>##6. 参考（Reference）</p>\n<ol>\n<li><a href=\"http://www.cnblogs.com/guguli/p/5218297.html\" target=\"_blank\" rel=\"external\">elastic调优参考</a></li>\n<li><a href=\"https://github.com/Wprosdocimo/Elasticsearch-zabbix\" target=\"_blank\" rel=\"external\">elastic监控</a></li>\n<li><a href=\"http://udn.yyuap.com/doc/mastering-elasticsearch/chapter-4/41_README.html\" target=\"_blank\" rel=\"external\">Mastering Elasticsearch(中文版)</a></li>\n<li><a href=\"http://kibana.logstash.es/content/logstash/plugins/input/file.html\" target=\"_blank\" rel=\"external\">ELK-权威指南</a></li>\n<li><a href=\"http://www.learnes.net/index.html\" target=\"_blank\" rel=\"external\">Elasticsearch 权威指南</a></li>\n<li><a href=\"http://www.biglittleant.cn/2016/12/01/elastic-study1/\" target=\"_blank\" rel=\"external\">elasticsearch 生产环境配置</a></li>\n<li><a href=\"http://tech.youzan.com/search-engine1/\" target=\"_blank\" rel=\"external\">有赞搜索引擎实践(工程篇)</a></li>\n</ol>\n<p><strong>[更新于2017-05-22 - v1.0 ]<br>[更新于2017-09-26 - v1.01]</strong></p>\n<p>(完)</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cj814lkce0000pjs6jwpjkson","category_id":"cj814lkcn0004pjs6j6w32492","_id":"cj814lkcv000epjs6km8jpd9q"},{"post_id":"cj81aidwm00004ss6a95dg9pg","category_id":"cj81aidwr00014ss6ml5lez37","_id":"cj81aidwx00044ss6aekjdv04"}],"PostTag":[{"post_id":"cj814lkce0000pjs6jwpjkson","tag_id":"cj814lkcp0005pjs6ux3173im","_id":"cj814lkcv000dpjs65pw1p7j2"},{"post_id":"cj81aidwm00004ss6a95dg9pg","tag_id":"cj81aidwv00024ss6skcl05gt","_id":"cj81aidww00034ss6d5r49ay7"}],"Tag":[{"name":"geeker","_id":"cj814lkcp0005pjs6ux3173im"},{"name":"rec","_id":"cj814lkct000bpjs6dw0wk753"},{"name":"search","_id":"cj81aidwv00024ss6skcl05gt"}]}}